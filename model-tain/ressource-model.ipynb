{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1566b4c7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005027,
     "end_time": "2025-06-13T09:19:10.403325",
     "exception": false,
     "start_time": "2025-06-13T09:19:10.398298",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bd56c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:10.412356Z",
     "iopub.status.busy": "2025-06-13T09:19:10.412046Z",
     "iopub.status.idle": "2025-06-13T09:19:38.982640Z",
     "shell.execute_reply": "2025-06-13T09:19:38.981802Z"
    },
    "papermill": {
     "duration": 28.576771,
     "end_time": "2025-06-13T09:19:38.984187",
     "exception": false,
     "start_time": "2025-06-13T09:19:10.407416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Evaluation Metrics and Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24519d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:38.995478Z",
     "iopub.status.busy": "2025-06-13T09:19:38.994824Z",
     "iopub.status.idle": "2025-06-13T09:19:39.009192Z",
     "shell.execute_reply": "2025-06-13T09:19:39.008197Z"
    },
    "papermill": {
     "duration": 0.021157,
     "end_time": "2025-06-13T09:19:39.010771",
     "exception": false,
     "start_time": "2025-06-13T09:19:38.989614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"Layer 1: Data Preprocessing\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scalers = {}\n",
    "        self.feature_columns = []\n",
    "\n",
    "    def clean_data(self, df):\n",
    "        \"\"\"Data cleaning with missing value handling and outlier detection\"\"\"\n",
    "        print(\"Cleaning data...\")\n",
    "\n",
    "        # Handle missing values\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "        df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "\n",
    "        # Outlier detection using IQR\n",
    "        for col in numeric_columns:\n",
    "            if col != 'timestamp':\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def feature_engineering(self, df):\n",
    "        \"\"\"Advanced feature engineering\"\"\"\n",
    "        print(\"Engineering features...\")\n",
    "\n",
    "        # Temporal features\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "        # Statistical features (rolling windows)\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            if col not in ['hour', 'day_of_week', 'is_weekend']:\n",
    "                df[f'{col}_ma_12'] = df[col].rolling(window=12, min_periods=1).mean()\n",
    "                df[f'{col}_std_12'] = df[col].rolling(window=12, min_periods=1).std().fillna(0)\n",
    "                df[f'{col}_diff'] = df[col].diff().fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def normalize_data(self, df, method='standard'):\n",
    "        \"\"\"Multi-method normalization\"\"\"\n",
    "        print(f\"Normalizing data using {method} method...\")\n",
    "\n",
    "        # Separate numeric and categorical columns\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        numeric_cols = [col for col in numeric_cols if col not in ['timestamp']]\n",
    "\n",
    "        if method == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif method == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'standard' or 'minmax'\")\n",
    "\n",
    "        df_normalized = df.copy()\n",
    "        df_normalized[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "        self.scalers[method] = scaler\n",
    "        self.feature_columns = numeric_cols\n",
    "\n",
    "        return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac99141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:39.021532Z",
     "iopub.status.busy": "2025-06-13T09:19:39.021161Z",
     "iopub.status.idle": "2025-06-13T09:19:39.044687Z",
     "shell.execute_reply": "2025-06-13T09:19:39.043870Z"
    },
    "papermill": {
     "duration": 0.031387,
     "end_time": "2025-06-13T09:19:39.046207",
     "exception": false,
     "start_time": "2025-06-13T09:19:39.014820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiScaleForecaster:\n",
    "    \"\"\"Layer 2: Multi-scale Forecasting Engine\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        self.models = {}\n",
    "        self.ensemble_weights = {}\n",
    "\n",
    "    def prepare_sequences(self, data, sequence_length, target_col):\n",
    "        \"\"\"Prepare sequences for LSTM/Transformer models\"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:(i + sequence_length)])\n",
    "            y.append(data[i + sequence_length, target_col])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def build_lstm_model(self, input_shape, name='lstm_24h'):\n",
    "        \"\"\"Build LSTM model for long-term forecasting (24h)\"\"\"\n",
    "        model = Sequential([\n",
    "            LSTM(128, return_sequences=True, input_shape=input_shape),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "        self.models[name] = model\n",
    "        return model\n",
    "\n",
    "    def build_transformer_model(self, input_shape, name='transformer_12h'):\n",
    "        \"\"\"Build Transformer model for medium-term forecasting (12h)\"\"\"\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        # Multi-head attention\n",
    "        attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=8, key_dim=64, dropout=0.1\n",
    "        )(inputs, inputs)\n",
    "\n",
    "        # Add & Norm\n",
    "        attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "        # Feed forward\n",
    "        ffn = Sequential([\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(input_shape[-1])\n",
    "        ])\n",
    "\n",
    "        ffn_output = ffn(attention)\n",
    "        ffn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + ffn_output)\n",
    "\n",
    "        # Global average pooling and output\n",
    "        outputs = tf.keras.layers.GlobalAveragePooling1D()(ffn_output)\n",
    "        outputs = Dense(64, activation='relu')(outputs)\n",
    "        outputs = Dense(1)(outputs)\n",
    "\n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "        self.models[name] = model\n",
    "        return model\n",
    "\n",
    "    def train_arima_model(self, data, name='arima_6h'):\n",
    "        \"\"\"Train ARIMA model for short-term forecasting (6h)\"\"\"\n",
    "        from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "        # Auto ARIMA parameter selection (simplified)\n",
    "        best_aic = float('inf')\n",
    "        best_params = (1, 1, 1)\n",
    "\n",
    "        for p in range(3):\n",
    "            for d in range(2):\n",
    "                for q in range(3):\n",
    "                    try:\n",
    "                        model = ARIMA(data, order=(p, d, q))\n",
    "                        fitted_model = model.fit()\n",
    "                        if fitted_model.aic < best_aic:\n",
    "                            best_aic = fitted_model.aic\n",
    "                            best_params = (p, d, q)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "        # Train final model\n",
    "        model = ARIMA(data, order=best_params)\n",
    "        fitted_model = model.fit()\n",
    "        self.models[name] = fitted_model\n",
    "        return fitted_model\n",
    "\n",
    "    def train_prophet_model(self, data, timestamps, name='prophet_48h'):\n",
    "        \"\"\"Train Prophet model for extended long-term forecasting (48h)\"\"\"\n",
    "        # Prepare data for Prophet\n",
    "        prophet_data = pd.DataFrame({\n",
    "            'ds': timestamps,\n",
    "            'y': data\n",
    "        })\n",
    "\n",
    "        model = Prophet(\n",
    "            changepoint_prior_scale=0.05,\n",
    "            seasonality_prior_scale=10,\n",
    "            daily_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            yearly_seasonality=False\n",
    "        )\n",
    "\n",
    "        model.fit(prophet_data)\n",
    "        self.models[name] = model\n",
    "        return model\n",
    "\n",
    "    def train_models_batch(self, df, target_column, epochs=50):\n",
    "        \"\"\"Train all models with batch processing\"\"\"\n",
    "        print(\"Training multi-scale forecasting models...\")\n",
    "\n",
    "        # Prepare data\n",
    "        data = df[self.feature_columns].values\n",
    "        target_idx = list(df.columns).index(target_column)\n",
    "\n",
    "        # LSTM (24h - sequence length 288 = 24h)\n",
    "        seq_len_lstm = 288\n",
    "        if len(data) > seq_len_lstm:\n",
    "            X_lstm, y_lstm = self.prepare_sequences(data, seq_len_lstm, target_idx)\n",
    "            lstm_model = self.build_lstm_model((seq_len_lstm, data.shape[1]))\n",
    "\n",
    "            # Batch training\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(0, len(X_lstm), self.batch_size):\n",
    "                    batch_X = X_lstm[i:i+self.batch_size]\n",
    "                    batch_y = y_lstm[i:i+self.batch_size]\n",
    "                    lstm_model.train_on_batch(batch_X, batch_y)\n",
    "\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    loss = lstm_model.evaluate(X_lstm, y_lstm, verbose=0)\n",
    "                    print(f\"LSTM Epoch {epoch+1}/{epochs}, Loss: {loss[0]:.4f}\")\n",
    "\n",
    "        # Transformer (12h - sequence length 144 = 12h)\n",
    "        seq_len_transformer = 144\n",
    "        if len(data) > seq_len_transformer:\n",
    "            X_transformer, y_transformer = self.prepare_sequences(data, seq_len_transformer, target_idx)\n",
    "            transformer_model = self.build_transformer_model((seq_len_transformer, data.shape[1]))\n",
    "\n",
    "            # Batch training\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(0, len(X_transformer), self.batch_size):\n",
    "                    batch_X = X_transformer[i:i+self.batch_size]\n",
    "                    batch_y = y_transformer[i:i+self.batch_size]\n",
    "                    transformer_model.train_on_batch(batch_X, batch_y)\n",
    "\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    loss = transformer_model.evaluate(X_transformer, y_transformer, verbose=0)\n",
    "                    print(f\"Transformer Epoch {epoch+1}/{epochs}, Loss: {loss[0]:.4f}\")\n",
    "\n",
    "        # ARIMA (6h)\n",
    "        arima_data = df[target_column].values[-1000:]  # Use last 1000 points\n",
    "        self.train_arima_model(arima_data)\n",
    "\n",
    "        # Prophet (48h)\n",
    "        prophet_data = df[target_column].values\n",
    "        prophet_timestamps = df['timestamp'].values\n",
    "        self.train_prophet_model(prophet_data, prophet_timestamps)\n",
    "\n",
    "        print(\"Multi-scale forecasting models trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060d89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:39.056120Z",
     "iopub.status.busy": "2025-06-13T09:19:39.055787Z",
     "iopub.status.idle": "2025-06-13T09:19:39.075857Z",
     "shell.execute_reply": "2025-06-13T09:19:39.075042Z"
    },
    "papermill": {
     "duration": 0.026713,
     "end_time": "2025-06-13T09:19:39.077384",
     "exception": false,
     "start_time": "2025-06-13T09:19:39.050671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiScaleForecaster:\n",
    "    \"\"\"Layer 2: Multi-scale Forecasting Engine\"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        self.models = {}\n",
    "        self.ensemble_weights = {}\n",
    "        \n",
    "    def prepare_sequences(self, data, sequence_length, target_col):\n",
    "        \"\"\"Prepare sequences for LSTM/Transformer models\"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:(i + sequence_length)])\n",
    "            y.append(data[i + sequence_length, target_col])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def build_lstm_model(self, input_shape, name='lstm_24h'):\n",
    "        \"\"\"Build LSTM model for long-term forecasting (24h)\"\"\"\n",
    "        model = Sequential([\n",
    "            LSTM(128, return_sequences=True, input_shape=input_shape),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(128),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "        self.models[name] = model\n",
    "        return model\n",
    "    \n",
    "    def build_transformer_model(self, input_shape, name='transformer_12h'):\n",
    "        \"\"\"Build Transformer model for medium-term forecasting (12h)\"\"\"\n",
    "        inputs = Input(shape=input_shape)\n",
    "        \n",
    "        # Multi-head attention\n",
    "        attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=8, key_dim=64, dropout=0.1\n",
    "        )(inputs, inputs)\n",
    "        \n",
    "        # Add & Norm\n",
    "        attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "        \n",
    "        # Feed forward\n",
    "        ffn = Sequential([\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(input_shape[-1])\n",
    "        ])\n",
    "        \n",
    "        ffn_output = ffn(attention)\n",
    "        ffn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + ffn_output)\n",
    "        \n",
    "        # Global average pooling and output\n",
    "        outputs = tf.keras.layers.GlobalAveragePooling1D()(ffn_output)\n",
    "        outputs = Dense(64, activation='relu')(outputs)\n",
    "        outputs = Dense(1)(outputs)\n",
    "        \n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "        self.models[name] = model\n",
    "        return model\n",
    "    \n",
    "    def train_arima_model(self, data, name='arima_6h'):\n",
    "        \"\"\"Train ARIMA model for short-term forecasting (6h)\"\"\"\n",
    "        from statsmodels.tsa.arima.model import ARIMA\n",
    "        \n",
    "        # Auto ARIMA parameter selection (simplified)\n",
    "        best_aic = float('inf')\n",
    "        best_params = (1, 1, 1)\n",
    "        \n",
    "        for p in range(3):\n",
    "            for d in range(2):\n",
    "                for q in range(3):\n",
    "                    try:\n",
    "                        model = ARIMA(data, order=(p, d, q))\n",
    "                        fitted_model = model.fit()\n",
    "                        if fitted_model.aic < best_aic:\n",
    "                            best_aic = fitted_model.aic\n",
    "                            best_params = (p, d, q)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        # Train final model\n",
    "        model = ARIMA(data, order=best_params)\n",
    "        fitted_model = model.fit()\n",
    "        self.models[name] = fitted_model\n",
    "        return fitted_model\n",
    "    \n",
    "    def train_prophet_model(self, data, timestamps, name='prophet_48h'):\n",
    "        \"\"\"Train Prophet model for extended long-term forecasting (48h)\"\"\"\n",
    "        # Prepare data for Prophet\n",
    "        prophet_data = pd.DataFrame({\n",
    "            'ds': timestamps,\n",
    "            'y': data\n",
    "        })\n",
    "        \n",
    "        model = Prophet(\n",
    "            changepoint_prior_scale=0.05,\n",
    "            seasonality_prior_scale=10,\n",
    "            daily_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            yearly_seasonality=False\n",
    "        )\n",
    "        \n",
    "        model.fit(prophet_data)\n",
    "        self.models[name] = model\n",
    "        return model\n",
    "    \n",
    "    def train_models_batch(self, df, target_column, epochs=50):\n",
    "        \"\"\"Train all models with batch processing\"\"\"\n",
    "        print(\"Training multi-scale forecasting models...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        data = df[self.feature_columns].values\n",
    "        target_idx = list(df.columns).index(target_column)\n",
    "        \n",
    "        # LSTM (24h - sequence length 288 = 24h)\n",
    "        seq_len_lstm = 288\n",
    "        if len(data) > seq_len_lstm:\n",
    "            X_lstm, y_lstm = self.prepare_sequences(data, seq_len_lstm, target_idx)\n",
    "            lstm_model = self.build_lstm_model((seq_len_lstm, data.shape[1]))\n",
    "            \n",
    "            # Batch training\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(0, len(X_lstm), self.batch_size):\n",
    "                    batch_X = X_lstm[i:i+self.batch_size]\n",
    "                    batch_y = y_lstm[i:i+self.batch_size]\n",
    "                    lstm_model.train_on_batch(batch_X, batch_y)\n",
    "                \n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    loss = lstm_model.evaluate(X_lstm, y_lstm, verbose=0)\n",
    "                    print(f\"LSTM Epoch {epoch+1}/{epochs}, Loss: {loss[0]:.4f}\")\n",
    "        \n",
    "        # Transformer (12h - sequence length 144 = 12h)\n",
    "        seq_len_transformer = 144\n",
    "        if len(data) > seq_len_transformer:\n",
    "            X_transformer, y_transformer = self.prepare_sequences(data, seq_len_transformer, target_idx)\n",
    "            transformer_model = self.build_transformer_model((seq_len_transformer, data.shape[1]))\n",
    "            \n",
    "            # Batch training\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(0, len(X_transformer), self.batch_size):\n",
    "                    batch_X = X_transformer[i:i+self.batch_size]\n",
    "                    batch_y = y_transformer[i:i+self.batch_size]\n",
    "                    transformer_model.train_on_batch(batch_X, batch_y)\n",
    "                \n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    loss = transformer_model.evaluate(X_transformer, y_transformer, verbose=0)\n",
    "                    print(f\"Transformer Epoch {epoch+1}/{epochs}, Loss: {loss[0]:.4f}\")\n",
    "        \n",
    "        # ARIMA (6h)\n",
    "        arima_data = df[target_column].values[-1000:]  # Use last 1000 points\n",
    "        self.train_arima_model(arima_data)\n",
    "        \n",
    "        # Prophet (48h)\n",
    "        prophet_data = df[target_column].values\n",
    "        prophet_timestamps = df['timestamp'].values\n",
    "        self.train_prophet_model(prophet_data, prophet_timestamps)\n",
    "        \n",
    "        print(\"Multi-scale forecasting models trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266629f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:39.086955Z",
     "iopub.status.busy": "2025-06-13T09:19:39.086595Z",
     "iopub.status.idle": "2025-06-13T09:19:39.105454Z",
     "shell.execute_reply": "2025-06-13T09:19:39.104648Z"
    },
    "papermill": {
     "duration": 0.025508,
     "end_time": "2025-06-13T09:19:39.106784",
     "exception": false,
     "start_time": "2025-06-13T09:19:39.081276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContextualAnomalyDetector:\n",
    "    \"\"\"Layer 3: Contextual Anomaly Detection Framework\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        self.detectors = {}\n",
    "        self.thresholds = {\n",
    "            'low': (0.3, 0.5),\n",
    "            'medium': (0.5, 0.7),\n",
    "            'high': (0.7, 0.9),\n",
    "            'critical': (0.9, 1.0)\n",
    "        }\n",
    "\n",
    "    def build_lstm_autoencoder(self, input_shape, name='lstm_autoencoder'):\n",
    "        \"\"\"Build LSTM Autoencoder for sequential anomaly detection\"\"\"\n",
    "        # Encoder\n",
    "        inputs = Input(shape=input_shape)\n",
    "        encoded = LSTM(64, return_sequences=True)(inputs)\n",
    "        encoded = LSTM(32, return_sequences=False)(encoded)\n",
    "\n",
    "        # Decoder\n",
    "        repeated = RepeatVector(input_shape[0])(encoded)\n",
    "        decoded = LSTM(32, return_sequences=True)(repeated)\n",
    "        decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "        decoded = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "\n",
    "        autoencoder = Model(inputs, decoded)\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "        self.detectors[name] = autoencoder\n",
    "        return autoencoder\n",
    "\n",
    "    def train_isolation_forest(self, data, name='isolation_forest'):\n",
    "        \"\"\"Train Isolation Forest for point anomaly detection\"\"\"\n",
    "        model = IsolationForest(\n",
    "            n_estimators=100,\n",
    "            contamination=0.05,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(data)\n",
    "        self.detectors[name] = model\n",
    "        return model\n",
    "\n",
    "    def train_oneclass_svm(self, data, name='oneclass_svm'):\n",
    "        \"\"\"Train One-Class SVM for collective anomaly detection\"\"\"\n",
    "        model = OneClassSVM(\n",
    "            kernel='rbf',\n",
    "            nu=0.05,\n",
    "            gamma='scale'\n",
    "        )\n",
    "        model.fit(data)\n",
    "        self.detectors[name] = model\n",
    "        return model\n",
    "\n",
    "    def train_detectors_batch(self, df, sequence_length=50, epochs=50):\n",
    "        \"\"\"Train all anomaly detectors with batch processing\"\"\"\n",
    "        print(\"Training contextual anomaly detection models...\")\n",
    "\n",
    "        # Prepare data\n",
    "        data = df[self.feature_columns].values\n",
    "\n",
    "        # 1. Isolation Forest (Point anomaly detection)\n",
    "        print(\"Training Isolation Forest...\")\n",
    "        self.train_isolation_forest(data)\n",
    "\n",
    "        # 2. One-Class SVM (Collective anomaly detection)\n",
    "        print(\"Training One-Class SVM...\")\n",
    "        # Use subset for SVM due to computational complexity\n",
    "        svm_data = data[::10]  # Use every 10th point\n",
    "        self.train_oneclass_svm(svm_data)\n",
    "\n",
    "        # 3. LSTM Autoencoder (Sequential anomaly detection)\n",
    "        print(\"Training LSTM Autoencoder...\")\n",
    "        if len(data) > sequence_length:\n",
    "            # Prepare sequences\n",
    "            X_seq = []\n",
    "            for i in range(len(data) - sequence_length):\n",
    "                X_seq.append(data[i:(i + sequence_length)])\n",
    "            X_seq = np.array(X_seq)\n",
    "\n",
    "            # Build and train autoencoder\n",
    "            autoencoder = self.build_lstm_autoencoder((sequence_length, data.shape[1]))\n",
    "\n",
    "            # Batch training\n",
    "            for epoch in range(epochs):\n",
    "                for i in range(0, len(X_seq), self.batch_size):\n",
    "                    batch_X = X_seq[i:i+self.batch_size]\n",
    "                    autoencoder.train_on_batch(batch_X, batch_X)\n",
    "\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    loss = autoencoder.evaluate(X_seq, X_seq, verbose=0)\n",
    "                    print(f\"Autoencoder Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "        print(\"Anomaly detection models trained successfully!\")\n",
    "\n",
    "    def detect_anomalies(self, data, sequence_length=50):\n",
    "        \"\"\"Detect anomalies using ensemble of detectors\"\"\"\n",
    "        results = {}\n",
    "\n",
    "        # Isolation Forest\n",
    "        if 'isolation_forest' in self.detectors:\n",
    "            if_scores = self.detectors['isolation_forest'].decision_function(data)\n",
    "            if_anomalies = self.detectors['isolation_forest'].predict(data)\n",
    "            results['isolation_forest'] = {\n",
    "                'scores': if_scores,\n",
    "                'anomalies': (if_anomalies == -1).astype(int)\n",
    "            }\n",
    "\n",
    "        # One-Class SVM\n",
    "        if 'oneclass_svm' in self.detectors:\n",
    "            svm_scores = self.detectors['oneclass_svm'].decision_function(data[::10])\n",
    "            svm_anomalies = self.detectors['oneclass_svm'].predict(data[::10])\n",
    "            # Interpolate back to original length\n",
    "            svm_scores_full = np.repeat(svm_scores, 10)[:len(data)]\n",
    "            svm_anomalies_full = np.repeat((svm_anomalies == -1).astype(int), 10)[:len(data)]\n",
    "            results['oneclass_svm'] = {\n",
    "                'scores': svm_scores_full,\n",
    "                'anomalies': svm_anomalies_full\n",
    "            }\n",
    "\n",
    "        # LSTM Autoencoder\n",
    "        if 'lstm_autoencoder' in self.detectors and len(data) > sequence_length:\n",
    "            X_seq = []\n",
    "            for i in range(len(data) - sequence_length):\n",
    "                X_seq.append(data[i:(i + sequence_length)])\n",
    "            X_seq = np.array(X_seq)\n",
    "\n",
    "            reconstructions = self.detectors['lstm_autoencoder'].predict(X_seq, batch_size=self.batch_size)\n",
    "            mse = np.mean(np.power(X_seq - reconstructions, 2), axis=(1, 2))\n",
    "\n",
    "            # Pad with zeros for first sequence_length points\n",
    "            mse_full = np.zeros(len(data))\n",
    "            mse_full[sequence_length:] = mse\n",
    "\n",
    "            # Threshold based on 95th percentile\n",
    "            threshold = np.percentile(mse, 95)\n",
    "            ae_anomalies = (mse_full > threshold).astype(int)\n",
    "\n",
    "            results['lstm_autoencoder'] = {\n",
    "                'scores': mse_full,\n",
    "                'anomalies': ae_anomalies\n",
    "            }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def classify_severity(self, score, method='isolation_forest'):\n",
    "        \"\"\"Classify anomaly severity based on adaptive thresholds\"\"\"\n",
    "        if method == 'isolation_forest':\n",
    "            # Normalize IF scores (typically negative)\n",
    "            normalized_score = max(0, min(1, (-score + 0.5) / 0.5))\n",
    "        elif method == 'oneclass_svm':\n",
    "            # Normalize SVM scores\n",
    "            normalized_score = max(0, min(1, (-score + 1) / 2))\n",
    "        else:\n",
    "            # For autoencoder (MSE scores)\n",
    "            normalized_score = min(1, score / 10)  # Adjust based on typical MSE range\n",
    "\n",
    "        for severity, (low, high) in self.thresholds.items():\n",
    "            if low <= normalized_score < high:\n",
    "                return severity\n",
    "        return 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8524e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:39.116296Z",
     "iopub.status.busy": "2025-06-13T09:19:39.115985Z",
     "iopub.status.idle": "2025-06-13T09:19:39.149414Z",
     "shell.execute_reply": "2025-06-13T09:19:39.148426Z"
    },
    "papermill": {
     "duration": 0.0405,
     "end_time": "2025-06-13T09:19:39.151219",
     "exception": false,
     "start_time": "2025-06-13T09:19:39.110719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AnomalyForecastingSystem:\n",
    "    \"\"\"Main system integrating all layers\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessor = DataPreprocessor()\n",
    "        self.forecaster = MultiScaleForecaster(batch_size)\n",
    "        self.detector = ContextualAnomalyDetector(batch_size)\n",
    "        self.data = {}\n",
    "\n",
    "    def load_data(self, data_generator):\n",
    "        \"\"\"Load and preprocess all metric data\"\"\"\n",
    "        print(\"Generating synthetic data...\")\n",
    "\n",
    "        # Generate all metric types\n",
    "        self.data['vmstat'] = data_generator.generate_vmstat_data()\n",
    "        self.data['iostat'] = data_generator.generate_iostat_data()\n",
    "        self.data['netstat'] = data_generator.generate_netstat_data()\n",
    "        self.data['process'] = data_generator.generate_process_data()\n",
    "\n",
    "        print(f\"Generated data shapes:\")\n",
    "        for key, df in self.data.items():\n",
    "            print(f\"  {key}: {df.shape}\")\n",
    "\n",
    "    def preprocess_all_data(self):\n",
    "        \"\"\"Apply Layer 1 preprocessing to all data\"\"\"\n",
    "        print(\"\\n=== LAYER 1: DATA PREPROCESSING ===\")\n",
    "\n",
    "        processed_data = {}\n",
    "        for metric_type, df in self.data.items():\n",
    "            print(f\"\\nProcessing {metric_type} data...\")\n",
    "\n",
    "            # Clean data\n",
    "            df_clean = self.preprocessor.clean_data(df.copy())\n",
    "\n",
    "            # Feature engineering\n",
    "            df_features = self.preprocessor.feature_engineering(df_clean)\n",
    "\n",
    "            # Normalize\n",
    "            df_normalized = self.preprocessor.normalize_data(df_features, method='standard')\n",
    "\n",
    "            processed_data[metric_type] = df_normalized\n",
    "\n",
    "        self.processed_data = processed_data\n",
    "        # Update feature columns from the first dataset\n",
    "        self.forecaster.feature_columns = self.preprocessor.feature_columns\n",
    "        self.detector.feature_columns = self.preprocessor.feature_columns\n",
    "\n",
    "        return processed_data\n",
    "\n",
    "    def train_forecasting_models(self, target_metric='vmstat', target_column='us'):\n",
    "        \"\"\"Apply Layer 2 multi-scale forecasting\"\"\"\n",
    "        print(f\"\\n=== LAYER 2: MULTI-SCALE FORECASTING ===\")\n",
    "\n",
    "        if target_metric not in self.processed_data:\n",
    "            raise ValueError(f\"Metric {target_metric} not found in processed data\")\n",
    "\n",
    "        df = self.processed_data[target_metric]\n",
    "        self.forecaster.train_models_batch(df, target_column, epochs=30)\n",
    "\n",
    "        return self.forecaster.models\n",
    "\n",
    "    def train_anomaly_detectors(self, target_metric='vmstat'):\n",
    "        \"\"\"Apply Layer 3 contextual anomaly detection\"\"\"\n",
    "        print(f\"\\n=== LAYER 3: CONTEXTUAL ANOMALY DETECTION ===\")\n",
    "\n",
    "        if target_metric not in self.processed_data:\n",
    "            raise ValueError(f\"Metric {target_metric} not found in processed data\")\n",
    "\n",
    "        df = self.processed_data[target_metric]\n",
    "        self.detector.train_detectors_batch(df, sequence_length=50, epochs=30)\n",
    "\n",
    "        return self.detector.detectors\n",
    "\n",
    "    def detect_and_analyze_anomalies(self, target_metric='vmstat'):\n",
    "        \"\"\"Detect anomalies and provide analysis\"\"\"\n",
    "        print(f\"\\n=== ANOMALY DETECTION ANALYSIS ===\")\n",
    "\n",
    "        df = self.processed_data[target_metric]\n",
    "        data = df[self.detector.feature_columns].values\n",
    "\n",
    "        # Detect anomalies\n",
    "        results = self.detector.detect_anomalies(data)\n",
    "\n",
    "        # Analyze results\n",
    "        analysis = {}\n",
    "        for method, result in results.items():\n",
    "            anomaly_count = np.sum(result['anomalies'])\n",
    "            anomaly_rate = anomaly_count / len(result['anomalies'])\n",
    "\n",
    "            # Classify severities\n",
    "            severities = [self.detector.classify_severity(score, method)\n",
    "                         for score in result['scores']]\n",
    "            severity_counts = pd.Series(severities).value_counts()\n",
    "\n",
    "            analysis[method] = {\n",
    "                'total_anomalies': anomaly_count,\n",
    "                'anomaly_rate': anomaly_rate,\n",
    "                'severity_distribution': severity_counts.to_dict()\n",
    "            }\n",
    "\n",
    "            print(f\"\\n{method.upper()} Results:\")\n",
    "            print(f\"  Total anomalies: {anomaly_count}\")\n",
    "            print(f\"  Anomaly rate: {anomaly_rate:.4f}\")\n",
    "            print(f\"  Severity distribution: {severity_counts.to_dict()}\")\n",
    "\n",
    "        return results, analysis\n",
    "\n",
    "    def generate_explanations(self, anomaly_results, target_metric='vmstat', top_n=5):\n",
    "        \"\"\"Generate explanations for detected anomalies\"\"\"\n",
    "        print(f\"\\n=== ANOMALY EXPLANATIONS ===\")\n",
    "\n",
    "        df = self.processed_data[target_metric]\n",
    "        explanations = []\n",
    "\n",
    "        # Find top anomalies from each method\n",
    "        for method, result in anomaly_results.items():\n",
    "            anomaly_indices = np.where(result['anomalies'] == 1)[0]\n",
    "            scores = result['scores'][anomaly_indices]\n",
    "\n",
    "            # Get top N anomalies by score\n",
    "            if method == 'isolation_forest':\n",
    "                top_indices = anomaly_indices[np.argsort(scores)[:top_n]]  # Most negative scores\n",
    "            else:\n",
    "                top_indices = anomaly_indices[np.argsort(scores)[-top_n:]]  # Highest scores\n",
    "\n",
    "            for idx in top_indices:\n",
    "                timestamp = df.iloc[idx]['timestamp']\n",
    "                severity = self.detector.classify_severity(result['scores'][idx], method)\n",
    "\n",
    "                # Feature importance (simplified)\n",
    "                feature_values = df.iloc[idx][self.detector.feature_columns].values\n",
    "                feature_names = self.detector.feature_columns\n",
    "\n",
    "                # Find most extreme features (highest absolute normalized values)\n",
    "                extreme_features = []\n",
    "                for i, (name, value) in enumerate(zip(feature_names, feature_values)):\n",
    "                    if abs(value) > 1.5:  # Threshold for extreme values\n",
    "                        extreme_features.append((name, value))\n",
    "\n",
    "                explanation = {\n",
    "                    'timestamp': timestamp,\n",
    "                    'method': method,\n",
    "                    'severity': severity,\n",
    "                    'score': result['scores'][idx],\n",
    "                    'extreme_features': extreme_features[:3],  # Top 3 extreme features\n",
    "                    'context': self._generate_context_explanation(df.iloc[idx])\n",
    "                }\n",
    "\n",
    "                explanations.append(explanation)\n",
    "\n",
    "                print(f\"\\nAnomaly detected at {timestamp} ({method}):\")\n",
    "                print(f\"  Severity: {severity}\")\n",
    "                print(f\"  Score: {result['scores'][idx]:.4f}\")\n",
    "                print(f\"  Key factors: {[f[0] for f in extreme_features[:3]]}\")\n",
    "                print(f\"  Context: {explanation['context']}\")\n",
    "\n",
    "        return explanations\n",
    "\n",
    "    def _generate_context_explanation(self, row):\n",
    "        \"\"\"Generate contextual explanation for an anomaly\"\"\"\n",
    "        hour = row['hour']\n",
    "        is_weekend = row['is_weekend']\n",
    "\n",
    "        context = []\n",
    "\n",
    "        # Time-based context\n",
    "        if 9 <= hour <= 17:\n",
    "            context.append(\"during business hours\")\n",
    "        elif 22 <= hour or hour <= 6:\n",
    "            context.append(\"during night hours\")\n",
    "        else:\n",
    "            context.append(\"during off-peak hours\")\n",
    "\n",
    "        # Day context\n",
    "        if is_weekend:\n",
    "            context.append(\"on weekend\")\n",
    "        else:\n",
    "            context.append(\"on weekday\")\n",
    "\n",
    "        return \", \".join(context)\n",
    "\n",
    "    def visualize_results(self, target_metric='vmstat', target_column='us'):\n",
    "        \"\"\"Visualize anomaly detection and forecasting results\"\"\"\n",
    "        print(f\"\\n=== VISUALIZATION ===\")\n",
    "\n",
    "        df = self.processed_data[target_metric]\n",
    "\n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "        fig.suptitle(f'Anomaly Detection & Forecasting Results - {target_metric}', fontsize=16)\n",
    "\n",
    "        # 1. Original time series with anomalies\n",
    "        axes[0, 0].plot(df['timestamp'], df[target_column], label='Original Signal', alpha=0.7)\n",
    "\n",
    "        # Detect anomalies for visualization\n",
    "        data = df[self.detector.feature_columns].values\n",
    "        anomaly_results = self.detector.detect_anomalies(data)\n",
    "\n",
    "        # Overlay anomalies from different methods\n",
    "        colors = ['red', 'orange', 'purple']\n",
    "        for i, (method, result) in enumerate(anomaly_results.items()):\n",
    "            anomaly_mask = result['anomalies'] == 1\n",
    "            if np.any(anomaly_mask):\n",
    "                axes[0, 0].scatter(df['timestamp'][anomaly_mask],\n",
    "                                 df[target_column][anomaly_mask],\n",
    "                                 color=colors[i % len(colors)],\n",
    "                                 label=f'{method} anomalies',\n",
    "                                 s=30, alpha=0.8)\n",
    "\n",
    "        axes[0, 0].set_title(f'{target_column} with Detected Anomalies')\n",
    "        axes[0, 0].set_xlabel('Time')\n",
    "        axes[0, 0].set_ylabel(target_column)\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # 2. Anomaly scores\n",
    "        for i, (method, result) in enumerate(anomaly_results.items()):\n",
    "            if i < 3:  # Only plot first 3 methods\n",
    "                row = i // 2\n",
    "                col = 1 if i % 2 == 0 else 0\n",
    "                if i == 0:\n",
    "                    axes[0, 1].plot(df['timestamp'], result['scores'], label=method, alpha=0.7)\n",
    "                    axes[0, 1].set_title('Anomaly Scores')\n",
    "                    axes[0, 1].set_xlabel('Time')\n",
    "                    axes[0, 1].set_ylabel('Anomaly Score')\n",
    "                    axes[0, 1].legend()\n",
    "                    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "                elif i == 1:\n",
    "                    axes[1, 0].plot(df['timestamp'], result['scores'], label=method, alpha=0.7, color='orange')\n",
    "                    axes[1, 0].set_title('SVM Anomaly Scores')\n",
    "                    axes[1, 0].set_xlabel('Time')\n",
    "                    axes[1, 0].set_ylabel('Anomaly Score')\n",
    "                    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "                else:\n",
    "                    axes[1, 1].plot(df['timestamp'], result['scores'], label=method, alpha=0.7, color='purple')\n",
    "                    axes[1, 1].set_title('Autoencoder Reconstruction Error')\n",
    "                    axes[1, 1].set_xlabel('Time')\n",
    "                    axes[1, 1].set_ylabel('MSE')\n",
    "                    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # 3. Feature correlation heatmap\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns[:10]  # Top 10 features\n",
    "        correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "        im = axes[2, 0].imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
    "        axes[2, 0].set_xticks(range(len(numeric_cols)))\n",
    "        axes[2, 0].set_yticks(range(len(numeric_cols)))\n",
    "        axes[2, 0].set_xticklabels(numeric_cols, rotation=45, ha='right')\n",
    "        axes[2, 0].set_yticklabels(numeric_cols)\n",
    "        axes[2, 0].set_title('Feature Correlation Matrix')\n",
    "        plt.colorbar(im, ax=axes[2, 0])\n",
    "\n",
    "        # 4. Severity distribution\n",
    "        severity_data = []\n",
    "        severity_methods = []\n",
    "\n",
    "        for method, result in anomaly_results.items():\n",
    "            severities = [self.detector.classify_severity(score, method)\n",
    "                         for score in result['scores']]\n",
    "            severity_counts = pd.Series(severities).value_counts()\n",
    "\n",
    "            for severity, count in severity_counts.items():\n",
    "                severity_data.append(count)\n",
    "                severity_methods.append(f\"{method}\\n{severity}\")\n",
    "\n",
    "        if severity_data:\n",
    "            axes[2, 1].bar(range(len(severity_data)), severity_data,\n",
    "                          color=['green', 'yellow', 'orange', 'red'] * (len(severity_data)//4 + 1))\n",
    "            axes[2, 1].set_xticks(range(len(severity_data)))\n",
    "            axes[2, 1].set_xticklabels(severity_methods, rotation=45, ha='right')\n",
    "            axes[2, 1].set_title('Anomaly Severity Distribution')\n",
    "            axes[2, 1].set_ylabel('Count')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f05da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:39.161117Z",
     "iopub.status.busy": "2025-06-13T09:19:39.160770Z",
     "iopub.status.idle": "2025-06-13T09:19:39.194688Z",
     "shell.execute_reply": "2025-06-13T09:19:39.193833Z"
    },
    "papermill": {
     "duration": 0.041011,
     "end_time": "2025-06-13T09:19:39.196330",
     "exception": false,
     "start_time": "2025-06-13T09:19:39.155319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AnomalyEvaluator:\n",
    "    \"\"\"Comprehensive evaluation of anomaly detection models\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.evaluation_results = {}\n",
    "\n",
    "    def create_ground_truth(self, data, anomaly_indices=None, contamination_rate=0.05):\n",
    "        \"\"\"Create ground truth labels for evaluation\"\"\"\n",
    "        n_samples = len(data)\n",
    "        y_true = np.zeros(n_samples)\n",
    "\n",
    "        if anomaly_indices is not None:\n",
    "            # Use provided anomaly indices\n",
    "            y_true[anomaly_indices] = 1\n",
    "        else:\n",
    "            # Simulate ground truth based on extreme values\n",
    "            # This is a simplified approach - in real scenarios, you'd have labeled data\n",
    "\n",
    "            # Method 1: Statistical outliers (Z-score > 3)\n",
    "            if isinstance(data, np.ndarray) and data.ndim > 1:\n",
    "                # For multivariate data, use Mahalanobis distance\n",
    "                from scipy.spatial.distance import mahalanobis\n",
    "                mean = np.mean(data, axis=0)\n",
    "                cov = np.cov(data.T)\n",
    "                try:\n",
    "                    inv_cov = np.linalg.inv(cov)\n",
    "                    distances = [mahalanobis(point, mean, inv_cov) for point in data]\n",
    "                    threshold = np.percentile(distances, (1 - contamination_rate) * 100)\n",
    "                    y_true[np.array(distances) > threshold] = 1\n",
    "                except:\n",
    "                    # Fallback to univariate approach\n",
    "                    z_scores = np.abs((data - np.mean(data, axis=0)) / np.std(data, axis=0))\n",
    "                    max_z_scores = np.max(z_scores, axis=1)\n",
    "                    threshold = np.percentile(max_z_scores, (1 - contamination_rate) * 100)\n",
    "                    y_true[max_z_scores > threshold] = 1\n",
    "            else:\n",
    "                # For univariate data\n",
    "                z_scores = np.abs((data - np.mean(data)) / np.std(data))\n",
    "                threshold = np.percentile(z_scores, (1 - contamination_rate) * 100)\n",
    "                y_true[z_scores > threshold] = 1\n",
    "\n",
    "        return y_true.astype(int)\n",
    "\n",
    "    def calculate_confusion_matrix(self, y_true, y_pred, method_name):\n",
    "        \"\"\"Calculate and visualize confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Calculate metrics\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        metrics = {\n",
    "            'confusion_matrix': cm,\n",
    "            'true_negatives': tn,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'true_positives': tp,\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'f1_score': f1_score(y_true, y_pred, zero_division=0),\n",
    "            'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "            'sensitivity': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "            'false_positive_rate': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "            'false_negative_rate': fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        }\n",
    "\n",
    "        self.evaluation_results[method_name] = metrics\n",
    "        return metrics\n",
    "\n",
    "    def plot_confusion_matrices(self, y_true, predictions_dict, figsize=(15, 10)):\n",
    "        \"\"\"Plot confusion matrices for all methods\"\"\"\n",
    "        n_methods = len(predictions_dict)\n",
    "        cols = min(3, n_methods)\n",
    "        rows = (n_methods + cols - 1) // cols\n",
    "\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "        if n_methods == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "\n",
    "        for idx, (method_name, y_pred) in enumerate(predictions_dict.items()):\n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            ax = axes[row, col] if rows > 1 else axes[col]\n",
    "\n",
    "            # Calculate confusion matrix\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "            ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "            # Add labels\n",
    "            classes = ['Normal', 'Anomaly']\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            ax.set_xticks(tick_marks)\n",
    "            ax.set_yticks(tick_marks)\n",
    "            ax.set_xticklabels(classes)\n",
    "            ax.set_yticklabels(classes)\n",
    "\n",
    "            # Add text annotations\n",
    "            thresh = cm.max() / 2.\n",
    "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "                ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                       horizontalalignment=\"center\",\n",
    "                       color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "            ax.set_ylabel('True Label')\n",
    "            ax.set_xlabel('Predicted Label')\n",
    "            ax.set_title(f'Confusion Matrix - {method_name}')\n",
    "\n",
    "        # Hide empty subplots\n",
    "        for idx in range(n_methods, rows * cols):\n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            if rows > 1:\n",
    "                axes[row, col].axis('off')\n",
    "            else:\n",
    "                axes[col].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return fig\n",
    "\n",
    "    def plot_roc_curves(self, y_true, scores_dict, figsize=(12, 8)):\n",
    "        \"\"\"Plot ROC curves for all methods\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']\n",
    "\n",
    "        for idx, (method_name, scores) in enumerate(scores_dict.items()):\n",
    "            # Normalize scores for ROC calculation\n",
    "            if method_name == 'isolation_forest':\n",
    "                # Isolation Forest scores are negative, invert them\n",
    "                normalized_scores = -scores\n",
    "            elif method_name == 'oneclass_svm':\n",
    "                # One-Class SVM scores are negative, invert them\n",
    "                normalized_scores = -scores\n",
    "            else:\n",
    "                # For autoencoder reconstruction error, higher is more anomalous\n",
    "                normalized_scores = scores\n",
    "\n",
    "            try:\n",
    "                fpr, tpr, _ = roc_curve(y_true, normalized_scores)\n",
    "                auc_score = roc_auc_score(y_true, normalized_scores)\n",
    "\n",
    "                plt.plot(fpr, tpr, color=colors[idx % len(colors)],\n",
    "                        label=f'{method_name} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "\n",
    "                # Store AUC score\n",
    "                if method_name in self.evaluation_results:\n",
    "                    self.evaluation_results[method_name]['auc_score'] = auc_score\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Could not calculate ROC for {method_name}: {e}\")\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Anomaly Detection Methods')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_precision_recall_curves(self, y_true, scores_dict, figsize=(12, 8)):\n",
    "        \"\"\"Plot Precision-Recall curves for all methods\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']\n",
    "\n",
    "        for idx, (method_name, scores) in enumerate(scores_dict.items()):\n",
    "            # Normalize scores\n",
    "            if method_name == 'isolation_forest':\n",
    "                normalized_scores = -scores\n",
    "            elif method_name == 'oneclass_svm':\n",
    "                normalized_scores = -scores\n",
    "            else:\n",
    "                normalized_scores = scores\n",
    "\n",
    "            try:\n",
    "                precision, recall, _ = precision_recall_curve(y_true, normalized_scores)\n",
    "                avg_precision = average_precision_score(y_true, normalized_scores)\n",
    "\n",
    "                plt.plot(recall, precision, color=colors[idx % len(colors)],\n",
    "                        label=f'{method_name} (AP = {avg_precision:.3f})', linewidth=2)\n",
    "\n",
    "                # Store average precision\n",
    "                if method_name in self.evaluation_results:\n",
    "                    self.evaluation_results[method_name]['average_precision'] = avg_precision\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Could not calculate PR curve for {method_name}: {e}\")\n",
    "\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curves - Anomaly Detection Methods')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    def generate_classification_report(self, y_true, predictions_dict):\n",
    "        \"\"\"Generate detailed classification reports\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        for method_name, y_pred in predictions_dict.items():\n",
    "            print(f\"\\n{method_name.upper()} CLASSIFICATION REPORT:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(classification_report(y_true, y_pred,\n",
    "                                      target_names=['Normal', 'Anomaly'],\n",
    "                                      digits=4))\n",
    "\n",
    "    def create_evaluation_summary(self):\n",
    "        \"\"\"Create comprehensive evaluation summary\"\"\"\n",
    "        if not self.evaluation_results:\n",
    "            print(\"No evaluation results available. Run evaluate_models first.\")\n",
    "            return None\n",
    "\n",
    "        # Create summary DataFrame\n",
    "        summary_data = []\n",
    "        for method, metrics in self.evaluation_results.items():\n",
    "            summary_data.append({\n",
    "                'Method': method,\n",
    "                'Accuracy': metrics.get('accuracy', 0),\n",
    "                'Precision': metrics.get('precision', 0),\n",
    "                'Recall': metrics.get('recall', 0),\n",
    "                'F1-Score': metrics.get('f1_score', 0),\n",
    "                'Specificity': metrics.get('specificity', 0),\n",
    "                'AUC': metrics.get('auc_score', 0),\n",
    "                'Avg Precision': metrics.get('average_precision', 0),\n",
    "                'FPR': metrics.get('false_positive_rate', 0),\n",
    "                'FNR': metrics.get('false_negative_rate', 0)\n",
    "            })\n",
    "\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"EVALUATION SUMMARY - ALL METHODS\")\n",
    "        print(\"=\"*100)\n",
    "        print(summary_df.round(4).to_string(index=False))\n",
    "\n",
    "        # Highlight best performers\n",
    "        print(f\"\\nBEST PERFORMERS:\")\n",
    "        print(f\"Highest Accuracy: {summary_df.loc[summary_df['Accuracy'].idxmax(), 'Method']} ({summary_df['Accuracy'].max():.4f})\")\n",
    "        print(f\"Highest F1-Score: {summary_df.loc[summary_df['F1-Score'].idxmax(), 'Method']} ({summary_df['F1-Score'].max():.4f})\")\n",
    "        print(f\"Highest AUC: {summary_df.loc[summary_df['AUC'].idxmax(), 'Method']} ({summary_df['AUC'].max():.4f})\")\n",
    "\n",
    "        return summary_df\n",
    "\n",
    "    def plot_metrics_comparison(self, figsize=(14, 10)):\n",
    "        \"\"\"Plot comparison of key metrics across methods\"\"\"\n",
    "        if not self.evaluation_results:\n",
    "            print(\"No evaluation results available.\")\n",
    "            return\n",
    "\n",
    "        methods = list(self.evaluation_results.keys())\n",
    "        metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_score']\n",
    "        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "\n",
    "        fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for idx, (metric, name) in enumerate(zip(metrics_to_plot, metric_names)):\n",
    "            values = [self.evaluation_results[method].get(metric, 0) for method in methods]\n",
    "\n",
    "            bars = axes[idx].bar(methods, values, color=['skyblue', 'lightcoral', 'lightgreen'][:len(methods)])\n",
    "            axes[idx].set_title(f'{name} Comparison')\n",
    "            axes[idx].set_ylabel(name)\n",
    "            axes[idx].set_ylim(0, 1)\n",
    "\n",
    "            # Add value labels on bars\n",
    "            for bar, value in zip(bars, values):\n",
    "                axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                              f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "            # Rotate x-axis labels\n",
    "            axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        # Hide the last subplot\n",
    "        axes[5].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa27e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:19:39.206150Z",
     "iopub.status.busy": "2025-06-13T09:19:39.205810Z",
     "iopub.status.idle": "2025-06-13T09:19:39.237181Z",
     "shell.execute_reply": "2025-06-13T09:19:39.236384Z"
    },
    "papermill": {
     "duration": 0.038292,
     "end_time": "2025-06-13T09:19:39.238693",
     "exception": false,
     "start_time": "2025-06-13T09:19:39.200401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Enhanced AnomalyForecastingSystem with evaluation capabilities\n",
    "class EnhancedAnomalyForecastingSystem(AnomalyForecastingSystem):\n",
    "    \"\"\"Enhanced system with comprehensive evaluation capabilities\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size=32):\n",
    "        super().__init__(batch_size)\n",
    "        self.evaluator = AnomalyEvaluator()\n",
    "        self.ground_truth = None\n",
    "\n",
    "    def evaluate_models(self, target_metric='vmstat', contamination_rate=0.05,\n",
    "                       known_anomaly_indices=None):\n",
    "        \"\"\"Comprehensive model evaluation with confusion matrices and scores\"\"\"\n",
    "        print(f\"\\n=== MODEL EVALUATION ===\")\n",
    "\n",
    "        # Get processed data\n",
    "        df = self.processed_data[target_metric]\n",
    "        data = df[self.detector.feature_columns].values\n",
    "\n",
    "        # Create or use ground truth\n",
    "        if known_anomaly_indices is not None:\n",
    "            self.ground_truth = np.zeros(len(data))\n",
    "            self.ground_truth[known_anomaly_indices] = 1\n",
    "        else:\n",
    "            print(\"Creating synthetic ground truth based on statistical outliers...\")\n",
    "            self.ground_truth = self.evaluator.create_ground_truth(\n",
    "                data, contamination_rate=contamination_rate\n",
    "            )\n",
    "\n",
    "        print(f\"Ground truth created: {np.sum(self.ground_truth)} anomalies out of {len(self.ground_truth)} samples\")\n",
    "        print(f\"Anomaly rate: {np.sum(self.ground_truth) / len(self.ground_truth):.4f}\")\n",
    "\n",
    "        # Detect anomalies\n",
    "        anomaly_results = self.detector.detect_anomalies(data)\n",
    "\n",
    "        # Prepare predictions and scores\n",
    "        predictions_dict = {}\n",
    "        scores_dict = {}\n",
    "\n",
    "        for method, result in anomaly_results.items():\n",
    "            predictions_dict[method] = result['anomalies']\n",
    "            scores_dict[method] = result['scores']\n",
    "\n",
    "            # Calculate confusion matrix and metrics\n",
    "            metrics = self.evaluator.calculate_confusion_matrix(\n",
    "                self.ground_truth, result['anomalies'], method\n",
    "            )\n",
    "\n",
    "            print(f\"\\n{method.upper()} METRICS:\")\n",
    "            print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "            print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "            print(f\"  F1-Score: {metrics['f1_score']:.4f}\")\n",
    "            print(f\"  Specificity: {metrics['specificity']:.4f}\")\n",
    "\n",
    "        # Generate visualizations\n",
    "        print(\"\\nGenerating evaluation visualizations...\")\n",
    "\n",
    "        # Confusion matrices\n",
    "        self.evaluator.plot_confusion_matrices(self.ground_truth, predictions_dict)\n",
    "\n",
    "        # ROC curves\n",
    "        self.evaluator.plot_roc_curves(self.ground_truth, scores_dict)\n",
    "\n",
    "        # Precision-Recall curves\n",
    "        self.evaluator.plot_precision_recall_curves(self.ground_truth, scores_dict)\n",
    "\n",
    "        # Classification reports\n",
    "        self.evaluator.generate_classification_report(self.ground_truth, predictions_dict)\n",
    "\n",
    "        # Summary and comparison\n",
    "        summary_df = self.evaluator.create_evaluation_summary()\n",
    "        self.evaluator.plot_metrics_comparison()\n",
    "\n",
    "        return {\n",
    "            'predictions': predictions_dict,\n",
    "            'scores': scores_dict,\n",
    "            'ground_truth': self.ground_truth,\n",
    "            'summary': summary_df,\n",
    "            'detailed_metrics': self.evaluator.evaluation_results\n",
    "        }\n",
    "\n",
    "    def cross_validate_models(self, target_metric='vmstat', n_splits=5):\n",
    "        \"\"\"Perform time-series cross-validation\"\"\"\n",
    "        print(f\"\\n=== CROSS-VALIDATION ===\")\n",
    "\n",
    "        df = self.processed_data[target_metric]\n",
    "        data = df[self.detector.feature_columns].values\n",
    "\n",
    "        # Time series split\n",
    "        split_size = len(data) // n_splits\n",
    "        cv_results = {}\n",
    "\n",
    "        for method in ['isolation_forest', 'oneclass_svm']:\n",
    "            method_scores = []\n",
    "\n",
    "            for i in range(n_splits):\n",
    "                start_idx = i * split_size\n",
    "                end_idx = (i + 1) * split_size if i < n_splits - 1 else len(data)\n",
    "\n",
    "                train_data = data[:start_idx] if start_idx > 0 else data[:end_idx//2]\n",
    "                test_data = data[start_idx:end_idx]\n",
    "\n",
    "                if len(train_data) > 100 and len(test_data) > 50:\n",
    "                    # Train model on training data\n",
    "                    if method == 'isolation_forest':\n",
    "                        model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "                    else:\n",
    "                        model = OneClassSVM(kernel='rbf', nu=0.05, gamma='scale')\n",
    "\n",
    "                    model.fit(train_data)\n",
    "\n",
    "                    # Test on test data\n",
    "                    test_predictions = model.predict(test_data)\n",
    "                    test_scores = model.decision_function(test_data)\n",
    "\n",
    "                    # Create ground truth for test data\n",
    "                    test_ground_truth = self.evaluator.create_ground_truth(test_data)\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    test_predictions_binary = (test_predictions == -1).astype(int)\n",
    "                    f1 = f1_score(test_ground_truth, test_predictions_binary)\n",
    "                    method_scores.append(f1)\n",
    "\n",
    "            cv_results[method] = {\n",
    "                'mean_f1': np.mean(method_scores),\n",
    "                'std_f1': np.std(method_scores),\n",
    "                'scores': method_scores\n",
    "            }\n",
    "\n",
    "            print(f\"{method}: F1 = {np.mean(method_scores):.4f} ± {np.std(method_scores):.4f}\")\n",
    "\n",
    "        return cv_results\n",
    "\n",
    "# Performance monitoring\n",
    "    \"\"\"Monitor system performance and resource usage\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "\n",
    "    def log_performance(self, stage, execution_time, memory_usage=None):\n",
    "        \"\"\"Log performance metrics for each stage\"\"\"\n",
    "        self.metrics[stage] = {\n",
    "            'execution_time': execution_time,\n",
    "            'memory_usage': memory_usage,\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "\n",
    "    def get_performance_summary(self):\n",
    "        \"\"\"Get summary of performance metrics\"\"\"\n",
    "        total_time = sum([m['execution_time'] for m in self.metrics.values()])\n",
    "\n",
    "        print(\"\\nPERFORMANCE SUMMARY:\")\n",
    "        print(\"-\" * 40)\n",
    "        for stage, metrics in self.metrics.items():\n",
    "            print(f\"{stage}: {metrics['execution_time']:.2f}s\")\n",
    "        print(f\"Total execution time: {total_time:.2f}s\")\n",
    "\n",
    "        return self.metrics\n",
    "\n",
    "# GPU memory management\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory to prevent OOM errors\"\"\"\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        tf.keras.backend.clear_session()\n",
    "        print(\"GPU memory cleared\")\n",
    "\n",
    "# Demo Usage with Comprehensive Evaluation\n",
    "def run_comprehensive_demo():\n",
    "    \"\"\"Run complete demo with evaluation metrics\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPREHENSIVE ANOMALY DETECTION EVALUATION DEMO\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Initialize enhanced system\n",
    "    system = EnhancedAnomalyForecastingSystem(batch_size=16)\n",
    "\n",
    "    # Generate synthetic data with known anomalies\n",
    "    data_gen = DataGenerator(days=7, freq='5min')\n",
    "    system.load_data(data_gen)\n",
    "\n",
    "    # Layer 1: Preprocessing\n",
    "    processed_data = system.preprocess_all_data()\n",
    "\n",
    "    # Layer 2: Forecasting\n",
    "    forecasting_models = system.train_forecasting_models(\n",
    "        target_metric='vmstat',\n",
    "        target_column='us'\n",
    "    )\n",
    "\n",
    "    # Layer 3: Anomaly Detection\n",
    "    detection_models = system.train_anomaly_detectors(target_metric='vmstat')\n",
    "\n",
    "    # Comprehensive Evaluation\n",
    "    evaluation_results = system.evaluate_models(\n",
    "        target_metric='vmstat',\n",
    "        contamination_rate=0.05  # Expected 5% anomaly rate\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_results = system.cross_validate_models(target_metric='vmstat', n_splits=5)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COMPREHENSIVE EVALUATION COMPLETED!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return system, evaluation_results, cv_results\n",
    "\n",
    "# Utility function to create custom ground truth\n",
    "def create_custom_ground_truth(timestamps, anomaly_periods):\n",
    "    \"\"\"\n",
    "    Create ground truth based on known anomaly periods\n",
    "\n",
    "    Parameters:\n",
    "    timestamps: array of timestamps\n",
    "    anomaly_periods: list of tuples (start_time, end_time) defining anomaly periods\n",
    "    \"\"\"\n",
    "    ground_truth = np.zeros(len(timestamps))\n",
    "\n",
    "    for start_time, end_time in anomaly_periods:\n",
    "        mask = (timestamps >= start_time) & (timestamps <= end_time)\n",
    "        ground_truth[mask] = 1\n",
    "\n",
    "    return ground_truth.astype(int)\n",
    "\n",
    "# Example usage with custom ground truth\n",
    "def demo_with_custom_ground_truth():\n",
    "    \"\"\"Demo with manually defined anomaly periods\"\"\"\n",
    "\n",
    "    # Initialize system\n",
    "    system = EnhancedAnomalyForecastingSystem(batch_size=16)\n",
    "    data_gen = DataGenerator(days=7, freq='5min')\n",
    "    system.load_data(data_gen)\n",
    "\n",
    "    # Preprocessing and training\n",
    "    system.preprocess_all_data()\n",
    "    system.train_anomaly_detectors(target_metric='vmstat')\n",
    "\n",
    "    # Define known anomaly periods (example)\n",
    "    df = system.processed_data['vmstat']\n",
    "    timestamps = df['timestamp'].values\n",
    "\n",
    "    anomaly_periods = [\n",
    "        (timestamps[100], timestamps[120]),   # First anomaly period\n",
    "        (timestamps[500], timestamps[530]),   # Second anomaly period\n",
    "        (timestamps[800], timestamps[820]),   # Third anomaly period\n",
    "    ]\n",
    "\n",
    "    # Create custom ground truth\n",
    "    custom_ground_truth = create_custom_ground_truth(timestamps, anomaly_periods)\n",
    "\n",
    "    # Evaluate with custom ground truth\n",
    "    data = df[system.detector.feature_columns].values\n",
    "    anomaly_results = system.detector.detect_anomalies(data)\n",
    "\n",
    "    # Manual evaluation\n",
    "    predictions_dict = {}\n",
    "    scores_dict = {}\n",
    "\n",
    "    for method, result in anomaly_results.items():\n",
    "        predictions_dict[method] = result['anomalies']\n",
    "        scores_dict[method] = result['scores']\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = system.evaluator.calculate_confusion_matrix(\n",
    "            custom_ground_truth, result['anomalies'], method\n",
    "        )\n",
    "\n",
    "    # Visualize results\n",
    "    system.evaluator.plot_confusion_matrices(custom_ground_truth, predictions_dict)\n",
    "    system.evaluator.plot_roc_curves(custom_ground_truth, scores_dict)\n",
    "    system.evaluator.create_evaluation_summary()\n",
    "\n",
    "    return system, custom_ground_truth, predictions_dict\n",
    "\n",
    "# Performance comparison function\n",
    "def compare_model_performance(results_dict):\n",
    "    \"\"\"Compare performance across different configurations\"\"\"\n",
    "\n",
    "    comparison_data = []\n",
    "\n",
    "    for config_name, results in results_dict.items():\n",
    "        metrics = results['detailed_metrics']\n",
    "\n",
    "        for method, method_metrics in metrics.items():\n",
    "            comparison_data.append({\n",
    "                'Configuration': config_name,\n",
    "                'Method': method,\n",
    "                'Accuracy': method_metrics.get('accuracy', 0),\n",
    "                'Precision': method_metrics.get('precision', 0),\n",
    "                'Recall': method_metrics.get('recall', 0),\n",
    "                'F1-Score': method_metrics.get('f1_score', 0),\n",
    "                'AUC': method_metrics.get('auc_score', 0)\n",
    "            })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Pivot for better visualization\n",
    "    pivot_metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, metric in enumerate(pivot_metrics):\n",
    "        pivot_df = comparison_df.pivot(index='Method', columns='Configuration', values=metric)\n",
    "\n",
    "        pivot_df.plot(kind='bar', ax=axes[idx], width=0.8)\n",
    "        axes[idx].set_title(f'{metric} Comparison')\n",
    "        axes[idx].set_ylabel(metric)\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "        axes[idx].legend(title='Configuration')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[5].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "# Example of batch evaluation for parameter tuning\n",
    "def parameter_tuning_demo():\n",
    "    \"\"\"Demo of parameter tuning with evaluation metrics\"\"\"\n",
    "\n",
    "    # Different contamination rates to test\n",
    "    contamination_rates = [0.03, 0.05, 0.07, 0.1]\n",
    "    results_dict = {}\n",
    "\n",
    "    for rate in contamination_rates:\n",
    "        print(f\"\\nTesting contamination rate: {rate}\")\n",
    "\n",
    "        # Initialize system\n",
    "        system = EnhancedAnomalyForecastingSystem(batch_size=16)\n",
    "        data_gen = DataGenerator(days=5, freq='5min')  # Smaller dataset for speed\n",
    "        system.load_data(data_gen)\n",
    "\n",
    "        # Preprocessing and training\n",
    "        system.preprocess_all_data()\n",
    "\n",
    "        # Train with different contamination rate\n",
    "        system.detector.train_isolation_forest(\n",
    "            system.processed_data['vmstat'][system.detector.feature_columns].values,\n",
    "            name=f'isolation_forest_{rate}'\n",
    "        )\n",
    "\n",
    "        # Evaluate\n",
    "        evaluation_results = system.evaluate_models(\n",
    "            target_metric='vmstat',\n",
    "            contamination_rate=rate\n",
    "        )\n",
    "\n",
    "        results_dict[f'contamination_{rate}'] = evaluation_results\n",
    "\n",
    "    # Compare results\n",
    "    comparison_df = compare_model_performance(results_dict)\n",
    "    print(\"\\nParameter Tuning Results:\")\n",
    "    print(comparison_df.groupby('Configuration')[['Accuracy', 'F1-Score', 'AUC']].mean())\n",
    "\n",
    "    return results_dict, comparison_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.207575,
   "end_time": "2025-06-13T09:19:42.684989",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-13T09:19:05.477414",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
