{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6821899",
   "metadata": {},
   "source": [
    "# AIX System Metrics Analysis & Model Training\n",
    "\n",
    "This notebook connects to the PostgreSQL database to retrieve system metrics data collected from AIX servers. We'll use this data to:\n",
    "1. Explore and visualize the metrics,\n",
    "2. Preprocess the data for machine learning,\n",
    "3. Train anomaly detection models,\n",
    "4. Evaluate and save the models for use in the Django application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e3d55",
   "metadata": {},
   "source": [
    "# System Metrics Analysis : Anomaly Dtetection and Classification\n",
    "# ================================================================\n",
    "\n",
    "# Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2560fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Set style for plots\n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c834b77",
   "metadata": {},
   "source": [
    "# 2. Load and Prepare data from postgres\n",
    "# Import necessary library for postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922071ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# from psycopg2 import sql\n",
    "# from sqlalchemy import create_engine\n",
    "# import json\n",
    "# import datetime\n",
    "\n",
    "# def load_system_metrics(db_config=None, use_sample_data=False, sample_size=10000, data_source=\"db\"):\n",
    "#     \"\"\"\n",
    "#     Load system metrics from PostgreSQL database in Docker or from a JSON file\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     db_config : dict\n",
    "#         Dictionary with database connection parameters (host, port, dbname, user, password)\n",
    "#         If None, default values will be used\n",
    "#     use_sample_data : bool\n",
    "#         If True, generates sample data instead of connecting to the database\n",
    "#     sample_size : int\n",
    "#         Number of rows to sample from the database (to avoid memory issues)\n",
    "#     data_source : str\n",
    "#         Source of data: \"db\" for database, \"json\" for JSON files\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     DataFrame : Pandas DataFrame with system metrics data\n",
    "#     \"\"\"\n",
    "#     if use_sample_data:\n",
    "#         return generate_sample_data()\n",
    "    \n",
    "#     if data_source == \"json\":\n",
    "#         return load_from_json()\n",
    "        \n",
    "#     # Default database configuration\n",
    "#     if db_config is None:\n",
    "#         db_config = {\n",
    "#             'host': 'postgres',  # Docker host - may need to be changed if Docker is on a different host\n",
    "#             'port': '5432',       # Default PostgreSQL port - change if mapped differently\n",
    "#             'dbname': 'aix_monitor',  # Your database name\n",
    "#             'user': 'postgres',   # Your database username\n",
    "#             'password': '@dmin**@@2025'  # Your database password\n",
    "#         }\n",
    "    \n",
    "#     try:\n",
    "#         # Create connection string\n",
    "#         conn_string = f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "        \n",
    "#         # Connect using SQLAlchemy (easier for pandas integration)\n",
    "#         engine = create_engine(conn_string)\n",
    "        \n",
    "#         print(\"Connected to PostgreSQL. Loading data...\")\n",
    "        \n",
    "#         # Strategy for handling large datasets:\n",
    "#         # 1. Sample a subset of the data (based on sample_size parameter)\n",
    "#         # 2. Use SQL to aggregate or filter data when possible\n",
    "        \n",
    "#         # Use more efficient SQL query with sampling to avoid memory issues\n",
    "#         # This example assumes specific table structures - adjust based on your schema\n",
    "        \n",
    "#         # For vmstat metrics\n",
    "#         vmstat_query = f\"\"\"\n",
    "#         SELECT * FROM vmstat_metrics\n",
    "#         TABLESAMPLE BERNOULLI ({sample_size * 100.0 / 80000})  -- Adjust percentage based on your total rows\n",
    "#         ORDER BY RANDOM()\n",
    "#         LIMIT {sample_size}\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # For iostat metrics (assuming similar volume)\n",
    "#         iostat_query = f\"\"\"\n",
    "#         SELECT * FROM iostat_metrics\n",
    "#         TABLESAMPLE BERNOULLI ({sample_size * 100.0 / 80000})\n",
    "#         ORDER BY RANDOM()\n",
    "#         LIMIT {sample_size}\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # For netstat metrics\n",
    "#         netstat_query = f\"\"\"\n",
    "#         SELECT * FROM netstat_metrics\n",
    "#         TABLESAMPLE BERNOULLI ({sample_size * 100.0 / 80000})\n",
    "#         ORDER BY RANDOM()\n",
    "#         LIMIT {sample_size}\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # For process metrics\n",
    "#         process_query = f\"\"\"\n",
    "#         SELECT * FROM process_metrics\n",
    "#         TABLESAMPLE BERNOULLI ({sample_size * 100.0 / 80000})\n",
    "#         ORDER BY RANDOM()\n",
    "#         LIMIT {sample_size}\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Load data from each table\n",
    "#         try:\n",
    "#             vmstat_df = pd.read_sql(vmstat_query, engine)\n",
    "#             print(f\"Loaded {len(vmstat_df)} vmstat records\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading vmstat data: {e}\")\n",
    "#             vmstat_df = pd.DataFrame()\n",
    "            \n",
    "#         try:\n",
    "#             iostat_df = pd.read_sql(iostat_query, engine)\n",
    "#             print(f\"Loaded {len(iostat_df)} iostat records\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading iostat data: {e}\")\n",
    "#             iostat_df = pd.DataFrame()\n",
    "            \n",
    "#         try:\n",
    "#             netstat_df = pd.read_sql(netstat_query, engine)\n",
    "#             print(f\"Loaded {len(netstat_df)} netstat records\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading netstat data: {e}\")\n",
    "#             netstat_df = pd.DataFrame()\n",
    "            \n",
    "#         try:\n",
    "#             process_df = pd.read_sql(process_query, engine)\n",
    "#             print(f\"Loaded {len(process_df)} process records\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading process data: {e}\")\n",
    "#             process_df = pd.DataFrame()\n",
    "        \n",
    "#         # Now we need to merge these datasets on timestamp or other appropriate keys\n",
    "#         # This is a simplified example - adjust the merge logic based on your data structure\n",
    "#         if not vmstat_df.empty:\n",
    "#             # Start with vmstat as the base\n",
    "#             merged_df = vmstat_df\n",
    "            \n",
    "#             # Prepare to add additional features from other tables\n",
    "#             # This assumes a timestamp field exists in all tables\n",
    "#             # You may need to adjust the merge logic based on your schema\n",
    "            \n",
    "#             # Function to merge data frames approximately on timestamp\n",
    "#             def merge_on_approximate_timestamp(base_df, add_df, suffix):\n",
    "#                 if add_df.empty:\n",
    "#                     return base_df\n",
    "                \n",
    "#                 # Make sure timestamp columns are datetime type\n",
    "#                 for df in [base_df, add_df]:\n",
    "#                     if 'timestamp' in df.columns and not pd.api.types.is_datetime64_dtype(df['timestamp']):\n",
    "#                         df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "                \n",
    "#                 # Find closest timestamp pairs\n",
    "#                 # This is a simple approach - for production use a more efficient method\n",
    "#                 merged = pd.merge_asof(\n",
    "#                     base_df.sort_values('timestamp'),\n",
    "#                     add_df.sort_values('timestamp'),\n",
    "#                     on='timestamp',\n",
    "#                     direction='nearest',\n",
    "#                     tolerance=pd.Timedelta('5m'),  # Allow 5 minute tolerance\n",
    "#                     suffixes=('', suffix)\n",
    "#                 )\n",
    "#                 return merged\n",
    "            \n",
    "#             # Merge with iostat data\n",
    "#             if not iostat_df.empty:\n",
    "#                 try:\n",
    "#                     merged_df = merge_on_approximate_timestamp(merged_df, iostat_df, '_iostat')\n",
    "#                     print(\"Merged iostat data\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error merging iostat data: {e}\")\n",
    "            \n",
    "#             # Merge with netstat data\n",
    "#             if not netstat_df.empty:\n",
    "#                 try:\n",
    "#                     merged_df = merge_on_approximate_timestamp(merged_df, netstat_df, '_netstat')\n",
    "#                     print(\"Merged netstat data\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error merging netstat data: {e}\")\n",
    "            \n",
    "#             # For process data, we might want to aggregate by timestamp first\n",
    "#             if not process_df.empty:\n",
    "#                 try:\n",
    "#                     # Group process data by timestamp and compute averages\n",
    "#                     process_agg = process_df.groupby('timestamp').agg({\n",
    "#                         'cpu': 'mean',\n",
    "#                         'mem': 'mean',\n",
    "#                         'pid': 'count'\n",
    "#                     }).rename(columns={'pid': 'process_count'}).reset_index()\n",
    "                    \n",
    "#                     merged_df = merge_on_approximate_timestamp(merged_df, process_agg, '_process')\n",
    "#                     print(\"Merged process data (aggregated)\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error merging process data: {e}\")\n",
    "            \n",
    "#             print(f\"Final merged dataset shape: {merged_df.shape}\")\n",
    "            \n",
    "#             # Add classification labels (state) based on system metrics\n",
    "#             # These thresholds need to be adjusted based on your specific environment\n",
    "#             merged_df['state'] = 0  # normal by default\n",
    "            \n",
    "#             # High load when CPU usage > 60% or runnable processes > 5\n",
    "#             if 'idle' in merged_df.columns:\n",
    "#                 high_load = ((1 - merged_df['idle']) > 0.6) | (merged_df['r'] > 5)\n",
    "#                 merged_df.loc[high_load, 'state'] = 1\n",
    "            \n",
    "#                 # Critical when CPU usage > 85% or free memory < 2000\n",
    "#                 critical = ((1 - merged_df['idle']) > 0.85) | (merged_df['fre'] < 2000)\n",
    "#                 merged_df.loc[critical, 'state'] = 2\n",
    "            \n",
    "#             return merged_df\n",
    "#         else:\n",
    "#             print(\"No vmstat data available. Cannot create merged dataset.\")\n",
    "#             return generate_sample_data()\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error connecting to database: {e}\")\n",
    "#         print(\"Falling back to sample data...\")\n",
    "#         return generate_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26069dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_from_json(vmstat_path=\"D:\\\\projet\\\\migration_data\\\\vmstat_metrics.json\", \n",
    "#                   iostat_path=\"D:\\\\projet\\\\migration_data\\\\iostat_metrics.json\",\n",
    "#                   netstat_path=\"D:\\\\projet\\\\migration_data\\\\netstat_metrics.json\",\n",
    "#                   process_path=\"D:\\\\projet\\\\migration_data\\\\process_metrics.json\",\n",
    "#                   sample_size=5000):\n",
    "#     \"\"\"\n",
    "#     Load system metrics from JSON files\n",
    "#     This is an alternative to loading from the database\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Load vmstat data\n",
    "#         with open(vmstat_path, 'r') as f:\n",
    "#             vmstat_data = json.load(f)\n",
    "#         # Convert to DataFrame and sample\n",
    "#         vmstat_df = pd.DataFrame(vmstat_data)\n",
    "#         if len(vmstat_df) > sample_size:\n",
    "#             vmstat_df = vmstat_df.sample(sample_size, random_state=42)\n",
    "#         print(f\"Loaded {len(vmstat_df)} vmstat records from JSON\")\n",
    "        \n",
    "#         # Load iostat data\n",
    "#         try:\n",
    "#             with open(iostat_path, 'r') as f:\n",
    "#                 iostat_data = json.load(f)\n",
    "#             iostat_df = pd.DataFrame(iostat_data)\n",
    "#             if len(iostat_df) > sample_size:\n",
    "#                 iostat_df = iostat_df.sample(sample_size, random_state=42)\n",
    "#             print(f\"Loaded {len(iostat_df)} iostat records from JSON\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading iostat data: {e}\")\n",
    "#             iostat_df = pd.DataFrame()\n",
    "        \n",
    "#         # Load netstat data\n",
    "#         try:\n",
    "#             with open(netstat_path, 'r') as f:\n",
    "#                 netstat_data = json.load(f)\n",
    "#             netstat_df = pd.DataFrame(netstat_data)\n",
    "#             if len(netstat_df) > sample_size:\n",
    "#                 netstat_df = netstat_df.sample(sample_size, random_state=42)\n",
    "#             print(f\"Loaded {len(netstat_df)} netstat records from JSON\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading netstat data: {e}\")\n",
    "#             netstat_df = pd.DataFrame()\n",
    "        \n",
    "#         # Load process data\n",
    "#         try:\n",
    "#             with open(process_path, 'r') as f:\n",
    "#                 process_data = json.load(f)\n",
    "#             process_df = pd.DataFrame(process_data)\n",
    "#             if len(process_df) > sample_size:\n",
    "#                 process_df = process_df.sample(sample_size, random_state=42)\n",
    "#             print(f\"Loaded {len(process_df)} process records from JSON\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading process data: {e}\")\n",
    "#             process_df = pd.DataFrame()\n",
    "        \n",
    "#         # Merge datasets (similar to database loading method)\n",
    "#         # Start with vmstat as the base\n",
    "#         merged_df = vmstat_df\n",
    "        \n",
    "#         # Function to merge data frames approximately on timestamp\n",
    "#         def merge_on_approximate_timestamp(base_df, add_df, suffix):\n",
    "#             if add_df.empty:\n",
    "#                 return base_df\n",
    "            \n",
    "#             # Make sure timestamp columns are datetime type\n",
    "#             for df in [base_df, add_df]:\n",
    "#                 if 'timestamp' in df.columns and not pd.api.types.is_datetime64_dtype(df['timestamp']):\n",
    "#                     df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            \n",
    "#             # Find closest timestamp pairs\n",
    "#             merged = pd.merge_asof(\n",
    "#                 base_df.sort_values('timestamp'),\n",
    "#                 add_df.sort_values('timestamp'),\n",
    "#                 on='timestamp',\n",
    "#                 direction='nearest',\n",
    "#                 tolerance=pd.Timedelta('5m'),  # Allow 5 minute tolerance\n",
    "#                 suffixes=('', suffix)\n",
    "#             )\n",
    "#             return merged\n",
    "        \n",
    "#         # Try to merge with each dataset\n",
    "#         if not iostat_df.empty:\n",
    "#             try:\n",
    "#                 merged_df = merge_on_approximate_timestamp(merged_df, iostat_df, '_iostat')\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error merging iostat data: {e}\")\n",
    "        \n",
    "#         if not netstat_df.empty:\n",
    "#             try:\n",
    "#                 merged_df = merge_on_approximate_timestamp(merged_df, netstat_df, '_netstat')\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error merging netstat data: {e}\")\n",
    "        \n",
    "#         if not process_df.empty:\n",
    "#             try:\n",
    "#                 # Group process data by timestamp and compute averages\n",
    "#                 process_agg = process_df.groupby('timestamp').agg({\n",
    "#                     'cpu': 'mean',\n",
    "#                     'mem': 'mean',\n",
    "#                     'pid': 'count'\n",
    "#                 }).rename(columns={'pid': 'process_count'}).reset_index()\n",
    "                \n",
    "#                 merged_df = merge_on_approximate_timestamp(merged_df, process_agg, '_process')\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error merging process data: {e}\")\n",
    "        \n",
    "#         # Add classification labels\n",
    "#         merged_df['state'] = 0  # normal by default\n",
    "        \n",
    "#         # High load when CPU usage > 60% or runnable processes > 5\n",
    "#         if 'idle' in merged_df.columns:\n",
    "#             high_load = ((1 - merged_df['idle']) > 0.6) | (merged_df['r'] > 5)\n",
    "#             merged_df.loc[high_load, 'state'] = 1\n",
    "        \n",
    "#             # Critical when CPU usage > 85% or free memory < 2000\n",
    "#             critical = ((1 - merged_df['idle']) > 0.85) | (merged_df['fre'] < 2000)\n",
    "#             merged_df.loc[critical, 'state'] = 2\n",
    "        \n",
    "#         return merged_df\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading data from JSON: {e}\")\n",
    "#         print(\"Falling back to sample data...\")\n",
    "#         return generate_sample_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85942030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_sample_data(n_samples=1000):\n",
    "#     \"\"\"\n",
    "#     Generate sample system metrics data for testing\n",
    "#     \"\"\"\n",
    "#     print(\"Generating sample data for demonstration...\")\n",
    "    \n",
    "#     np.random.seed(42)\n",
    "    \n",
    "#     # Create timestamp index\n",
    "#     timestamps = pd.date_range(start='2024-01-01', periods=n_samples, freq='5min')\n",
    "    \n",
    "#     # VM stats\n",
    "#     r = np.random.poisson(2, n_samples)  # runnable processes\n",
    "#     b = np.random.poisson(1, n_samples)  # processes in uninterruptible sleep\n",
    "#     avm = np.random.normal(8000, 1000, n_samples)  # active virtual memory\n",
    "#     fre = np.random.normal(4000, 800, n_samples)  # free memory\n",
    "    \n",
    "#     # CPU stats\n",
    "#     us = np.clip(np.random.beta(2, 5, n_samples), 0, 1)  # user CPU time\n",
    "#     sy = np.clip(np.random.beta(1.5, 6, n_samples), 0, 1)  # system CPU time\n",
    "#     idle = 1 - (us + sy)  # idle CPU time\n",
    "#     idle = np.clip(idle, 0, 1)\n",
    "    \n",
    "#     # Disk stats - create patterns for 2 disks\n",
    "#     tps1 = np.random.gamma(2, 10, n_samples)\n",
    "#     kb_read1 = np.random.gamma(3, 500, n_samples)\n",
    "#     kb_wrtn1 = np.random.gamma(2, 300, n_samples)\n",
    "    \n",
    "#     tps2 = np.random.gamma(1.5, 8, n_samples)\n",
    "#     kb_read2 = np.random.gamma(2, 400, n_samples)\n",
    "#     kb_wrtn2 = np.random.gamma(1.5, 250, n_samples)\n",
    "    \n",
    "#     # Network stats - 2 interfaces\n",
    "#     ipkts1 = np.random.gamma(5, 200, n_samples)\n",
    "#     opkts1 = np.random.gamma(4, 180, n_samples)\n",
    "    \n",
    "#     ipkts2 = np.random.gamma(3, 150, n_samples)\n",
    "#     opkts2 = np.random.gamma(2.5, 130, n_samples)\n",
    "    \n",
    "#     # Create the DataFrame\n",
    "#     df = pd.DataFrame({\n",
    "#         'timestamp': timestamps,\n",
    "#         'r': r,\n",
    "#         'b': b,\n",
    "#         'avm': avm,\n",
    "#         'fre': fre,\n",
    "#         'us': us,\n",
    "#         'sy': sy,\n",
    "#         'idle': idle,\n",
    "#         'disk1_tps': tps1,\n",
    "#         'disk1_kb_read': kb_read1,\n",
    "#         'disk1_kb_wrtn': kb_wrtn1,\n",
    "#         'disk2_tps': tps2,\n",
    "#         'disk2_kb_read': kb_read2,\n",
    "#         'disk2_kb_wrtn': kb_wrtn2,\n",
    "#         'net1_ipkts': ipkts1,\n",
    "#         'net1_opkts': opkts1,\n",
    "#         'net2_ipkts': ipkts2,\n",
    "#         'net2_opkts': opkts2\n",
    "#     })\n",
    "    \n",
    "#     # Add some anomalies \n",
    "#     # High load periods\n",
    "#     anomaly_indices = np.random.choice(range(n_samples), size=50, replace=False)\n",
    "#     for idx in anomaly_indices:\n",
    "#         df.loc[idx, 'us'] = np.clip(df.loc[idx, 'us'] * 2.5, 0, 1)\n",
    "#         df.loc[idx, 'sy'] = np.clip(df.loc[idx, 'sy'] * 2, 0, 1)\n",
    "#         df.loc[idx, 'idle'] = np.clip(1 - (df.loc[idx, 'us'] + df.loc[idx, 'sy']), 0, 1)\n",
    "#         df.loc[idx, 'r'] = df.loc[idx, 'r'] * 3\n",
    "#         df.loc[idx, 'avm'] = df.loc[idx, 'avm'] * 1.5\n",
    "#         df.loc[idx, 'fre'] = df.loc[idx, 'fre'] * 0.6\n",
    "    \n",
    "#     # Add classification labels\n",
    "#     # 0: normal, 1: high load, 2: critical\n",
    "#     df['state'] = 0  # normal by default\n",
    "    \n",
    "#     # High load when CPU usage > 60% or runnable processes > 5\n",
    "#     high_load = ((1 - df['idle']) > 0.6) | (df['r'] > 5)\n",
    "#     df.loc[high_load, 'state'] = 1\n",
    "    \n",
    "#     # Critical when CPU usage > 85% or free memory < 2000\n",
    "#     critical = ((1 - df['idle']) > 0.85) | (df['fre'] < 2000)\n",
    "#     df.loc[critical, 'state'] = 2\n",
    "    \n",
    "#     # return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea7277",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "You can choose from three approaches:\n",
    " 1. Direct DB connection (may be slow for large datasets)\n",
    " 2. JSON files (more efficient for large datasets)\n",
    " 3. Sample data (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b71f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Direct DB connection with sampling\n",
    "# Configure your database connection here\n",
    "# db_config = {\n",
    "#     'host': 'postgres',\n",
    "#     'port': '5432',\n",
    "#     'dbname': 'aix_monitor',\n",
    "#     'user': 'postgres',\n",
    "#     'password': '%40dmin**%40%402025'  # URL-encoded password\n",
    "# }\n",
    "\n",
    "# Option 1: Load directly from database with sampling\n",
    "# Adjust sample_size based on your machine's memory capacity\n",
    "# data = load_system_metrics(db_config=db_config, sample_size=2000, data_source=\"db\")\n",
    "\n",
    "# Option 2: Load from JSON files (if you've exported your data to JSON)\n",
    "# data = load_from_json()\n",
    "\n",
    "# Option 3: Use sample data (for testing)\n",
    "# data = load_system_metrics(use_sample_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6deeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmpath = \"D:\\\\projet\\\\migration_data\\\\vmstat_metrics.json\"\n",
    "iopath = \"D:\\\\projet\\\\migration_data\\\\iostat_metrics.json\"\n",
    "netpath = \"D:\\\\projet\\\\migration_data\\\\netstat_metrics.json\"\n",
    "propath = \"D:\\\\projet\\\\migration_data\\\\process_metrics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0972c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON first, then rename columns\n",
    "vmstat_df = pd.read_json(vmpath)\n",
    "iostat_df = pd.read_json(iopath)\n",
    "netstat_df = pd.read_json(netpath)\n",
    "process_df = pd.read_json(propath)\n",
    "vmstat_df.columns = [\n",
    "    'timestamp', \n",
    "    'r', \n",
    "    'b', \n",
    "    'avm', \n",
    "    'fre', \n",
    "    'pi',\n",
    "    'po',\n",
    "    'fr',\n",
    "    'in',\n",
    "    'cs',\n",
    "    'us', \n",
    "    'sy', \n",
    "    'idle'\n",
    "]\n",
    "iostat_df.columns = [\n",
    "    'timestamp', \n",
    "    'disk', \n",
    "    'tps', \n",
    "    'kB_read', \n",
    "    'kB_wrtn', \n",
    "    'service_time'\n",
    "]\n",
    "netstat_df.columns = [\n",
    "    'timestamp', \n",
    "    'interface', \n",
    "    'ipkts', \n",
    "    'ierrs',\n",
    "    'opkts',\n",
    "    'oerrs', \n",
    "    'coll'\n",
    "]\n",
    "process_df.columns = [\n",
    "    'timestamp', \n",
    "    'user',\n",
    "    'pid', \n",
    "    'cpu', \n",
    "    'mem', \n",
    "    'command',\n",
    "    'do notknow',\n",
    "    'donotknow2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511f6323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>disk</th>\n",
       "      <th>tps</th>\n",
       "      <th>kB_read</th>\n",
       "      <th>kB_wrtn</th>\n",
       "      <th>service_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-21T13:30:05.498549</td>\n",
       "      <td>hdisk3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-21T13:30:05.498549</td>\n",
       "      <td>hdisk2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-21T13:30:05.498549</td>\n",
       "      <td>hdisk1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-21T13:30:05.498549</td>\n",
       "      <td>hdisk0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>144</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-21T13:30:11.566351</td>\n",
       "      <td>hdisk3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp    disk  tps  kB_read  kB_wrtn  service_time\n",
       "0  2025-03-21T13:30:05.498549  hdisk3  0.0        0        0             0\n",
       "1  2025-03-21T13:30:05.498549  hdisk2  0.0        0        0             0\n",
       "2  2025-03-21T13:30:05.498549  hdisk1  0.0        0        0             0\n",
       "3  2025-03-21T13:30:05.498549  hdisk0  3.0      144       36             0\n",
       "4  2025-03-21T13:30:11.566351  hdisk3  0.0        0        0             0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iostat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec841c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "      <th>avm</th>\n",
       "      <th>fre</th>\n",
       "      <th>pi</th>\n",
       "      <th>po</th>\n",
       "      <th>fr</th>\n",
       "      <th>in</th>\n",
       "      <th>cs</th>\n",
       "      <th>us</th>\n",
       "      <th>sy</th>\n",
       "      <th>idle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-21T13:30:05.498549</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>52546.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-21T13:30:11.566351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>61322.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-21T13:30:18.075893</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>65857.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-21T13:30:23.467769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>59241.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-21T13:30:28.041217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>59518.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp  r  b  avm  fre  pi  po  fr  in  cs       us  \\\n",
       "0  2025-03-21T13:30:05.498549  3  0    0    0   0   0   0   0  66  52546.0   \n",
       "1  2025-03-21T13:30:11.566351  0  0    0    0   0   0   0   0  43  61322.0   \n",
       "2  2025-03-21T13:30:18.075893  2  0    0    0   0   0   0   0  36  65857.0   \n",
       "3  2025-03-21T13:30:23.467769  0  0    0    0   0   0   0   0  37  59241.0   \n",
       "4  2025-03-21T13:30:28.041217  1  0    0    0   0   0   0   0  47  59518.0   \n",
       "\n",
       "     sy  idle  \n",
       "0  27.0  46.0  \n",
       "1  22.0  44.0  \n",
       "2  21.0  43.0  \n",
       "3  21.0  43.0  \n",
       "4  21.0  43.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmstat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0993c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>interface</th>\n",
       "      <th>ipkts</th>\n",
       "      <th>ierrs</th>\n",
       "      <th>opkts</th>\n",
       "      <th>oerrs</th>\n",
       "      <th>coll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-24T09:48:02.535188</td>\n",
       "      <td>en0</td>\n",
       "      <td>384380616</td>\n",
       "      <td>0</td>\n",
       "      <td>586361020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-24T09:48:02.535188</td>\n",
       "      <td>en0</td>\n",
       "      <td>384380616</td>\n",
       "      <td>0</td>\n",
       "      <td>586361020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-24T09:48:02.535188</td>\n",
       "      <td>lo0</td>\n",
       "      <td>4302493</td>\n",
       "      <td>0</td>\n",
       "      <td>4302493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-24T09:48:07.828480</td>\n",
       "      <td>en0</td>\n",
       "      <td>384380685</td>\n",
       "      <td>0</td>\n",
       "      <td>586361096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-24T09:48:07.828480</td>\n",
       "      <td>en0</td>\n",
       "      <td>384380685</td>\n",
       "      <td>0</td>\n",
       "      <td>586361096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp interface      ipkts  ierrs      opkts  oerrs  \\\n",
       "0  2025-03-24T09:48:02.535188       en0  384380616      0  586361020      0   \n",
       "1  2025-03-24T09:48:02.535188       en0  384380616      0  586361020      0   \n",
       "2  2025-03-24T09:48:02.535188       lo0    4302493      0    4302493      0   \n",
       "3  2025-03-24T09:48:07.828480       en0  384380685      0  586361096      0   \n",
       "4  2025-03-24T09:48:07.828480       en0  384380685      0  586361096      0   \n",
       "\n",
       "   coll  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netstat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8898ebbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>pid</th>\n",
       "      <th>cpu</th>\n",
       "      <th>mem</th>\n",
       "      <th>command</th>\n",
       "      <th>do notknow</th>\n",
       "      <th>donotknow2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-14T12:10:12.359560</td>\n",
       "      <td>11338124</td>\n",
       "      <td>root</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>59002:32 sudo vi /etc/g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-14T12:10:12.359560</td>\n",
       "      <td>1048872</td>\n",
       "      <td>root</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>28819:44 wait</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-14T12:10:12.359560</td>\n",
       "      <td>983334</td>\n",
       "      <td>root</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>28803:30 wait</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-14T12:10:12.359560</td>\n",
       "      <td>917796</td>\n",
       "      <td>root</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>21866:59 wait</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-14T12:10:12.359560</td>\n",
       "      <td>7274790</td>\n",
       "      <td>root</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>18881:29 vi /etc/group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp      user   pid  cpu  mem  \\\n",
       "0  2025-04-14T12:10:12.359560  11338124  root  5.2    0   \n",
       "1  2025-04-14T12:10:12.359560   1048872  root  2.3    0   \n",
       "2  2025-04-14T12:10:12.359560    983334  root  2.3    0   \n",
       "3  2025-04-14T12:10:12.359560    917796  root  1.8    0   \n",
       "4  2025-04-14T12:10:12.359560   7274790  root  1.7    0   \n",
       "\n",
       "                   command  do notknow  donotknow2  \n",
       "0  59002:32 sudo vi /etc/g         NaN         NaN  \n",
       "1            28819:44 wait         NaN         NaN  \n",
       "2            28803:30 wait         NaN         NaN  \n",
       "3            21866:59 wait         NaN         NaN  \n",
       "4  18881:29 vi /etc/group          NaN         NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e3de0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis on system metrics\n",
    "    \"\"\"\n",
    "    print(\"Data shape:\", df.shape)\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(\"\\nBasic statistics:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    # Missing values check\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"\\nNo missing values found\")\n",
    "    \n",
    "    # # Distribution of states (classification target)\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # sns.countplot(x='state', data=df)\n",
    "    # plt.title('Distribution of System States')\n",
    "    # plt.xlabel('State (0: Normal, 1: High Load, 2: Critical)')\n",
    "    # plt.ylabel('Count')\n",
    "    # plt.show()\n",
    "    \n",
    "    # Time series plot of key metrics\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # CPU metrics\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(df['timestamp'], df['us'], label='User CPU')\n",
    "    plt.plot(df['timestamp'], df['sy'], label='System CPU')\n",
    "    plt.plot(df['timestamp'], df['idle'], label='Idle CPU')\n",
    "    plt.title('CPU Metrics Over Time')\n",
    "    plt.ylabel('CPU Usage (0-1)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Memory metrics\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(df['timestamp'], df['avm'], label='Active Virtual Memory')\n",
    "    plt.plot(df['timestamp'], df['fre'], label='Free Memory')\n",
    "    plt.title('Memory Metrics Over Time')\n",
    "    plt.ylabel('Memory (MB)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Process metrics\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(df['timestamp'], df['r'], label='Runnable Processes')\n",
    "    plt.plot(df['timestamp'], df['b'], label='Blocked Processes')\n",
    "    plt.title('Process Metrics Over Time')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # # Correlation matrix\n",
    "    # plt.figure(figsize=(14, 12))\n",
    "    # numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    # corr_matrix = df[numeric_cols].corr()\n",
    "    # sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    # plt.title('Correlation Matrix of System Metrics')\n",
    "    # plt.xticks(rotation=45, ha='right')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    # Feature distributions by state\n",
    "    # key_metrics = ['us', 'sy', 'idle', 'r', 'avm', 'fre']\n",
    "    # plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # for i, metric in enumerate(key_metrics):\n",
    "    #     plt.subplot(3, 2, i+1)\n",
    "    #     for state in sorted(df['state'].unique()):\n",
    "    #         sns.kdeplot(df[df['state'] == state][metric], label=f'State {state}')\n",
    "    #     plt.title(f'Distribution of {metric} by State')\n",
    "    #     plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (227778, 13)\n",
      "\n",
      "Data types:\n",
      "timestamp     object\n",
      "r              int64\n",
      "b              int64\n",
      "avm            int64\n",
      "fre            int64\n",
      "pi             int64\n",
      "po             int64\n",
      "fr             int64\n",
      "in             int64\n",
      "cs             int64\n",
      "us           float64\n",
      "sy           float64\n",
      "idle         float64\n",
      "dtype: object\n",
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "      <th>avm</th>\n",
       "      <th>fre</th>\n",
       "      <th>pi</th>\n",
       "      <th>po</th>\n",
       "      <th>fr</th>\n",
       "      <th>in</th>\n",
       "      <th>cs</th>\n",
       "      <th>us</th>\n",
       "      <th>sy</th>\n",
       "      <th>idle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>227778.000000</td>\n",
       "      <td>227778.000000</td>\n",
       "      <td>227778.0</td>\n",
       "      <td>227778.0</td>\n",
       "      <td>227778.0</td>\n",
       "      <td>227778.000000</td>\n",
       "      <td>227778.000000</td>\n",
       "      <td>227778.0</td>\n",
       "      <td>227778.000000</td>\n",
       "      <td>227778.000000</td>\n",
       "      <td>227778.000000</td>\n",
       "      <td>227778.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.658128</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.479594</td>\n",
       "      <td>16.577497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.802751</td>\n",
       "      <td>131.350830</td>\n",
       "      <td>23.787323</td>\n",
       "      <td>42.676689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.016620</td>\n",
       "      <td>0.029619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>478.674670</td>\n",
       "      <td>1027.290341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.369689</td>\n",
       "      <td>2099.161786</td>\n",
       "      <td>8.872937</td>\n",
       "      <td>3.320829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>14.126000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>60.364000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>63.411000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>65.818000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93102.000000</td>\n",
       "      <td>161909.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14936.000000</td>\n",
       "      <td>71396.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   r              b       avm       fre        pi  \\\n",
       "count  227778.000000  227778.000000  227778.0  227778.0  227778.0   \n",
       "mean        1.658128       0.000869       0.0       0.0       0.0   \n",
       "std         1.016620       0.029619       0.0       0.0       0.0   \n",
       "min         0.000000       0.000000       0.0       0.0       0.0   \n",
       "25%         1.000000       0.000000       0.0       0.0       0.0   \n",
       "50%         2.000000       0.000000       0.0       0.0       0.0   \n",
       "75%         2.000000       0.000000       0.0       0.0       0.0   \n",
       "max        10.000000       2.000000       0.0       0.0       0.0   \n",
       "\n",
       "                  po             fr        in             cs             us  \\\n",
       "count  227778.000000  227778.000000  227778.0  227778.000000  227778.000000   \n",
       "mean        9.479594      16.577497       0.0      55.802751     131.350830   \n",
       "std       478.674670    1027.290341       0.0     139.369689    2099.161786   \n",
       "min         0.000000       0.000000       0.0      31.000000      14.126000   \n",
       "25%         0.000000       0.000000       0.0      37.000000      60.364000   \n",
       "50%         0.000000       0.000000       0.0      41.000000      63.411000   \n",
       "75%         0.000000       0.000000       0.0      47.000000      65.818000   \n",
       "max     93102.000000  161909.000000       0.0   14936.000000   71396.000000   \n",
       "\n",
       "                  sy           idle  \n",
       "count  227778.000000  227778.000000  \n",
       "mean       23.787323      42.676689  \n",
       "std         8.872937       3.320829  \n",
       "min         0.020000       0.043000  \n",
       "25%        21.000000      43.000000  \n",
       "50%        21.000000      43.000000  \n",
       "75%        21.000000      44.000000  \n",
       "max        90.000000      89.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No missing values found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mperform_eda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmstat_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mperform_eda\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     53\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mCount\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     54\u001b[39m plt.legend()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtight_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m plt.show()\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# # Correlation matrix\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# plt.figure(figsize=(14, 12))\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# numeric_cols = df.select_dtypes(include=np.number).columns\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m \u001b[38;5;66;03m#     plt.title(f'Distribution of {metric} by State')\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m#     plt.legend()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\pyplot.py:2844\u001b[39m, in \u001b[36mtight_layout\u001b[39m\u001b[34m(pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m   2836\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure.tight_layout)\n\u001b[32m   2837\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtight_layout\u001b[39m(\n\u001b[32m   2838\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2842\u001b[39m     rect: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2843\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m     \u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtight_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrect\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\figure.py:3640\u001b[39m, in \u001b[36mFigure.tight_layout\u001b[39m\u001b[34m(self, pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m   3638\u001b[39m previous_engine = \u001b[38;5;28mself\u001b[39m.get_layout_engine()\n\u001b[32m   3639\u001b[39m \u001b[38;5;28mself\u001b[39m.set_layout_engine(engine)\n\u001b[32m-> \u001b[39m\u001b[32m3640\u001b[39m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m previous_engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3642\u001b[39m     previous_engine, (TightLayoutEngine, PlaceHolderLayoutEngine)\n\u001b[32m   3643\u001b[39m ):\n\u001b[32m   3644\u001b[39m     _api.warn_external(\u001b[33m'\u001b[39m\u001b[33mThe figure layout has changed to tight\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\layout_engine.py:188\u001b[39m, in \u001b[36mTightLayoutEngine.execute\u001b[39m\u001b[34m(self, fig)\u001b[39m\n\u001b[32m    186\u001b[39m renderer = fig._get_renderer()\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[33m\"\u001b[39m\u001b[33m_draw_disabled\u001b[39m\u001b[33m\"\u001b[39m, nullcontext)():\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     kwargs = \u001b[43mget_tight_layout_figure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_subplotspec_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mh_pad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw_pad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrect\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m    193\u001b[39m     fig.subplots_adjust(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\_tight_layout.py:266\u001b[39m, in \u001b[36mget_tight_layout_figure\u001b[39m\u001b[34m(fig, axes_list, subplotspec_list, renderer, pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m    261\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m    262\u001b[39m     span_pairs.append((\n\u001b[32m    263\u001b[39m         \u001b[38;5;28mslice\u001b[39m(ss.rowspan.start * div_row, ss.rowspan.stop * div_row),\n\u001b[32m    264\u001b[39m         \u001b[38;5;28mslice\u001b[39m(ss.colspan.start * div_col, ss.colspan.stop * div_col)))\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m kwargs = \u001b[43m_auto_adjust_subplotpars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_nrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ncols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mspan_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspan_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43msubplot_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubplot_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43max_bbox_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43max_bbox_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_pad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m# kwargs can be none if tight_layout fails...\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# if rect is given, the whole subplots area (including\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# labels) will fit into the rect instead of the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# auto_adjust_subplotpars twice, where the second run\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# with adjusted rect parameters.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\_tight_layout.py:82\u001b[39m, in \u001b[36m_auto_adjust_subplotpars\u001b[39m\u001b[34m(fig, renderer, shape, span_pairs, subplot_list, ax_bbox_list, pad, h_pad, w_pad, rect)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m subplots:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ax.get_visible():\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         bb += [\u001b[43mmartist\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_tightbbox_for_layout_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     84\u001b[39m tight_bbox_raw = Bbox.union(bb)\n\u001b[32m     85\u001b[39m tight_bbox = fig.transFigure.inverted().transform_bbox(tight_bbox_raw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\artist.py:1402\u001b[39m, in \u001b[36m_get_tightbbox_for_layout_only\u001b[39m\u001b[34m(obj, *args, **kwargs)\u001b[39m\n\u001b[32m   1396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1397\u001b[39m \u001b[33;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[32m   1398\u001b[39m \u001b[33;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[32m   1399\u001b[39m \u001b[33;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[32m   1400\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfor_layout_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1404\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.get_tightbbox(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axes\\_base.py:4554\u001b[39m, in \u001b[36m_AxesBase.get_tightbbox\u001b[39m\u001b[34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[39m\n\u001b[32m   4552\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._axis_map.values():\n\u001b[32m   4553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axison \u001b[38;5;129;01mand\u001b[39;00m axis.get_visible():\n\u001b[32m-> \u001b[39m\u001b[32m4554\u001b[39m         ba = \u001b[43mmartist\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_tightbbox_for_layout_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4555\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ba:\n\u001b[32m   4556\u001b[39m             bb.append(ba)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\artist.py:1402\u001b[39m, in \u001b[36m_get_tightbbox_for_layout_only\u001b[39m\u001b[34m(obj, *args, **kwargs)\u001b[39m\n\u001b[32m   1396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1397\u001b[39m \u001b[33;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[32m   1398\u001b[39m \u001b[33;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[32m   1399\u001b[39m \u001b[33;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[32m   1400\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfor_layout_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1404\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.get_tightbbox(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axis.py:1351\u001b[39m, in \u001b[36mAxis.get_tightbbox\u001b[39m\u001b[34m(self, renderer, for_layout_only)\u001b[39m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1350\u001b[39m     renderer = \u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m)._get_renderer()\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m ticks_to_draw = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[38;5;28mself\u001b[39m._update_label_position(renderer)\n\u001b[32m   1355\u001b[39m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axis.py:1283\u001b[39m, in \u001b[36mAxis._update_ticks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1281\u001b[39m major_locs = \u001b[38;5;28mself\u001b[39m.get_majorticklocs()\n\u001b[32m   1282\u001b[39m major_labels = \u001b[38;5;28mself\u001b[39m.major.formatter.format_ticks(major_locs)\n\u001b[32m-> \u001b[39m\u001b[32m1283\u001b[39m major_ticks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmajor_locs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick, loc, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(major_ticks, major_locs, major_labels):\n\u001b[32m   1285\u001b[39m     tick.update_position(loc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axis.py:1664\u001b[39m, in \u001b[36mAxis.get_major_ticks\u001b[39m\u001b[34m(self, numticks)\u001b[39m\n\u001b[32m   1660\u001b[39m     numticks = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_majorticklocs())\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.majorTicks) < numticks:\n\u001b[32m   1663\u001b[39m     \u001b[38;5;66;03m# Update the new tick label properties from the old.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1664\u001b[39m     tick = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1665\u001b[39m     \u001b[38;5;28mself\u001b[39m.majorTicks.append(tick)\n\u001b[32m   1666\u001b[39m     \u001b[38;5;28mself\u001b[39m._copy_tick_props(\u001b[38;5;28mself\u001b[39m.majorTicks[\u001b[32m0\u001b[39m], tick)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axis.py:1592\u001b[39m, in \u001b[36mAxis._get_tick\u001b[39m\u001b[34m(self, major)\u001b[39m\n\u001b[32m   1588\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1589\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe Axis subclass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must define \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1590\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_tick_class or reimplement _get_tick()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1591\u001b[39m tick_kw = \u001b[38;5;28mself\u001b[39m._major_tick_kw \u001b[38;5;28;01mif\u001b[39;00m major \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._minor_tick_kw\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tick_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtick_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axis.py:368\u001b[39m, in \u001b[36mXTick.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m     \u001b[38;5;66;03m# x in data coords, y in axes coords\u001b[39;00m\n\u001b[32m    370\u001b[39m     ax = \u001b[38;5;28mself\u001b[39m.axes\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axis.py:181\u001b[39m, in \u001b[36mTick.__init__\u001b[39m\u001b[34m(self, axes, loc, size, width, color, tickdir, pad, labelsize, labelcolor, labelfontfamily, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kwargs)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.label1 = mtext.Text(\n\u001b[32m    173\u001b[39m     np.nan, np.nan,\n\u001b[32m    174\u001b[39m     fontsize=labelsize, color=labelcolor, visible=label1On,\n\u001b[32m    175\u001b[39m     fontfamily=labelfontfamily, rotation=\u001b[38;5;28mself\u001b[39m._labelrotation[\u001b[32m1\u001b[39m])\n\u001b[32m    176\u001b[39m \u001b[38;5;28mself\u001b[39m.label2 = mtext.Text(\n\u001b[32m    177\u001b[39m     np.nan, np.nan,\n\u001b[32m    178\u001b[39m     fontsize=labelsize, color=labelcolor, visible=label2On,\n\u001b[32m    179\u001b[39m     fontfamily=labelfontfamily, rotation=\u001b[38;5;28mself\u001b[39m._labelrotation[\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_tickdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m artist \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.tick1line, \u001b[38;5;28mself\u001b[39m.tick2line, \u001b[38;5;28mself\u001b[39m.gridline,\n\u001b[32m    184\u001b[39m                \u001b[38;5;28mself\u001b[39m.label1, \u001b[38;5;28mself\u001b[39m.label2]:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_artist_props(artist)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\axis.py:403\u001b[39m, in \u001b[36mXTick._apply_tickdir\u001b[39m\u001b[34m(self, tickdir)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28msuper\u001b[39m()._apply_tickdir(tickdir)\n\u001b[32m    398\u001b[39m mark1, mark2 = {\n\u001b[32m    399\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m: (mlines.TICKDOWN, mlines.TICKUP),\n\u001b[32m    400\u001b[39m     \u001b[33m'\u001b[39m\u001b[33min\u001b[39m\u001b[33m'\u001b[39m: (mlines.TICKUP, mlines.TICKDOWN),\n\u001b[32m    401\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minout\u001b[39m\u001b[33m'\u001b[39m: (\u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    402\u001b[39m }[\u001b[38;5;28mself\u001b[39m._tickdir]\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtick1line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmark1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28mself\u001b[39m.tick2line.set_marker(mark2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\lines.py:1214\u001b[39m, in \u001b[36mLine2D.set_marker\u001b[39m\u001b[34m(self, marker)\u001b[39m\n\u001b[32m   1203\u001b[39m \u001b[38;5;129m@_docstring\u001b[39m.interpd\n\u001b[32m   1204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_marker\u001b[39m(\u001b[38;5;28mself\u001b[39m, marker):\n\u001b[32m   1205\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1206\u001b[39m \u001b[33;03m    Set the line marker.\u001b[39;00m\n\u001b[32m   1207\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1212\u001b[39m \u001b[33;03m        arguments.\u001b[39;00m\n\u001b[32m   1213\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1214\u001b[39m     \u001b[38;5;28mself\u001b[39m._marker = MarkerStyle(marker, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_marker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_fillstyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1215\u001b[39m     \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projet\\venv\\Lib\\site-packages\\matplotlib\\markers.py:272\u001b[39m, in \u001b[36mMarkerStyle.get_fillstyle\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_filled\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._filled\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_fillstyle\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fillstyle\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_fillstyle\u001b[39m(\u001b[38;5;28mself\u001b[39m, fillstyle):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to create process using 'd:\\projet\\venv\\Scripts\\python.exe -m ipykernel_launcher --f=c:\\Users\\isarhrany\\AppData\\Roaming\\jupyter\\runtime\\kernel-v363ec5100ed13d733b39f8b30b97116bdc49d5ec4.json': Impossible d?acc�der au disque ou � la disquette sp�cifi�. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "perform_eda(vmstat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
