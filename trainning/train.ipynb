{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "078a8b14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m      1\u001b[39m {\n\u001b[32m      2\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mcells\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m     {\n\u001b[32m      4\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1566b4c7\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1566b4c7\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m       },\n\u001b[32m      9\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m     10\u001b[39m     },\n\u001b[32m     11\u001b[39m     {\n\u001b[32m     12\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Library Imports\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m       ],\n\u001b[32m     16\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muCSRIld0tnWz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m       },\n\u001b[32m     19\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muCSRIld0tnWz\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m     },\n\u001b[32m     21\u001b[39m     {\n\u001b[32m     22\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     24\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# !pip install pytorch_forecasting polars\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m       ],\n\u001b[32m     26\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mKGhO5A8QnQop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m       },\n\u001b[32m     29\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mKGhO5A8QnQop\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[32m     31\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m     32\u001b[39m     },\n\u001b[32m     33\u001b[39m     {\n\u001b[32m     34\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport polars as pl\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom sklearn.preprocessing import StandardScaler, RobustScaler\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom sklearn.ensemble import IsolationForest\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom sklearn.svm import OneClassSVM\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom sklearn.model_selection import train_test_split\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom sklearn.metrics import precision_recall_fscore_support, mean_absolute_error\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport tensorflow as tf\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom tensorflow.keras.models import Sequential, Model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Input, RepeatVector, TimeDistributed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     47\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom tensorflow.keras.optimizers import Adam\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     48\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom statsmodels.tsa.arima.model import ARIMA\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     49\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     50\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfrom prophet import Prophet\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     51\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport warnings\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimport sys\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwarnings.filterwarnings(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m       ],\n\u001b[32m     55\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     56\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mabb6PFxrmGk3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m       },\n\u001b[32m     58\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mabb6PFxrmGk3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m     60\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m     61\u001b[39m     },\n\u001b[32m     62\u001b[39m     {\n\u001b[32m     63\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass DataProcessor:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.scalers = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feature_columns = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.temporal_features = [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhour\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mday_of_week\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mday_of_month\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mis_weekend\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.target_columns = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_temporal_features(self, df):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mCreate time-based features (optimized)\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = df.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhour\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].dt.hour\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     76\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mday_of_week\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].dt.dayofweek\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mday_of_month\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].dt.day\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis_weekend\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = (df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mday_of_week\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] >= 5).astype(int)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     79\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return df\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     80\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     81\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_statistical_features(self, df, window_sizes=[5]):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     82\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mOptimized rolling features with minimal windows\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = df.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     84\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Only process target columns and key metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     85\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        numeric_cols = self.target_columns + [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mavm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfre\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33min\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        numeric_cols = [col for col in numeric_cols if col in df.columns]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for window in window_sizes:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            for col in numeric_cols:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     90\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                # Only calculate rolling mean (skip std/max)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     91\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                df[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{col}\u001b[39;00m\u001b[33m_rolling_mean_\u001b[39m\u001b[38;5;132;01m{window}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m] = df.groupby(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)[col].transform(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     92\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    lambda x: x.rolling(window, min_periods=1).mean()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     93\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     94\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return df.fillna(0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     95\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     96\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_cross_metric_features(self, df):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mOptimized cross-metric features\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     98\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = df.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmem_mean\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    100\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu_mem_ratio\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] / (df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmem_mean\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + 1e-6)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mkb_read\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mkb_wrtn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtps\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mio_efficiency\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = (df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mkb_read\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mkb_wrtn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]) / (df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtps\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + 1e-6)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mipkts_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mopkts_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mierrs_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33moerrs_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    104\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnet_error_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = (df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mierrs_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33moerrs_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]) / (df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mipkts_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mopkts_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + 1e-6)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33msy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in df:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33msystem_load\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33msy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] + (df[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] * 10)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return df.fillna(0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def detect_and_handle_outliers(self, df):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mOptimized outlier handling for target columns only\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    111\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = df.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    112\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for col in self.target_columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if col not in df.columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                continue\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Vectorized IQR calculation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            q1 = df[col].quantile(0.25)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            q3 = df[col].quantile(0.75)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            iqr = q3 - q1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            lower_bound = q1 - 1.5 * iqr\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    120\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            upper_bound = q3 + 1.5 * iqr\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            df[col] = df[col].clip(lower_bound, upper_bound)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return df\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    124\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def normalize_features(self, df, method=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrobust\u001b[39m\u001b[33m'\u001b[39m\u001b[33m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mOptimized normalization\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = df.copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        numeric_cols = df.select_dtypes(include=[np.number]).columns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        numeric_cols = [col for col in numeric_cols if col not in [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhour\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mday_of_week\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mday_of_month\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mis_weekend\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    129\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    130\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if method == \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrobust\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    131\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            scaler = RobustScaler()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    132\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    133\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            scaler = StandardScaler()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    134\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    135\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    136\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.scalers[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmain_scaler\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = scaler\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    137\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feature_columns = numeric_cols\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return df\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    141\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def process_data(self, merged_df, target_columns):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    142\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mOptimized processing pipeline\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    143\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Validate target columns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        valid_columns = [col for col in target_columns if col in merged_df.columns]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    145\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        missing = set(target_columns) - set(valid_columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    147\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if missing:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mWarning: Missing target columns: \u001b[39m\u001b[38;5;132;01m{missing}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    149\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    150\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.target_columns = valid_columns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = self.create_temporal_features(merged_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    152\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = self.create_statistical_features(df, window_sizes=[5])  # Single window size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = self.create_cross_metric_features(df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = self.detect_and_handle_outliers(df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = self.normalize_features(df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return df\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m       ],\n\u001b[32m    158\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mXquWKbn9mHAN\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m       },\n\u001b[32m    161\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mXquWKbn9mHAN\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    162\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    163\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m    164\u001b[39m     },\n\u001b[32m    165\u001b[39m     {\n\u001b[32m    166\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    167\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    168\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass ForecastingEngine:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    Multi-model forecasting engine with ensemble capabilities\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    172\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self, sequence_length=50):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    174\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.sequence_length = sequence_length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    175\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.models = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    176\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.model_weights = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    177\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feature_columns = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    178\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    179\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_lstm_model(self, input_shape, horizon=24):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Create LSTM model for long-term forecasting\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    183\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        model = Sequential([\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    184\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            LSTM(128, return_sequences=True, input_shape=input_shape),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    185\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            Dropout(0.2),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    186\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            LSTM(64, return_sequences=True),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            Dropout(0.2),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    188\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            LSTM(32, return_sequences=False),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    189\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            Dropout(0.2),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    190\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            Dense(horizon)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        ])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    193\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        model.compile(optimizer=Adam(learning_rate=0.001), loss=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, metrics=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmae\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    194\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    195\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    196\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_transformer_model(self, input_shape, horizon=12):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    197\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    198\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Create Transformer model for medium-term forecasting\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    199\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    200\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        inputs = Input(shape=input_shape)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    201\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Multi-head attention\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        attention = tf.keras.layers.MultiHeadAttention(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    204\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            num_heads=8, key_dim=64\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )(inputs, inputs)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    207\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Add & Norm\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        attention = tf.keras.layers.LayerNormalization()(inputs + attention)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Feed Forward\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        ff = tf.keras.layers.Dense(128, activation=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)(attention)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    212\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        ff = tf.keras.layers.Dense(input_shape[-1])(ff)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    213\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    214\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Add & Norm\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        output = tf.keras.layers.LayerNormalization()(attention + ff)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Output layer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        output = tf.keras.layers.GlobalAveragePooling1D()(output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    219\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        output = tf.keras.layers.Dense(horizon)(output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        model = Model(inputs=inputs, outputs=output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        model.compile(optimizer=Adam(learning_rate=0.001), loss=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, metrics=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmae\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_sequences(self, data, target_col, horizon=1):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    228\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Create sequences for time series models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    229\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    230\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        X, y = [], []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        max_start = len(data) - self.sequence_length - horizon\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    232\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if max_start < 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Pad with zeros if insufficient data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    235\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            padded = np.pad(data, ((0, -max_start), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    236\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            X.append(padded[:self.sequence_length])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    237\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            y.append(padded[self.sequence_length:self.sequence_length + horizon, target_col])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    238\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    239\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            for i in range(max_start + 1):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    240\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                X.append(data[i:(i + self.sequence_length)])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    241\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                y.append(data[i + self.sequence_length:i + self.sequence_length + horizon, target_col])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    242\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    243\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return np.array(X), np.array(y)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def fit_arima_model(self, series, order=(5, 1, 0), seasonal_order=(1, 1, 1, 24)):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    247\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Fit ARIMA model for short-term forecasting\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    248\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    249\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    250\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            model = ARIMA(series, order=order, seasonal_order=seasonal_order)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    251\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            fitted_model = model.fit()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    252\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return fitted_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    253\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        except Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mARIMA failed: \u001b[39m\u001b[33m{\u001b[39m\u001b[33mstr(e)}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    255\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Fallback to simple exponential smoothing\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    256\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            model = SimpleExpSmoothing(series)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            fitted_model = model.fit()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    258\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return fitted_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    260\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def fit_prophet_model(self, df, target_col):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    261\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    262\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Fit Prophet model for long-term forecasting with seasonality\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    263\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    264\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        prophet_df = df[[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, target_col]].copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    265\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        prophet_df.columns = [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mds\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    266\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    267\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        model = Prophet(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    268\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            yearly_seasonality=True,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    269\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            weekly_seasonality=True,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    270\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            daily_seasonality=True,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    271\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            changepoint_prior_scale=0.05\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    272\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    273\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    274\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        model.fit(prophet_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    275\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    276\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    277\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def train_ensemble(self, df, target_columns):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    278\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    279\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Train all forecasting models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    280\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feature_columns = [col for col in df.columns if col not in [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    282\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    283\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for target_col in target_columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    284\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mTraining models for \u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    285\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    286\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Prepare data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            numeric_data = df[self.feature_columns].values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            target_idx = self.feature_columns.index(target_col)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Create sequences\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    291\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            X_lstm, y_lstm_24 = self.create_sequences(numeric_data, target_idx, horizon=24)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    292\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            X_trans, y_trans_12 = self.create_sequences(numeric_data, target_idx, horizon=12)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    293\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    294\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Split data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    295\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            split_idx = int(0.8 * len(X_lstm))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    296\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            X_train_lstm, X_test_lstm = X_lstm[:split_idx], X_lstm[split_idx:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    297\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            y_train_lstm, y_test_lstm = y_lstm_24[:split_idx], y_lstm_24[split_idx:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    298\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    299\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Train LSTM\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    300\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            lstm_model = self.create_lstm_model(X_train_lstm.shape[1:], horizon=24)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    301\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, verbose=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    302\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_lstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = lstm_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    303\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Train Transformer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if len(X_trans) > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                trans_model = self.create_transformer_model(X_trans.shape[1:], horizon=12)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                X_train_trans = X_trans[:int(0.8 * len(X_trans))]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    308\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                y_train_trans = y_trans_12[:int(0.8 * len(y_trans_12))]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    309\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                trans_model.fit(X_train_trans, y_train_trans, epochs=30, batch_size=32, verbose=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_transformer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = trans_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    311\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    312\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Train ARIMA\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            series = df[target_col].values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    314\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            arima_model = self.fit_arima_model(series)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    315\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_arima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = arima_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    316\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    317\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Train Prophet\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    318\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            prophet_model = self.fit_prophet_model(df, target_col)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_prophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = prophet_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Initialize equal weights\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.model_weights[target_col] = \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.25, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtransformer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.25, \u001b[39m\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.25, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.25}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def predict(self, df, target_col, horizon=24):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    325\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    326\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Generate ensemble predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        predictions = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    329\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    330\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # LSTM prediction\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_lstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.models:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            numeric_data = df[self.feature_columns].values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    333\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if len(numeric_data) >= self.sequence_length:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    334\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                X_pred = numeric_data[-self.sequence_length:].reshape(1, self.sequence_length, -1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    335\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                lstm_pred = self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_lstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].predict(X_pred, verbose=0)[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                predictions[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = lstm_pred[:horizon]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    337\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    338\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # ARIMA prediction\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_arima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.models:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                arima_pred = self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_arima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].forecast(steps=horizon)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    342\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                predictions[\u001b[39m\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = arima_pred\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            except:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                predictions[\u001b[39m\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = np.full(horizon, df[target_col].iloc[-1])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Prophet prediction\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    347\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_prophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.models:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    348\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            future = self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_prophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].make_future_dataframe(periods=horizon, freq=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mH\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    349\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            prophet_pred = self.models[f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m_prophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].predict(future)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    350\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            predictions[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = prophet_pred[\u001b[39m\u001b[33m'\u001b[39m\u001b[33myhat\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].tail(horizon).values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    351\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Ensemble prediction\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    353\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if predictions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    354\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            weights = self.model_weights.get(target_col, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            ensemble_pred = np.zeros(horizon)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    356\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            total_weight = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    357\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            for model_name, pred in predictions.items():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                if len(pred) == horizon:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    360\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    weight = weights.get(model_name, 0.25)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    ensemble_pred += pred * weight\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    362\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    total_weight += weight\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    363\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if total_weight > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    365\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                ensemble_pred /= total_weight\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    367\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return ensemble_pred, predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    368\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return None, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    370\u001b[39m       ],\n\u001b[32m    371\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    372\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mvklvAK7SmKhV\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    373\u001b[39m       },\n\u001b[32m    374\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mvklvAK7SmKhV\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    375\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    376\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m    377\u001b[39m     },\n\u001b[32m    378\u001b[39m     {\n\u001b[32m    379\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    380\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    381\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass AnomalyDetector:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    382\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    383\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    Multi-method anomaly detection framework\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    384\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    385\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    386\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self, sequence_length=50):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    387\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.sequence_length = sequence_length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    388\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.models = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    389\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.thresholds = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    390\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.3,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    391\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.5,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    392\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.7,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    393\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcritical\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.9\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feature_columns = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    397\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_lstm_autoencoder(self, input_shape):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    398\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Create LSTM Autoencoder for sequential anomaly detection\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    401\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Encoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    402\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        encoder_inputs = Input(shape=input_shape)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    403\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        encoder = LSTM(64, return_sequences=True)(encoder_inputs)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    404\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        encoder = LSTM(32, return_sequences=False)(encoder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    405\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    407\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        decoder = RepeatVector(input_shape[0])(encoder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    408\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        decoder = LSTM(32, return_sequences=True)(decoder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    409\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        decoder = LSTM(64, return_sequences=True)(decoder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    410\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        decoder_outputs = TimeDistributed(Dense(input_shape[1]))(decoder)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    412\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        autoencoder = Model(encoder_inputs, decoder_outputs)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    413\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    414\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    415\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return autoencoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    417\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def create_sequences_for_autoencoder(self, data):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    418\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    419\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Create sequences for autoencoder training\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    420\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    421\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        X = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    422\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for i in range(len(data) - self.sequence_length + 1):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    423\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            X.append(data[i:(i + self.sequence_length)])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    424\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return np.array(X)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    425\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    426\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def train_detectors(self, df, contamination=0.05):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    427\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    428\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Train all anomaly detection models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    429\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    430\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feature_columns = [col for col in df.columns if col not in [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    431\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        numeric_data = df[self.feature_columns].values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    433\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Train Isolation Forest\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    434\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        iso_forest = IsolationForest(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    435\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            contamination=contamination,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    436\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            n_estimators=100,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    437\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            random_state=42\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    438\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    439\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        iso_forest.fit(numeric_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    440\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = iso_forest\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    441\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    442\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Train One-Class SVM\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    443\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        oc_svm = OneClassSVM(kernel=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrbf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, nu=contamination)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    444\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        oc_svm.fit(numeric_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    445\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33moneclass_svm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = oc_svm\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    446\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    447\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Train LSTM Autoencoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    448\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        sequences = self.create_sequences_for_autoencoder(numeric_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    449\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if len(sequences) > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            autoencoder = self.create_lstm_autoencoder((self.sequence_length, len(self.feature_columns)))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    451\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            autoencoder.fit(sequences, sequences, epochs=50, batch_size=32, verbose=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    452\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = autoencoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    453\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    454\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Calculate reconstruction threshold\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    455\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            reconstructions = autoencoder.predict(sequences, verbose=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    456\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            mse = np.mean(np.power(sequences - reconstructions, 2), axis=(1, 2))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mreconstruction\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = np.percentile(mse, 95)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    458\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    459\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def detect_anomalies(self, df):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    460\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    461\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Detect anomalies using ensemble approach\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    462\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    463\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        numeric_data = df[self.feature_columns].values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    464\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        anomaly_scores = np.zeros(len(df))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    465\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        detection_details = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    466\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    467\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Isolation Forest\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    468\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.models:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    469\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            iso_scores = self.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].decision_function(numeric_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    470\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            iso_scores = (iso_scores - iso_scores.min()) / (iso_scores.max() - iso_scores.min())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    471\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            anomaly_scores += iso_scores * 0.33\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    472\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            detection_details[\u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = iso_scores\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    473\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # One-Class SVM\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    475\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33moneclass_svm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.models:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            svm_scores = self.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33moneclass_svm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].decision_function(numeric_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    477\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            svm_scores = (svm_scores - svm_scores.min()) / (svm_scores.max() - svm_scores.min())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    478\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            anomaly_scores += svm_scores * 0.33\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    479\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            detection_details[\u001b[39m\u001b[33m'\u001b[39m\u001b[33moneclass_svm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = svm_scores\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    480\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    481\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # LSTM Autoencoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    482\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.models and len(numeric_data) >= self.sequence_length:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    483\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            sequences = self.create_sequences_for_autoencoder(numeric_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if len(sequences) > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    485\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                reconstructions = self.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].predict(sequences, verbose=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    486\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                mse = np.mean(np.power(sequences - reconstructions, 2), axis=(1, 2))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    487\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    488\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                # Pad the scores to match original length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    489\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                ae_scores = np.zeros(len(numeric_data))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    490\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                ae_scores[self.sequence_length-1:] = mse\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    491\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                ae_scores = (ae_scores - ae_scores.min()) / (ae_scores.max() - ae_scores.min() + 1e-8)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    492\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                anomaly_scores += ae_scores * 0.34\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    493\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                detection_details[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = ae_scores\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    494\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    495\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Classify severity\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    496\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        severity = np.where(anomaly_scores >= self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcritical\u001b[39m\u001b[33m'\u001b[39m\u001b[33m], \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCritical\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    497\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                   np.where(anomaly_scores >= self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m], \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    498\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                   np.where(anomaly_scores >= self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m'\u001b[39m\u001b[33m], \u001b[39m\u001b[33m'\u001b[39m\u001b[33mMedium\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    499\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                   np.where(anomaly_scores >= self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m], \u001b[39m\u001b[33m'\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m\u001b[33m))))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return anomaly_scores, severity, detection_details\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def update_thresholds(self, feedback_data):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    505\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Adapt thresholds based on feedback\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    506\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    507\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # This would be implemented based on expert feedback\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    508\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # For now, we\u001b[39m\u001b[33m'\u001b[39m\u001b[33mll use a simple adaptive approach\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    509\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if len(feedback_data) > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            true_anomalies = feedback_data[feedback_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis_anomaly\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] == True][\u001b[39m\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    511\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if len(true_anomalies) > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    512\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = np.percentile(true_anomalies, 25)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = np.percentile(true_anomalies, 50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = np.percentile(true_anomalies, 75)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    515\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                self.thresholds[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcritical\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = np.percentile(true_anomalies, 90)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m       ],\n\u001b[32m    517\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    518\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mC7jCyoZKmN8_\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    519\u001b[39m       },\n\u001b[32m    520\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mC7jCyoZKmN8_\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    521\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    522\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m    523\u001b[39m     },\n\u001b[32m    524\u001b[39m     {\n\u001b[32m    525\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    526\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    527\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass ActiveLearningComponent:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    528\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    529\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    Active learning for continuous model improvement\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    530\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    531\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    532\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self, buffer_size=10000):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    533\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.buffer_size = buffer_size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    534\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.experience_buffer = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    535\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feedback_history = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.model_performance = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    538\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def collect_feedback(self, predictions, actual_values, expert_annotations=None):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    539\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    540\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Collect feedback from various sources\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    541\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    542\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        feedback = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    543\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: pd.Timestamp.now(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    544\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: predictions,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    545\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mactual_values\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: actual_values,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    546\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexpert_annotations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: expert_annotations,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    547\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: np.abs(predictions - actual_values) if actual_values is not None else None\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    548\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    549\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    550\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feedback_history.append(feedback)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    551\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    552\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Maintain buffer size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    553\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if len(self.feedback_history) > self.buffer_size:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    554\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.feedback_history = self.feedback_history[-self.buffer_size:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    555\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    556\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def select_samples_for_labeling(self, uncertainty_scores, n_samples=10):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    558\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Select most uncertain samples for expert labeling\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Select samples with highest uncertainty\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    561\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        uncertain_indices = np.argsort(uncertainty_scores)[-n_samples:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    562\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return uncertain_indices\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    563\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    564\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def update_models(self, forecasting_engine, anomaly_detector, new_data):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    565\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    566\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Incremental model updates using transfer learning\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    567\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    568\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # This would implement incremental learning\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # For now, we\u001b[39m\u001b[33m'\u001b[39m\u001b[33mll track performance and suggest retraining\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    570\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    571\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        current_performance = self.evaluate_model_performance(new_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    572\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    573\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if self.should_retrain(current_performance):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return True  # Signal for retraining\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    575\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return False\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    577\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    578\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def evaluate_model_performance(self, data):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Evaluate current model performance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Calculate performance metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    583\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        performance = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    584\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: pd.Timestamp.now(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.0,  # Would be calculated from actual vs predicted\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.0,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.0,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mf1_score\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: 0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    589\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    590\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    591\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.model_performance[performance[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]] = performance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    592\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return performance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    593\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def should_retrain(self, current_performance, threshold=0.8):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    595\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    596\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Decide if models need retraining\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    597\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    598\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if len(self.model_performance) < 2:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    599\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return False\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    600\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    601\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Compare with historical performance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    602\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        recent_performances = list(self.model_performance.values())[-5:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    603\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        avg_performance = np.mean([p[\u001b[39m\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] for p in recent_performances])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    604\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    605\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return current_performance[\u001b[39m\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] < avg_performance * threshold\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m       ],\n\u001b[32m    607\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    608\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mEW6z6m_0mPGe\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m       },\n\u001b[32m    610\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mEW6z6m_0mPGe\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    611\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    612\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m    613\u001b[39m     },\n\u001b[32m    614\u001b[39m     {\n\u001b[32m    615\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    616\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    617\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass ExplainableDecisionSupport:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    618\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    619\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    Provides explanations and decision support for predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    620\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    621\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    622\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    623\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.feature_importance = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    624\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.explanation_templates = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    625\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mAnomaly detected due to unusual patterns in \u001b[39m\u001b[38;5;132;01m{features}\u001b[39;00m\u001b[33m. Confidence: \u001b[39m\u001b[38;5;132;01m{confidence:.2f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    626\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecast\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mForecast based on historical trends in \u001b[39m\u001b[38;5;132;01m{features}\u001b[39;00m\u001b[33m. Confidence interval: [\u001b[39m\u001b[38;5;132;01m{lower:.2f}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{upper:.2f}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    627\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    628\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    629\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def explain_anomaly(self, anomaly_score, feature_values, feature_names, detection_details):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    630\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    631\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Generate explanation for anomaly detection\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    632\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    633\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Find most contributing features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    634\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in detection_details:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    635\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # For simplicity, use variance-based importance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    636\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            feature_importance = np.var(feature_values.reshape(1, -1), axis=0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    637\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            top_features_idx = np.argsort(feature_importance)[-3:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    638\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            top_features = [feature_names[i] for i in top_features_idx]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    639\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    640\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            top_features = feature_names[:3]  # Fallback\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    641\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    642\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        explanation = self.explanation_templates[\u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].format(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    643\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            features=\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.join(top_features),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    644\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            confidence=anomaly_score\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    645\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    646\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    647\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanation\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: explanation,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontributing_features\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: top_features,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: anomaly_score,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mseverity\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self._get_severity_level(anomaly_score),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    652\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrecommendations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self._get_recommendations(anomaly_score, top_features)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    653\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    654\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    655\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def explain_forecast(self, forecast_values, confidence_intervals, contributing_factors):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    656\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    657\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Generate explanation for forecasts\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    658\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    659\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        explanation = self.explanation_templates[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecast\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].format(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    660\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            features=\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.join(contributing_factors),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    661\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            lower=confidence_intervals[0],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    662\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            upper=confidence_intervals[1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    663\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    664\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    665\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    666\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanation\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: explanation,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    667\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecast_trend\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mincreasing\u001b[39m\u001b[33m'\u001b[39m\u001b[33m if forecast_values[-1] > forecast_values[0] else \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdecreasing\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    668\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfidence_interval\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: confidence_intervals,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    669\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mkey_factors\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: contributing_factors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    670\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    671\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    672\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def _get_severity_level(self, score):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    673\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    674\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Map anomaly score to severity level\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    675\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    676\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if score >= 0.9:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    677\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCritical\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    678\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        elif score >= 0.7:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    679\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    680\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        elif score >= 0.5:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m'\u001b[39m\u001b[33mMedium\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    682\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        elif score >= 0.3:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    683\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m'\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    684\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    685\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    686\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    687\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def _get_recommendations(self, score, features):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    688\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    689\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Generate recommendations based on anomaly\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    690\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    691\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        recommendations = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    692\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    693\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if score >= 0.7:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    694\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            recommendations.append(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mImmediate investigation required\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    695\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            recommendations.append(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mCheck system logs for errors\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    696\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    697\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in str(features).lower():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    698\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            recommendations.append(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mMonitor CPU-intensive processes\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    699\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    700\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in str(features).lower():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    701\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            recommendations.append(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mCheck memory usage and potential leaks\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    702\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    703\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mio\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in str(features).lower():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    704\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            recommendations.append(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mInvestigate disk I/O performance\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    705\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    706\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return recommendations\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    707\u001b[39m       ],\n\u001b[32m    708\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    709\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRlz5XXAImQY9\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    710\u001b[39m       },\n\u001b[32m    711\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mRlz5XXAImQY9\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    712\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m    713\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m    714\u001b[39m     },\n\u001b[32m    715\u001b[39m     {\n\u001b[32m    716\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    717\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m    718\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclass AIXMonitoringTrainer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    719\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    720\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    Main training class that orchestrates all components\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    721\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    722\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    723\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def __init__(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    724\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.data_processor = DataProcessor()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    725\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.forecasting_engine = ForecastingEngine()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.anomaly_detector = AnomalyDetector()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    727\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.active_learner = ActiveLearningComponent()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    728\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.explainer = ExplainableDecisionSupport()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    729\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    730\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.is_trained = False\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    731\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.training_history = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    732\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    733\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def merge_data(self, vmstat_df, iostat_df, netstat_df, process_df):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    734\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mMerge data from multiple sources\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    735\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Convert to pandas if using Polars\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    736\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if isinstance(vmstat_df, pl.DataFrame):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    737\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            vmstat_df = vmstat_df.to_pandas(date_unit=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mms\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    738\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if isinstance(iostat_df, pl.DataFrame):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    739\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            iostat_df = iostat_df.to_pandas(date_unit=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mms\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    740\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if isinstance(netstat_df, pl.DataFrame):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    741\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            netstat_df = netstat_df.to_pandas(date_unit=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mms\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    742\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if isinstance(process_df, pl.DataFrame):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    743\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            process_df = process_df.to_pandas(date_unit=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mms\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    744\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    745\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Merge all data on id and timestamp\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    746\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        merged_df = vmstat_df.merge(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    747\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            iostat_df, on=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m], how=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, suffixes=(\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_iostat\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    748\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        ).merge(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    749\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            netstat_df, on=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m], how=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, suffixes=(\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_netstat\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    750\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        ).merge(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    751\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            process_df, on=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m], how=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mouter\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, suffixes=(\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_process\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    752\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    753\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    754\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Fill missing values with 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    755\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        merged_df.fillna(0, inplace=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    756\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return merged_df\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    757\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    758\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def train(self, vmstat_df, iostat_df, netstat_df, process_df,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    759\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m              target_columns=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33msy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmem_mean\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtps\u001b[39m\u001b[33m'\u001b[39m\u001b[33m],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    760\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m              test_size=0.2):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    761\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    762\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Complete training pipeline\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    763\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    764\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mStarting AIX Monitoring System Training...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    765\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    766\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # 0. Merge data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    767\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m0. Merging data...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    768\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        merged_df = self.merge_data(vmstat_df, iostat_df, netstat_df, process_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    769\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    770\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # 1. Data Processing\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    771\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m1. Processing data...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    772\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        processed_df = self.data_processor.process_data(merged_df, target_columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    773\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    774\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # 2. Split data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    775\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        train_df, test_df = train_test_split(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    776\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            processed_df, test_size=test_size, shuffle=False\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    777\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    778\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    779\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # 3. Train Forecasting Models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    780\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m2. Training forecasting models...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    781\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.forecasting_engine.train_ensemble(train_df, target_columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    782\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    783\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # 4. Train Anomaly Detection Models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    784\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m3. Training anomaly detection models...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    785\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.anomaly_detector.train_detectors(train_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    786\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    787\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # 5. Evaluate on test set\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    788\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m4. Evaluating models...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    789\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        evaluation_results = self.evaluate_models(test_df, target_columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    790\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    791\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # 6. Store training history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    792\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        training_record = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    793\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: pd.Timestamp.now(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    794\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain_size\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len(train_df),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    795\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtest_size\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len(test_df),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    796\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtarget_columns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: target_columns,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    797\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mevaluation_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: evaluation_results\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    798\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    799\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.training_history.append(training_record)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    800\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    801\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.is_trained = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    802\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mTraining completed successfully!\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    803\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    804\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return evaluation_results\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    805\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    806\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def evaluate_models(self, test_df, target_columns):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    807\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    808\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Comprehensive model evaluation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    809\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    810\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        results = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    811\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasting\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    812\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_detection\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    813\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33moverall_performance\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    814\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    815\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    816\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Evaluate Forecasting\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    817\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for target_col in target_columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    818\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if target_col in test_df.columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    819\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                # Generate predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    820\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                forecast_pred, model_preds = self.forecasting_engine.predict(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    821\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    test_df.head(50), target_col, horizon=24\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    822\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    823\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    824\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                if forecast_pred is not None and len(forecast_pred) > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    825\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    # Calculate metrics (simplified - would need actual future values)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    826\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasting\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][target_col] = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    827\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmae\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: np.mean(np.abs(forecast_pred)),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    828\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: np.mean(forecast_pred ** 2),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    829\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_contributions\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: list(model_preds.keys())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    830\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    831\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    832\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Evaluate Anomaly Detection\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    833\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        anomaly_scores, severity, detection_details = self.anomaly_detector.detect_anomalies(test_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    834\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    835\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_detection\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    836\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtotal_anomalies\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: np.sum(severity != \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m\u001b[33m),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    837\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mseverity_distribution\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    838\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                severity_level: np.sum(severity == severity_level)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    839\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                for severity_level in [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mLow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mMedium\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCritical\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    840\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    841\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33maverage_anomaly_score\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: np.mean(anomaly_scores),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    842\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdetection_methods_used\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: list(detection_details.keys())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    843\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    844\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    845\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Overall Performance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    846\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33moverall_performance\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    847\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining_time\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: pd.Timestamp.now(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    848\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata_quality_score\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self._calculate_data_quality_score(test_df),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    849\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_complexity\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self._calculate_model_complexity(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    850\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmemory_usage_mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self._estimate_memory_usage()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    851\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    852\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    853\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return results\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    854\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    855\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def predict_and_detect(self, vmstat_df, iostat_df, netstat_df, process_df,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    856\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                          target_columns=[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33msy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmem_mean\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtps\u001b[39m\u001b[33m'\u001b[39m\u001b[33m],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    857\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                          forecast_horizon=24):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    858\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    859\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Generate predictions and detect anomalies on new data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    860\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    861\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if not self.is_trained:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    862\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            raise ValueError(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModels must be trained before making predictions\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    863\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    864\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Process new data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    865\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        merged_df = self.merge_data(vmstat_df, iostat_df, netstat_df, process_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    866\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        processed_df = self.data_processor.process_data(merged_df, target_columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    867\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    868\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        results = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasts\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    870\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomalies\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    871\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    872\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrecommendations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    873\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    874\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    875\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Generate Forecasts\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    876\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for target_col in target_columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    877\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if target_col in processed_df.columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    878\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                forecast_pred, model_preds = self.forecasting_engine.predict(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    processed_df, target_col, horizon=forecast_horizon\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    880\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    881\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    882\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                if forecast_pred is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    883\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    std_dev = np.std(forecast_pred)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    884\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    # Calculate full confidence bands\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    885\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    confidence_band_lower = forecast_pred - 1.96 * std_dev\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    886\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    confidence_band_upper = forecast_pred + 1.96 * std_dev\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    887\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    888\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    # Get LAST confidence interval for explanation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    889\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    last_ci = [confidence_band_lower[-1], confidence_band_upper[-1]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    890\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    891\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasts\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][target_col] = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    892\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: forecast_pred.tolist(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    893\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfidence_intervals\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: [confidence_band_lower.tolist(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    894\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                                               confidence_band_upper.tolist()],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    895\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_contributions\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: model_preds\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    896\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    897\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    898\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    # Pass single interval to explainer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    899\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    explanation = self.explainer.explain_forecast(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    900\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        forecast_pred, last_ci, [target_col]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    901\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    902\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][f\u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecast_\u001b[39m\u001b[38;5;132;01m{target_col}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m] = explanation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    903\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    904\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Detect Anomalies\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    905\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        anomaly_scores, severity, detection_details = self.anomaly_detector.detect_anomalies(processed_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    906\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    907\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Find anomalous points\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    908\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        anomalous_indices = np.where(severity != \u001b[39m\u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    909\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    910\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33manomalies\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    911\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: anomaly_scores.tolist(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    912\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mseverity\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: severity.tolist(),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    913\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomalous_points\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len(anomalous_indices),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    914\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdetection_details\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\u001b[33mk: v.tolist() if isinstance(v, np.ndarray) else v\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    915\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                                for k, v in detection_details.items()}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    916\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    917\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    918\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Generate explanations for significant anomalies\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    919\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for idx in anomalous_indices[:5]:  # Explain top 5 anomalies\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    920\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if severity[idx] in [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCritical\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    921\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                feature_values = processed_df.iloc[idx][self.anomaly_detector.feature_columns].values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    922\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                explanation = self.explainer.explain_anomaly(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    923\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    anomaly_scores[idx],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    924\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    feature_values,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    925\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    self.anomaly_detector.feature_columns,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    926\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    detection_details\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    927\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    928\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][f\u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_\u001b[39m\u001b[38;5;132;01m{idx}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m] = explanation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    929\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrecommendations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].extend(explanation[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrecommendations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    930\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    931\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return results\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    932\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    933\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def update_models_with_feedback(self, feedback_data):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    934\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    935\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Update models with new feedback data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    936\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    937\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if not self.is_trained:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    938\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            raise ValueError(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModels must be trained before updating\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    939\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    940\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Collect feedback\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    941\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.active_learner.collect_feedback(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    942\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            predictions=feedback_data.get(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m'\u001b[39m\u001b[33m),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    943\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            actual_values=feedback_data.get(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mactual_values\u001b[39m\u001b[33m'\u001b[39m\u001b[33m),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    944\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            expert_annotations=feedback_data.get(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexpert_annotations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    945\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    946\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    947\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Check if retraining is needed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        should_retrain = self.active_learner.update_models(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.forecasting_engine,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    950\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.anomaly_detector,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    951\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            feedback_data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    952\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    953\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    954\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if should_retrain:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    955\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModel performance degraded. Retraining recommended.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    956\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mretraining_recommended\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mreason\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mperformance_degradation\u001b[39m\u001b[33m'\u001b[39m\u001b[33m}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    957\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    958\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            # Update thresholds based on feedback\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    959\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_feedback\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in feedback_data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    960\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                self.anomaly_detector.update_thresholds(feedback_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_feedback\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    961\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    962\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mupdated\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mreason\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mincremental_learning\u001b[39m\u001b[33m'\u001b[39m\u001b[33m}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def get_model_status(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    966\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Get current status of all models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    967\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    968\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if not self.is_trained:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    969\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            return \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnot_trained\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    970\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    971\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        status = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    972\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrained\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    973\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining_history\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len(self.training_history),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    974\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlast_training\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self.training_history[-1][\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] if self.training_history else None,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    975\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    976\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                \u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasting\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    977\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len([k for k in self.forecasting_engine.models.keys() if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in k]),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    978\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtransformer_models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len([k for k in self.forecasting_engine.models.keys() if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtransformer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in k]),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    979\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33marima_models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len([k for k in self.forecasting_engine.models.keys() if \u001b[39m\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in k]),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    980\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprophet_models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len([k for k in self.forecasting_engine.models.keys() if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in k]),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    981\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    982\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_detection\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    983\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.anomaly_detector.models,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    984\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33moneclass_svm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33moneclass_svm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.anomaly_detector.models,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    985\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.anomaly_detector.models,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    986\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    987\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                \u001b[39m\u001b[33m'\u001b[39m\u001b[33mactive_learning\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    988\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfeedback_samples\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len(self.active_learner.feedback_history),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    989\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mperformance_records\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: len(self.active_learner.model_performance)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmemory_usage_estimate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self._estimate_memory_usage()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    995\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return status\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    996\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    997\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def save_models(self, filepath):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    998\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    999\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Save trained models to disk\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1000\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1001\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        import pickle\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1002\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        import os\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1003\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1004\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if not self.is_trained:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1005\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            raise ValueError(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mNo trained models to save\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1006\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1007\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        os.makedirs(filepath, exist_ok=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1008\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1009\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save data processor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata_processor.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1011\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            pickle.dump(self.data_processor, f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1012\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1013\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save forecasting models (non-neural network components)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1014\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        forecasting_state = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1015\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_weights\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self.forecasting_engine.model_weights,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1016\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfeature_columns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self.forecasting_engine.feature_columns,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33msequence_length\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self.forecasting_engine.sequence_length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save ARIMA and Prophet models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        arima_models = \u001b[39m\u001b[33m{\u001b[39m\u001b[33mk: v for k, v in self.forecasting_engine.models.items() if \u001b[39m\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in k}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1022\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        prophet_models = \u001b[39m\u001b[33m{\u001b[39m\u001b[33mk: v for k, v in self.forecasting_engine.models.items() if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in k}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasting_classical.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            pickle.dump(\u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: arima_models, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: prophet_models, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: forecasting_state}, f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1027\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save neural network models separately\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1028\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for model_name, model in self.forecasting_engine.models.items():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1029\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in model_name or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtransformer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in model_name:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1030\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                model.save(os.path.join(filepath, f\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{model_name}\u001b[39;00m\u001b[33m.h5\u001b[39m\u001b[33m'\u001b[39m\u001b[33m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1031\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1032\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save anomaly detection models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1033\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        anomaly_state = \u001b[39m\u001b[33m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1034\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mthresholds\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self.anomaly_detector.thresholds,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1035\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfeature_columns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self.anomaly_detector.feature_columns,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1036\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            \u001b[39m\u001b[33m'\u001b[39m\u001b[33msequence_length\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: self.anomaly_detector.sequence_length\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1037\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1038\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1039\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save sklearn models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1040\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        sklearn_models = \u001b[39m\u001b[33m{\u001b[39m\u001b[33mk: v for k, v in self.anomaly_detector.models.items()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1041\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                         if k in [\u001b[39m\u001b[33m'\u001b[39m\u001b[33misolation_forest\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33moneclass_svm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1042\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1043\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_detection.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1044\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            pickle.dump(\u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33msklearn_models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: sklearn_models, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: anomaly_state}, f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1045\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1046\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save LSTM autoencoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1047\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in self.anomaly_detector.models:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1048\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.anomaly_detector.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].save(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1049\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder.h5\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1050\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1051\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1052\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save active learning component\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1053\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mactive_learning.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1054\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            pickle.dump(self.active_learner, f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1055\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1056\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Save training history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1057\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining_history.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            pickle.dump(self.training_history, f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1059\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1060\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModels saved successfully to \u001b[39m\u001b[38;5;132;01m{filepath}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1061\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1062\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def load_models(self, filepath):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1063\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1064\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Load trained models from disk\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1065\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1066\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        import pickle\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1067\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        import os\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1068\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        from tensorflow.keras.models import load_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1069\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1070\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if not os.path.exists(filepath):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1071\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            raise ValueError(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModel directory \u001b[39m\u001b[38;5;132;01m{filepath}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1072\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1073\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load data processor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1074\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata_processor.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1075\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.data_processor = pickle.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1076\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1077\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load forecasting models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1078\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasting_classical.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1079\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            forecasting_data = pickle.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1080\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1081\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.forecasting_engine.model_weights = forecasting_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_weights\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1082\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.forecasting_engine.feature_columns = forecasting_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfeature_columns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1083\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.forecasting_engine.sequence_length = forecasting_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[33m'\u001b[39m\u001b[33msequence_length\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1084\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1085\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load classical models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1086\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.forecasting_engine.models.update(forecasting_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1087\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.forecasting_engine.models.update(forecasting_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1088\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1089\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load neural network models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1090\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for filename in os.listdir(filepath):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1091\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if filename.endswith(\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) and (\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in filename or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtransformer\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in filename):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1092\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                model_name = filename.replace(\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1093\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                if \u001b[39m\u001b[33m'\u001b[39m\u001b[33mautoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m not in filename:  # Skip autoencoder here\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1094\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    self.forecasting_engine.models[model_name] = load_model(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1095\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                        os.path.join(filepath, filename)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1096\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                    )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1097\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1098\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load anomaly detection models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1099\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_detection.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1100\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            anomaly_data = pickle.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.anomaly_detector.thresholds = anomaly_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[33m'\u001b[39m\u001b[33mthresholds\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1103\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.anomaly_detector.feature_columns = anomaly_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfeature_columns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1104\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.anomaly_detector.sequence_length = anomaly_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[33m'\u001b[39m\u001b[33msequence_length\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.anomaly_detector.models.update(anomaly_data[\u001b[39m\u001b[33m'\u001b[39m\u001b[33msklearn_models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load LSTM autoencoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        autoencoder_path = os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder.h5\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        if os.path.exists(autoencoder_path):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1110\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.anomaly_detector.models[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlstm_autoencoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] = load_model(autoencoder_path)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1111\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1112\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load active learning component\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mactive_learning.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.active_learner = pickle.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Load training history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        with open(os.path.join(filepath, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining_history.pkl\u001b[39m\u001b[33m'\u001b[39m\u001b[33m), \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.training_history = pickle.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1120\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        self.is_trained = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModels loaded successfully from \u001b[39m\u001b[38;5;132;01m{filepath}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def _calculate_data_quality_score(self, df):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1124\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1125\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Calculate a simple data quality score\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        numeric_df = df.select_dtypes(include=[np.number])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1129\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Check for missing values\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1130\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        missing_ratio = numeric_df.isnull().sum().sum() / (len(numeric_df) * len(numeric_df.columns))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1131\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1132\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Check for constant columns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1133\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        constant_cols = (numeric_df.nunique() == 1).sum()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1134\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        constant_ratio = constant_cols / len(numeric_df.columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1135\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1136\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Calculate quality score (0-1, higher is better)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1137\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        quality_score = (1 - missing_ratio) * (1 - constant_ratio)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return max(0, min(1, quality_score))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1141\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def _calculate_model_complexity(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1142\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1143\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Estimate model complexity\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1145\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        complexity = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1147\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Count forecasting models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        complexity += len(self.forecasting_engine.models) * 10\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1149\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1150\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Count anomaly detection models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        complexity += len(self.anomaly_detector.models) * 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1152\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Add feature complexity\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1154\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        complexity += len(self.data_processor.feature_columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return complexity\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def _estimate_memory_usage(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1160\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        Estimate memory usage in MB\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        total_size = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        components = [\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.data_processor,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.forecasting_engine,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.anomaly_detector,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            self.active_learner\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1168\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        ]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for obj in components:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            for v in vars(obj).values():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1172\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                total_size += sys.getsizeof(v)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1174\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Add model sizes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1175\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        for model in self.forecasting_engine.models.values():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1176\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            if hasattr(model, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcount_params\u001b[39m\u001b[33m'\u001b[39m\u001b[33m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1177\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                total_size += model.count_params() * 4  # 4 bytes per float\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1178\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1179\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return total_size / (1024 * 1024)  # Convert to MB\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1180\u001b[39m       ],\n\u001b[32m   1181\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   1182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mKYh8rWTumRni\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1183\u001b[39m       },\n\u001b[32m   1184\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mKYh8rWTumRni\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1185\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m   1186\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m   1187\u001b[39m     },\n\u001b[32m   1188\u001b[39m     {\n\u001b[32m   1189\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcell_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1190\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   1191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Load data with Polars\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdef load_and_fix_data():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1193\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mLoading real AIX server metrics with Polars...\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1194\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1195\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # Load data with Polars\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1196\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    vmstat_df = pl.read_csv(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mvmstat_metrics.csv\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1197\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    iostat_df = pl.read_csv(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33miostat_metrics.csv\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1198\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    netstat_df = pl.read_csv(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mnetstat_metrics.csv\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1199\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    process_df = pl.read_csv(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mprocess_metrics.csv\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1200\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1201\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # Function to fix timestamps\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    def fix_timestamps(df):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Handle incomplete timestamps\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1204\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        df = df.with_columns(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            pl.when(pl.col(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtimestamp\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m).str.ends_with(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m+00\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m) | pl.col(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtimestamp\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m).str.ends_with(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m-00\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            .then(pl.col(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtimestamp\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m) + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m00\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1207\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            .otherwise(pl.col(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtimestamp\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        # Try multiple formats\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        return df.with_columns(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1212\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            pl.coalesce(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1213\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                pl.col(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtimestamp\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m).str.to_datetime(strict=False, format=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m%\u001b[39m\u001b[33m.f\u001b[39m\u001b[33m%\u001b[39m\u001b[33mz\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1214\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                pl.col(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtimestamp\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m).str.to_datetime(strict=False, format=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1215\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m                pl.col(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mtimestamp\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m).str.to_datetime(strict=False, format=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m            )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        )\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1219\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # Apply to all dataframes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    vmstat_df = fix_timestamps(vmstat_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1221\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    iostat_df = fix_timestamps(iostat_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1222\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    netstat_df = fix_timestamps(netstat_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    process_df = fix_timestamps(process_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1224\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1225\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    return vmstat_df, iostat_df, netstat_df, process_df\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1226\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1227\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Load data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1228\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvmstat_df, iostat_df, netstat_df, process_df = load_and_fix_data()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1229\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1230\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Initialize trainer\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1231\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrainer = AIXMonitoringTrainer()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1232\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Define target columns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtarget_columns = [\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1235\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # CPU metrics (vmstat)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1236\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mus\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,    # User CPU \u001b[39m\u001b[33m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1237\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33msy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,    # System CPU \u001b[39m\u001b[33m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1238\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33midle\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,  # Idle CPU \u001b[39m\u001b[33m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1239\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1240\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # Memory metrics (vmstat)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1241\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfre\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,   # Free memory\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1242\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1243\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # Disk metrics (iostat)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtps\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,   # Transactions per second\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mservice_time\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,  # Disk service time\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1247\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # Network metrics (netstat)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1248\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mipkts_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,  # Input packets rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1249\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33moerrs_rate\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,  # Output error rate\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1250\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1251\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    # Process metrics (process)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1252\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m    # Process CPU usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1253\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1255\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Train the model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1256\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnTraining models for:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m, target_columns)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mevaluation_results = trainer.train(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1258\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    vmstat_df,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1259\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    iostat_df,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1260\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    netstat_df,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1261\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    process_df,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1262\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    target_columns=target_columns,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1263\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    test_size=0.2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1264\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1265\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1266\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Print detailed evaluation results\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1267\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdef print_evaluation(results):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1268\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1269\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mFORECASTING PERFORMANCE (MAE/MSE)\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1270\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1271\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    for metric, scores in results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasting\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].items():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1272\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m{\u001b[39m\u001b[33mmetric.upper():<15} MAE: \u001b[39m\u001b[38;5;132;01m{scores['mae']:.4f}\u001b[39;00m\u001b[33m | MSE: \u001b[39m\u001b[38;5;132;01m{scores['mse']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1273\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m    Models used: \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.join(scores[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_contributions\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1274\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1275\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1276\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mANOMALY DETECTION RESULTS\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1277\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1278\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    anomalies = results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_detection\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1279\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mTotal anomalies detected: \u001b[39m\u001b[38;5;132;01m{anomalies['total_anomalies']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1280\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mSeverity distribution:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    for severity, count in anomalies[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mseverity_distribution\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].items():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1282\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{severity:<8}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{count}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1283\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mAverage anomaly score: \u001b[39m\u001b[38;5;132;01m{anomalies['average_anomaly_score']:.2f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1284\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mDetection methods: \u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.join(anomalies[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdetection_methods_used\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1285\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1286\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mSYSTEM PERFORMANCE METRICS\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    perf = results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33moverall_performance\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mTraining time: \u001b[39m\u001b[38;5;132;01m{perf['training_time']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1291\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mData quality score: \u001b[39m\u001b[38;5;132;01m{perf['data_quality_score']:.2f}\u001b[39;00m\u001b[33m/1.0\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1292\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mModel complexity: \u001b[39m\u001b[38;5;132;01m{perf['model_complexity']}\u001b[39;00m\u001b[33m (relative units)\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1293\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mMemory usage: \u001b[39m\u001b[38;5;132;01m{perf['memory_usage_mb']:.2f}\u001b[39;00m\u001b[33m MB\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1294\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1295\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint_evaluation(evaluation_results)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1296\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1297\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Sample predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1298\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1299\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mGENERATING SAMPLE PREDICTIONS\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1300\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1301\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msample_results = trainer.predict_and_detect(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1302\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    vmstat_df.tail(100),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1303\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    iostat_df.tail(200),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    netstat_df.tail(200),\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m    process_df.tail(500)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1308\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mnGenerated forecasts for: \u001b[39m\u001b[33m{\u001b[39m\u001b[33mlist(sample_results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mforecasts\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].keys())}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1309\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mDetected \u001b[39m\u001b[38;5;132;01m{sample_results['anomalies']['anomalous_points']}\u001b[39;00m\u001b[33m anomalies\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mTop anomaly explanation:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1311\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfirst_anomaly_key = [k for k in sample_results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m].keys() if \u001b[39m\u001b[33m'\u001b[39m\u001b[33manomaly_\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in k][0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1312\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(sample_results[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanations\u001b[39m\u001b[33m'\u001b[39m\u001b[33m][first_anomaly_key][\u001b[39m\u001b[33m'\u001b[39m\u001b[33mexplanation\u001b[39m\u001b[33m'\u001b[39m\u001b[33m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1314\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Model status\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1315\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m + \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1316\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mMODEL STATUS SUMMARY\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1317\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m*50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1318\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstatus = trainer.get_model_status()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mStatus: \u001b[39m\u001b[38;5;132;01m{status['status']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1320\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mLast trained: \u001b[39m\u001b[38;5;132;01m{status['last_training']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mForecasting models: \u001b[39m\u001b[38;5;132;01m{status['models']['forecasting']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mAnomaly detectors: \u001b[39m\u001b[38;5;132;01m{status['models']['anomaly_detection']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mMemory usage: \u001b[39m\u001b[38;5;132;01m{status['memory_usage_estimate']:.2f}\u001b[39;00m\u001b[33m MB\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1325\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m# Save models\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1326\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrainer.save_models(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33maix_monitoring_models\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1327\u001b[39m       ],\n\u001b[32m   1328\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   1329\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWRfSmnYwmTOZ\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1330\u001b[39m       },\n\u001b[32m   1331\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWRfSmnYwmTOZ\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1332\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mexecution_count\u001b[39m\u001b[33m\"\u001b[39m: null,\n\u001b[32m   1333\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m   1334\u001b[39m     }\n\u001b[32m   1335\u001b[39m   ],\n\u001b[32m   1336\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   1337\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mkernelspec\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   1338\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPython 3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1339\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1340\u001b[39m     },\n\u001b[32m   1341\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlanguage_info\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   1342\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mcodemirror_mode\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   1343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m\n\u001b[32m   1345\u001b[39m       },\n\u001b[32m   1346\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mfile_extension\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1347\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mmimetype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtext/x-python\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1348\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1349\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mnbconvert_exporter\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1350\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mpygments_lexer\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mipython3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1351\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m3.11.11\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1352\u001b[39m     },\n\u001b[32m   1353\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolab\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   1354\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mprovenance\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m   1355\u001b[39m     }\n\u001b[32m   1356\u001b[39m   },\n\u001b[32m   1357\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mnbformat\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m   1358\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mnbformat_minor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m\n\u001b[32m   1359\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"id\": \"1566b4c7\",\n",
    "      \"metadata\": {\n",
    "        \"id\": \"1566b4c7\"\n",
    "      },\n",
    "      \"source\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"# Library Imports\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"uCSRIld0tnWz\"\n",
    "      },\n",
    "      \"id\": \"uCSRIld0tnWz\"\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"# !pip install pytorch_forecasting polars\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"KGhO5A8QnQop\"\n",
    "      },\n",
    "      \"id\": \"KGhO5A8QnQop\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import polars as pl\\n\",\n",
    "        \"from sklearn.preprocessing import StandardScaler, RobustScaler\\n\",\n",
    "        \"from sklearn.ensemble import IsolationForest\\n\",\n",
    "        \"from sklearn.svm import OneClassSVM\\n\",\n",
    "        \"from sklearn.model_selection import train_test_split\\n\",\n",
    "        \"from sklearn.metrics import precision_recall_fscore_support, mean_absolute_error\\n\",\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from tensorflow.keras.models import Sequential, Model\\n\",\n",
    "        \"from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, RepeatVector, TimeDistributed\\n\",\n",
    "        \"from tensorflow.keras.optimizers import Adam\\n\",\n",
    "        \"from statsmodels.tsa.arima.model import ARIMA\\n\",\n",
    "        \"from statsmodels.tsa.holtwinters import SimpleExpSmoothing\\n\",\n",
    "        \"from prophet import Prophet\\n\",\n",
    "        \"import warnings\\n\",\n",
    "        \"import sys\\n\",\n",
    "        \"warnings.filterwarnings('ignore')\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"abb6PFxrmGk3\"\n",
    "      },\n",
    "      \"id\": \"abb6PFxrmGk3\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"class DataProcessor:\\n\",\n",
    "        \"    def __init__(self):\\n\",\n",
    "        \"        self.scalers = {}\\n\",\n",
    "        \"        self.feature_columns = []\\n\",\n",
    "        \"        self.temporal_features = ['hour', 'day_of_week', 'day_of_month', 'is_weekend']\\n\",\n",
    "        \"        self.target_columns = []\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_temporal_features(self, df):\\n\",\n",
    "        \"        \\\"\\\"\\\"Create time-based features (optimized)\\\"\\\"\\\"\\n\",\n",
    "        \"        df = df.copy()\\n\",\n",
    "        \"        df['hour'] = df['timestamp'].dt.hour\\n\",\n",
    "        \"        df['day_of_week'] = df['timestamp'].dt.dayofweek\\n\",\n",
    "        \"        df['day_of_month'] = df['timestamp'].dt.day\\n\",\n",
    "        \"        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\\n\",\n",
    "        \"        return df\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_statistical_features(self, df, window_sizes=[5]):\\n\",\n",
    "        \"        \\\"\\\"\\\"Optimized rolling features with minimal windows\\\"\\\"\\\"\\n\",\n",
    "        \"        df = df.copy()\\n\",\n",
    "        \"        # Only process target columns and key metrics\\n\",\n",
    "        \"        numeric_cols = self.target_columns + ['r', 'b', 'avm', 'fre', 'fr', 'in', 'cs']\\n\",\n",
    "        \"        numeric_cols = [col for col in numeric_cols if col in df.columns]\\n\",\n",
    "        \"\\n\",\n",
    "        \"        for window in window_sizes:\\n\",\n",
    "        \"            for col in numeric_cols:\\n\",\n",
    "        \"                # Only calculate rolling mean (skip std/max)\\n\",\n",
    "        \"                df[f'{col}_rolling_mean_{window}'] = df.groupby('id')[col].transform(\\n\",\n",
    "        \"                    lambda x: x.rolling(window, min_periods=1).mean()\\n\",\n",
    "        \"                )\\n\",\n",
    "        \"        return df.fillna(0)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_cross_metric_features(self, df):\\n\",\n",
    "        \"        \\\"\\\"\\\"Optimized cross-metric features\\\"\\\"\\\"\\n\",\n",
    "        \"        df = df.copy()\\n\",\n",
    "        \"        if 'us' in df and 'mem_mean' in df:\\n\",\n",
    "        \"            df['cpu_mem_ratio'] = df['us'] / (df['mem_mean'] + 1e-6)\\n\",\n",
    "        \"        if 'kb_read' in df and 'kb_wrtn' in df and 'tps' in df:\\n\",\n",
    "        \"            df['io_efficiency'] = (df['kb_read'] + df['kb_wrtn']) / (df['tps'] + 1e-6)\\n\",\n",
    "        \"        if 'ipkts_rate' in df and 'opkts_rate' in df and 'ierrs_rate' in df and 'oerrs_rate' in df:\\n\",\n",
    "        \"            df['net_error_rate'] = (df['ierrs_rate'] + df['oerrs_rate']) / (df['ipkts_rate'] + df['opkts_rate'] + 1e-6)\\n\",\n",
    "        \"        if 'us' in df and 'sy' in df and 'r' in df:\\n\",\n",
    "        \"            df['system_load'] = df['us'] + df['sy'] + (df['r'] * 10)\\n\",\n",
    "        \"        return df.fillna(0)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def detect_and_handle_outliers(self, df):\\n\",\n",
    "        \"        \\\"\\\"\\\"Optimized outlier handling for target columns only\\\"\\\"\\\"\\n\",\n",
    "        \"        df = df.copy()\\n\",\n",
    "        \"        for col in self.target_columns:\\n\",\n",
    "        \"            if col not in df.columns:\\n\",\n",
    "        \"                continue\\n\",\n",
    "        \"            # Vectorized IQR calculation\\n\",\n",
    "        \"            q1 = df[col].quantile(0.25)\\n\",\n",
    "        \"            q3 = df[col].quantile(0.75)\\n\",\n",
    "        \"            iqr = q3 - q1\\n\",\n",
    "        \"            lower_bound = q1 - 1.5 * iqr\\n\",\n",
    "        \"            upper_bound = q3 + 1.5 * iqr\\n\",\n",
    "        \"            df[col] = df[col].clip(lower_bound, upper_bound)\\n\",\n",
    "        \"        return df\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def normalize_features(self, df, method='robust'):\\n\",\n",
    "        \"        \\\"\\\"\\\"Optimized normalization\\\"\\\"\\\"\\n\",\n",
    "        \"        df = df.copy()\\n\",\n",
    "        \"        numeric_cols = df.select_dtypes(include=[np.number]).columns\\n\",\n",
    "        \"        numeric_cols = [col for col in numeric_cols if col not in ['id', 'hour', 'day_of_week', 'day_of_month', 'is_weekend']]\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if method == 'robust':\\n\",\n",
    "        \"            scaler = RobustScaler()\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            scaler = StandardScaler()\\n\",\n",
    "        \"\\n\",\n",
    "        \"        df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\\n\",\n",
    "        \"        self.scalers['main_scaler'] = scaler\\n\",\n",
    "        \"        self.feature_columns = numeric_cols\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return df\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def process_data(self, merged_df, target_columns):\\n\",\n",
    "        \"        \\\"\\\"\\\"Optimized processing pipeline\\\"\\\"\\\"\\n\",\n",
    "        \"        # Validate target columns\\n\",\n",
    "        \"        valid_columns = [col for col in target_columns if col in merged_df.columns]\\n\",\n",
    "        \"        missing = set(target_columns) - set(valid_columns)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        if missing:\\n\",\n",
    "        \"            print(f\\\"Warning: Missing target columns: {missing}\\\")\\n\",\n",
    "        \"            \\n\",\n",
    "        \"        self.target_columns = valid_columns\\n\",\n",
    "        \"        df = self.create_temporal_features(merged_df)\\n\",\n",
    "        \"        df = self.create_statistical_features(df, window_sizes=[5])  # Single window size\\n\",\n",
    "        \"        df = self.create_cross_metric_features(df)\\n\",\n",
    "        \"        df = self.detect_and_handle_outliers(df)\\n\",\n",
    "        \"        df = self.normalize_features(df)\\n\",\n",
    "        \"        return df\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"XquWKbn9mHAN\"\n",
    "      },\n",
    "      \"id\": \"XquWKbn9mHAN\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"class ForecastingEngine:\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"    Multi-model forecasting engine with ensemble capabilities\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def __init__(self, sequence_length=50):\\n\",\n",
    "        \"        self.sequence_length = sequence_length\\n\",\n",
    "        \"        self.models = {}\\n\",\n",
    "        \"        self.model_weights = {}\\n\",\n",
    "        \"        self.feature_columns = []\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_lstm_model(self, input_shape, horizon=24):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Create LSTM model for long-term forecasting\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        model = Sequential([\\n\",\n",
    "        \"            LSTM(128, return_sequences=True, input_shape=input_shape),\\n\",\n",
    "        \"            Dropout(0.2),\\n\",\n",
    "        \"            LSTM(64, return_sequences=True),\\n\",\n",
    "        \"            Dropout(0.2),\\n\",\n",
    "        \"            LSTM(32, return_sequences=False),\\n\",\n",
    "        \"            Dropout(0.2),\\n\",\n",
    "        \"            Dense(horizon)\\n\",\n",
    "        \"        ])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\\n\",\n",
    "        \"        return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_transformer_model(self, input_shape, horizon=12):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Create Transformer model for medium-term forecasting\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        inputs = Input(shape=input_shape)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Multi-head attention\\n\",\n",
    "        \"        attention = tf.keras.layers.MultiHeadAttention(\\n\",\n",
    "        \"            num_heads=8, key_dim=64\\n\",\n",
    "        \"        )(inputs, inputs)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Add & Norm\\n\",\n",
    "        \"        attention = tf.keras.layers.LayerNormalization()(inputs + attention)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Feed Forward\\n\",\n",
    "        \"        ff = tf.keras.layers.Dense(128, activation='relu')(attention)\\n\",\n",
    "        \"        ff = tf.keras.layers.Dense(input_shape[-1])(ff)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Add & Norm\\n\",\n",
    "        \"        output = tf.keras.layers.LayerNormalization()(attention + ff)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Output layer\\n\",\n",
    "        \"        output = tf.keras.layers.GlobalAveragePooling1D()(output)\\n\",\n",
    "        \"        output = tf.keras.layers.Dense(horizon)(output)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        model = Model(inputs=inputs, outputs=output)\\n\",\n",
    "        \"        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_sequences(self, data, target_col, horizon=1):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Create sequences for time series models\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        X, y = [], []\\n\",\n",
    "        \"        max_start = len(data) - self.sequence_length - horizon\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        if max_start < 0:\\n\",\n",
    "        \"            # Pad with zeros if insufficient data\\n\",\n",
    "        \"            padded = np.pad(data, ((0, -max_start), 'constant')\\n\",\n",
    "        \"            X.append(padded[:self.sequence_length])\\n\",\n",
    "        \"            y.append(padded[self.sequence_length:self.sequence_length + horizon, target_col])\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            for i in range(max_start + 1):\\n\",\n",
    "        \"                X.append(data[i:(i + self.sequence_length)])\\n\",\n",
    "        \"                y.append(data[i + self.sequence_length:i + self.sequence_length + horizon, target_col])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return np.array(X), np.array(y)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def fit_arima_model(self, series, order=(5, 1, 0), seasonal_order=(1, 1, 1, 24)):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Fit ARIMA model for short-term forecasting\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        try:\\n\",\n",
    "        \"            model = ARIMA(series, order=order, seasonal_order=seasonal_order)\\n\",\n",
    "        \"            fitted_model = model.fit()\\n\",\n",
    "        \"            return fitted_model\\n\",\n",
    "        \"        except Exception as e:\\n\",\n",
    "        \"            print(f\\\"ARIMA failed: {str(e)}\\\")\\n\",\n",
    "        \"            # Fallback to simple exponential smoothing\\n\",\n",
    "        \"            model = SimpleExpSmoothing(series)\\n\",\n",
    "        \"            fitted_model = model.fit()\\n\",\n",
    "        \"            return fitted_model\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def fit_prophet_model(self, df, target_col):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Fit Prophet model for long-term forecasting with seasonality\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        prophet_df = df[['timestamp', target_col]].copy()\\n\",\n",
    "        \"        prophet_df.columns = ['ds', 'y']\\n\",\n",
    "        \"\\n\",\n",
    "        \"        model = Prophet(\\n\",\n",
    "        \"            yearly_seasonality=True,\\n\",\n",
    "        \"            weekly_seasonality=True,\\n\",\n",
    "        \"            daily_seasonality=True,\\n\",\n",
    "        \"            changepoint_prior_scale=0.05\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        model.fit(prophet_df)\\n\",\n",
    "        \"        return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def train_ensemble(self, df, target_columns):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Train all forecasting models\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        self.feature_columns = [col for col in df.columns if col not in ['id', 'timestamp']]\\n\",\n",
    "        \"\\n\",\n",
    "        \"        for target_col in target_columns:\\n\",\n",
    "        \"            print(f\\\"Training models for {target_col}...\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Prepare data\\n\",\n",
    "        \"            numeric_data = df[self.feature_columns].values\\n\",\n",
    "        \"            target_idx = self.feature_columns.index(target_col)\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Create sequences\\n\",\n",
    "        \"            X_lstm, y_lstm_24 = self.create_sequences(numeric_data, target_idx, horizon=24)\\n\",\n",
    "        \"            X_trans, y_trans_12 = self.create_sequences(numeric_data, target_idx, horizon=12)\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Split data\\n\",\n",
    "        \"            split_idx = int(0.8 * len(X_lstm))\\n\",\n",
    "        \"            X_train_lstm, X_test_lstm = X_lstm[:split_idx], X_lstm[split_idx:]\\n\",\n",
    "        \"            y_train_lstm, y_test_lstm = y_lstm_24[:split_idx], y_lstm_24[split_idx:]\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Train LSTM\\n\",\n",
    "        \"            lstm_model = self.create_lstm_model(X_train_lstm.shape[1:], horizon=24)\\n\",\n",
    "        \"            lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, verbose=0)\\n\",\n",
    "        \"            self.models[f'{target_col}_lstm'] = lstm_model\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Train Transformer\\n\",\n",
    "        \"            if len(X_trans) > 0:\\n\",\n",
    "        \"                trans_model = self.create_transformer_model(X_trans.shape[1:], horizon=12)\\n\",\n",
    "        \"                X_train_trans = X_trans[:int(0.8 * len(X_trans))]\\n\",\n",
    "        \"                y_train_trans = y_trans_12[:int(0.8 * len(y_trans_12))]\\n\",\n",
    "        \"                trans_model.fit(X_train_trans, y_train_trans, epochs=30, batch_size=32, verbose=0)\\n\",\n",
    "        \"                self.models[f'{target_col}_transformer'] = trans_model\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Train ARIMA\\n\",\n",
    "        \"            series = df[target_col].values\\n\",\n",
    "        \"            arima_model = self.fit_arima_model(series)\\n\",\n",
    "        \"            self.models[f'{target_col}_arima'] = arima_model\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Train Prophet\\n\",\n",
    "        \"            prophet_model = self.fit_prophet_model(df, target_col)\\n\",\n",
    "        \"            self.models[f'{target_col}_prophet'] = prophet_model\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Initialize equal weights\\n\",\n",
    "        \"            self.model_weights[target_col] = {'lstm': 0.25, 'transformer': 0.25, 'arima': 0.25, 'prophet': 0.25}\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def predict(self, df, target_col, horizon=24):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Generate ensemble predictions\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        predictions = {}\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # LSTM prediction\\n\",\n",
    "        \"        if f'{target_col}_lstm' in self.models:\\n\",\n",
    "        \"            numeric_data = df[self.feature_columns].values\\n\",\n",
    "        \"            if len(numeric_data) >= self.sequence_length:\\n\",\n",
    "        \"                X_pred = numeric_data[-self.sequence_length:].reshape(1, self.sequence_length, -1)\\n\",\n",
    "        \"                lstm_pred = self.models[f'{target_col}_lstm'].predict(X_pred, verbose=0)[0]\\n\",\n",
    "        \"                predictions['lstm'] = lstm_pred[:horizon]\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # ARIMA prediction\\n\",\n",
    "        \"        if f'{target_col}_arima' in self.models:\\n\",\n",
    "        \"            try:\\n\",\n",
    "        \"                arima_pred = self.models[f'{target_col}_arima'].forecast(steps=horizon)\\n\",\n",
    "        \"                predictions['arima'] = arima_pred\\n\",\n",
    "        \"            except:\\n\",\n",
    "        \"                predictions['arima'] = np.full(horizon, df[target_col].iloc[-1])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Prophet prediction\\n\",\n",
    "        \"        if f'{target_col}_prophet' in self.models:\\n\",\n",
    "        \"            future = self.models[f'{target_col}_prophet'].make_future_dataframe(periods=horizon, freq='H')\\n\",\n",
    "        \"            prophet_pred = self.models[f'{target_col}_prophet'].predict(future)\\n\",\n",
    "        \"            predictions['prophet'] = prophet_pred['yhat'].tail(horizon).values\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Ensemble prediction\\n\",\n",
    "        \"        if predictions:\\n\",\n",
    "        \"            weights = self.model_weights.get(target_col, {})\\n\",\n",
    "        \"            ensemble_pred = np.zeros(horizon)\\n\",\n",
    "        \"            total_weight = 0\\n\",\n",
    "        \"\\n\",\n",
    "        \"            for model_name, pred in predictions.items():\\n\",\n",
    "        \"                if len(pred) == horizon:\\n\",\n",
    "        \"                    weight = weights.get(model_name, 0.25)\\n\",\n",
    "        \"                    ensemble_pred += pred * weight\\n\",\n",
    "        \"                    total_weight += weight\\n\",\n",
    "        \"\\n\",\n",
    "        \"            if total_weight > 0:\\n\",\n",
    "        \"                ensemble_pred /= total_weight\\n\",\n",
    "        \"\\n\",\n",
    "        \"            return ensemble_pred, predictions\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return None, {}\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"vklvAK7SmKhV\"\n",
    "      },\n",
    "      \"id\": \"vklvAK7SmKhV\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"class AnomalyDetector:\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"    Multi-method anomaly detection framework\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def __init__(self, sequence_length=50):\\n\",\n",
    "        \"        self.sequence_length = sequence_length\\n\",\n",
    "        \"        self.models = {}\\n\",\n",
    "        \"        self.thresholds = {\\n\",\n",
    "        \"            'low': 0.3,\\n\",\n",
    "        \"            'medium': 0.5,\\n\",\n",
    "        \"            'high': 0.7,\\n\",\n",
    "        \"            'critical': 0.9\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"        self.feature_columns = []\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_lstm_autoencoder(self, input_shape):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Create LSTM Autoencoder for sequential anomaly detection\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        # Encoder\\n\",\n",
    "        \"        encoder_inputs = Input(shape=input_shape)\\n\",\n",
    "        \"        encoder = LSTM(64, return_sequences=True)(encoder_inputs)\\n\",\n",
    "        \"        encoder = LSTM(32, return_sequences=False)(encoder)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Decoder\\n\",\n",
    "        \"        decoder = RepeatVector(input_shape[0])(encoder)\\n\",\n",
    "        \"        decoder = LSTM(32, return_sequences=True)(decoder)\\n\",\n",
    "        \"        decoder = LSTM(64, return_sequences=True)(decoder)\\n\",\n",
    "        \"        decoder_outputs = TimeDistributed(Dense(input_shape[1]))(decoder)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        autoencoder = Model(encoder_inputs, decoder_outputs)\\n\",\n",
    "        \"        autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return autoencoder\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def create_sequences_for_autoencoder(self, data):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Create sequences for autoencoder training\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        X = []\\n\",\n",
    "        \"        for i in range(len(data) - self.sequence_length + 1):\\n\",\n",
    "        \"            X.append(data[i:(i + self.sequence_length)])\\n\",\n",
    "        \"        return np.array(X)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def train_detectors(self, df, contamination=0.05):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Train all anomaly detection models\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        self.feature_columns = [col for col in df.columns if col not in ['id', 'timestamp']]\\n\",\n",
    "        \"        numeric_data = df[self.feature_columns].values\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Train Isolation Forest\\n\",\n",
    "        \"        iso_forest = IsolationForest(\\n\",\n",
    "        \"            contamination=contamination,\\n\",\n",
    "        \"            n_estimators=100,\\n\",\n",
    "        \"            random_state=42\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"        iso_forest.fit(numeric_data)\\n\",\n",
    "        \"        self.models['isolation_forest'] = iso_forest\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Train One-Class SVM\\n\",\n",
    "        \"        oc_svm = OneClassSVM(kernel='rbf', nu=contamination)\\n\",\n",
    "        \"        oc_svm.fit(numeric_data)\\n\",\n",
    "        \"        self.models['oneclass_svm'] = oc_svm\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Train LSTM Autoencoder\\n\",\n",
    "        \"        sequences = self.create_sequences_for_autoencoder(numeric_data)\\n\",\n",
    "        \"        if len(sequences) > 0:\\n\",\n",
    "        \"            autoencoder = self.create_lstm_autoencoder((self.sequence_length, len(self.feature_columns)))\\n\",\n",
    "        \"            autoencoder.fit(sequences, sequences, epochs=50, batch_size=32, verbose=0)\\n\",\n",
    "        \"            self.models['lstm_autoencoder'] = autoencoder\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # Calculate reconstruction threshold\\n\",\n",
    "        \"            reconstructions = autoencoder.predict(sequences, verbose=0)\\n\",\n",
    "        \"            mse = np.mean(np.power(sequences - reconstructions, 2), axis=(1, 2))\\n\",\n",
    "        \"            self.thresholds['reconstruction'] = np.percentile(mse, 95)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def detect_anomalies(self, df):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Detect anomalies using ensemble approach\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        numeric_data = df[self.feature_columns].values\\n\",\n",
    "        \"        anomaly_scores = np.zeros(len(df))\\n\",\n",
    "        \"        detection_details = {}\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Isolation Forest\\n\",\n",
    "        \"        if 'isolation_forest' in self.models:\\n\",\n",
    "        \"            iso_scores = self.models['isolation_forest'].decision_function(numeric_data)\\n\",\n",
    "        \"            iso_scores = (iso_scores - iso_scores.min()) / (iso_scores.max() - iso_scores.min())\\n\",\n",
    "        \"            anomaly_scores += iso_scores * 0.33\\n\",\n",
    "        \"            detection_details['isolation_forest'] = iso_scores\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # One-Class SVM\\n\",\n",
    "        \"        if 'oneclass_svm' in self.models:\\n\",\n",
    "        \"            svm_scores = self.models['oneclass_svm'].decision_function(numeric_data)\\n\",\n",
    "        \"            svm_scores = (svm_scores - svm_scores.min()) / (svm_scores.max() - svm_scores.min())\\n\",\n",
    "        \"            anomaly_scores += svm_scores * 0.33\\n\",\n",
    "        \"            detection_details['oneclass_svm'] = svm_scores\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # LSTM Autoencoder\\n\",\n",
    "        \"        if 'lstm_autoencoder' in self.models and len(numeric_data) >= self.sequence_length:\\n\",\n",
    "        \"            sequences = self.create_sequences_for_autoencoder(numeric_data)\\n\",\n",
    "        \"            if len(sequences) > 0:\\n\",\n",
    "        \"                reconstructions = self.models['lstm_autoencoder'].predict(sequences, verbose=0)\\n\",\n",
    "        \"                mse = np.mean(np.power(sequences - reconstructions, 2), axis=(1, 2))\\n\",\n",
    "        \"\\n\",\n",
    "        \"                # Pad the scores to match original length\\n\",\n",
    "        \"                ae_scores = np.zeros(len(numeric_data))\\n\",\n",
    "        \"                ae_scores[self.sequence_length-1:] = mse\\n\",\n",
    "        \"                ae_scores = (ae_scores - ae_scores.min()) / (ae_scores.max() - ae_scores.min() + 1e-8)\\n\",\n",
    "        \"                anomaly_scores += ae_scores * 0.34\\n\",\n",
    "        \"                detection_details['lstm_autoencoder'] = ae_scores\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Classify severity\\n\",\n",
    "        \"        severity = np.where(anomaly_scores >= self.thresholds['critical'], 'Critical',\\n\",\n",
    "        \"                   np.where(anomaly_scores >= self.thresholds['high'], 'High',\\n\",\n",
    "        \"                   np.where(anomaly_scores >= self.thresholds['medium'], 'Medium',\\n\",\n",
    "        \"                   np.where(anomaly_scores >= self.thresholds['low'], 'Low', 'Normal'))))\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return anomaly_scores, severity, detection_details\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def update_thresholds(self, feedback_data):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Adapt thresholds based on feedback\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        # This would be implemented based on expert feedback\\n\",\n",
    "        \"        # For now, we'll use a simple adaptive approach\\n\",\n",
    "        \"        if len(feedback_data) > 0:\\n\",\n",
    "        \"            true_anomalies = feedback_data[feedback_data['is_anomaly'] == True]['score']\\n\",\n",
    "        \"            if len(true_anomalies) > 0:\\n\",\n",
    "        \"                self.thresholds['low'] = np.percentile(true_anomalies, 25)\\n\",\n",
    "        \"                self.thresholds['medium'] = np.percentile(true_anomalies, 50)\\n\",\n",
    "        \"                self.thresholds['high'] = np.percentile(true_anomalies, 75)\\n\",\n",
    "        \"                self.thresholds['critical'] = np.percentile(true_anomalies, 90)\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"C7jCyoZKmN8_\"\n",
    "      },\n",
    "      \"id\": \"C7jCyoZKmN8_\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"class ActiveLearningComponent:\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"    Active learning for continuous model improvement\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def __init__(self, buffer_size=10000):\\n\",\n",
    "        \"        self.buffer_size = buffer_size\\n\",\n",
    "        \"        self.experience_buffer = []\\n\",\n",
    "        \"        self.feedback_history = []\\n\",\n",
    "        \"        self.model_performance = {}\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def collect_feedback(self, predictions, actual_values, expert_annotations=None):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Collect feedback from various sources\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        feedback = {\\n\",\n",
    "        \"            'timestamp': pd.Timestamp.now(),\\n\",\n",
    "        \"            'predictions': predictions,\\n\",\n",
    "        \"            'actual_values': actual_values,\\n\",\n",
    "        \"            'expert_annotations': expert_annotations,\\n\",\n",
    "        \"            'error': np.abs(predictions - actual_values) if actual_values is not None else None\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        self.feedback_history.append(feedback)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Maintain buffer size\\n\",\n",
    "        \"        if len(self.feedback_history) > self.buffer_size:\\n\",\n",
    "        \"            self.feedback_history = self.feedback_history[-self.buffer_size:]\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def select_samples_for_labeling(self, uncertainty_scores, n_samples=10):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Select most uncertain samples for expert labeling\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        # Select samples with highest uncertainty\\n\",\n",
    "        \"        uncertain_indices = np.argsort(uncertainty_scores)[-n_samples:]\\n\",\n",
    "        \"        return uncertain_indices\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def update_models(self, forecasting_engine, anomaly_detector, new_data):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Incremental model updates using transfer learning\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        # This would implement incremental learning\\n\",\n",
    "        \"        # For now, we'll track performance and suggest retraining\\n\",\n",
    "        \"\\n\",\n",
    "        \"        current_performance = self.evaluate_model_performance(new_data)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if self.should_retrain(current_performance):\\n\",\n",
    "        \"            return True  # Signal for retraining\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return False\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def evaluate_model_performance(self, data):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Evaluate current model performance\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        # Calculate performance metrics\\n\",\n",
    "        \"        performance = {\\n\",\n",
    "        \"            'timestamp': pd.Timestamp.now(),\\n\",\n",
    "        \"            'accuracy': 0.0,  # Would be calculated from actual vs predicted\\n\",\n",
    "        \"            'precision': 0.0,\\n\",\n",
    "        \"            'recall': 0.0,\\n\",\n",
    "        \"            'f1_score': 0.0\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        self.model_performance[performance['timestamp']] = performance\\n\",\n",
    "        \"        return performance\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def should_retrain(self, current_performance, threshold=0.8):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Decide if models need retraining\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        if len(self.model_performance) < 2:\\n\",\n",
    "        \"            return False\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Compare with historical performance\\n\",\n",
    "        \"        recent_performances = list(self.model_performance.values())[-5:]\\n\",\n",
    "        \"        avg_performance = np.mean([p['accuracy'] for p in recent_performances])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return current_performance['accuracy'] < avg_performance * threshold\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"EW6z6m_0mPGe\"\n",
    "      },\n",
    "      \"id\": \"EW6z6m_0mPGe\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"class ExplainableDecisionSupport:\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"    Provides explanations and decision support for predictions\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def __init__(self):\\n\",\n",
    "        \"        self.feature_importance = {}\\n\",\n",
    "        \"        self.explanation_templates = {\\n\",\n",
    "        \"            'anomaly': \\\"Anomaly detected due to unusual patterns in {features}. Confidence: {confidence:.2f}\\\",\\n\",\n",
    "        \"            'forecast': \\\"Forecast based on historical trends in {features}. Confidence interval: [{lower:.2f}, {upper:.2f}]\\\"\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def explain_anomaly(self, anomaly_score, feature_values, feature_names, detection_details):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Generate explanation for anomaly detection\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        # Find most contributing features\\n\",\n",
    "        \"        if 'isolation_forest' in detection_details:\\n\",\n",
    "        \"            # For simplicity, use variance-based importance\\n\",\n",
    "        \"            feature_importance = np.var(feature_values.reshape(1, -1), axis=0)\\n\",\n",
    "        \"            top_features_idx = np.argsort(feature_importance)[-3:]\\n\",\n",
    "        \"            top_features = [feature_names[i] for i in top_features_idx]\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            top_features = feature_names[:3]  # Fallback\\n\",\n",
    "        \"\\n\",\n",
    "        \"        explanation = self.explanation_templates['anomaly'].format(\\n\",\n",
    "        \"            features=', '.join(top_features),\\n\",\n",
    "        \"            confidence=anomaly_score\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return {\\n\",\n",
    "        \"            'explanation': explanation,\\n\",\n",
    "        \"            'contributing_features': top_features,\\n\",\n",
    "        \"            'confidence': anomaly_score,\\n\",\n",
    "        \"            'severity': self._get_severity_level(anomaly_score),\\n\",\n",
    "        \"            'recommendations': self._get_recommendations(anomaly_score, top_features)\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def explain_forecast(self, forecast_values, confidence_intervals, contributing_factors):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Generate explanation for forecasts\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        explanation = self.explanation_templates['forecast'].format(\\n\",\n",
    "        \"            features=', '.join(contributing_factors),\\n\",\n",
    "        \"            lower=confidence_intervals[0],\\n\",\n",
    "        \"            upper=confidence_intervals[1]\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return {\\n\",\n",
    "        \"            'explanation': explanation,\\n\",\n",
    "        \"            'forecast_trend': 'increasing' if forecast_values[-1] > forecast_values[0] else 'decreasing',\\n\",\n",
    "        \"            'confidence_interval': confidence_intervals,\\n\",\n",
    "        \"            'key_factors': contributing_factors\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def _get_severity_level(self, score):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Map anomaly score to severity level\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        if score >= 0.9:\\n\",\n",
    "        \"            return 'Critical'\\n\",\n",
    "        \"        elif score >= 0.7:\\n\",\n",
    "        \"            return 'High'\\n\",\n",
    "        \"        elif score >= 0.5:\\n\",\n",
    "        \"            return 'Medium'\\n\",\n",
    "        \"        elif score >= 0.3:\\n\",\n",
    "        \"            return 'Low'\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            return 'Normal'\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def _get_recommendations(self, score, features):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Generate recommendations based on anomaly\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        recommendations = []\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if score >= 0.7:\\n\",\n",
    "        \"            recommendations.append(\\\"Immediate investigation required\\\")\\n\",\n",
    "        \"            recommendations.append(\\\"Check system logs for errors\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if 'cpu' in str(features).lower():\\n\",\n",
    "        \"            recommendations.append(\\\"Monitor CPU-intensive processes\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if 'memory' in str(features).lower():\\n\",\n",
    "        \"            recommendations.append(\\\"Check memory usage and potential leaks\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if 'io' in str(features).lower():\\n\",\n",
    "        \"            recommendations.append(\\\"Investigate disk I/O performance\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return recommendations\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Rlz5XXAImQY9\"\n",
    "      },\n",
    "      \"id\": \"Rlz5XXAImQY9\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"class AIXMonitoringTrainer:\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"    Main training class that orchestrates all components\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def __init__(self):\\n\",\n",
    "        \"        self.data_processor = DataProcessor()\\n\",\n",
    "        \"        self.forecasting_engine = ForecastingEngine()\\n\",\n",
    "        \"        self.anomaly_detector = AnomalyDetector()\\n\",\n",
    "        \"        self.active_learner = ActiveLearningComponent()\\n\",\n",
    "        \"        self.explainer = ExplainableDecisionSupport()\\n\",\n",
    "        \"\\n\",\n",
    "        \"        self.is_trained = False\\n\",\n",
    "        \"        self.training_history = []\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def merge_data(self, vmstat_df, iostat_df, netstat_df, process_df):\\n\",\n",
    "        \"        \\\"\\\"\\\"Merge data from multiple sources\\\"\\\"\\\"\\n\",\n",
    "        \"        # Convert to pandas if using Polars\\n\",\n",
    "        \"        if isinstance(vmstat_df, pl.DataFrame):\\n\",\n",
    "        \"            vmstat_df = vmstat_df.to_pandas(date_unit='ms')\\n\",\n",
    "        \"        if isinstance(iostat_df, pl.DataFrame):\\n\",\n",
    "        \"            iostat_df = iostat_df.to_pandas(date_unit='ms')\\n\",\n",
    "        \"        if isinstance(netstat_df, pl.DataFrame):\\n\",\n",
    "        \"            netstat_df = netstat_df.to_pandas(date_unit='ms')\\n\",\n",
    "        \"        if isinstance(process_df, pl.DataFrame):\\n\",\n",
    "        \"            process_df = process_df.to_pandas(date_unit='ms')\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Merge all data on id and timestamp\\n\",\n",
    "        \"        merged_df = vmstat_df.merge(\\n\",\n",
    "        \"            iostat_df, on=['id', 'timestamp'], how='outer', suffixes=('', '_iostat')\\n\",\n",
    "        \"        ).merge(\\n\",\n",
    "        \"            netstat_df, on=['id', 'timestamp'], how='outer', suffixes=('', '_netstat')\\n\",\n",
    "        \"        ).merge(\\n\",\n",
    "        \"            process_df, on=['id', 'timestamp'], how='outer', suffixes=('', '_process')\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Fill missing values with 0\\n\",\n",
    "        \"        merged_df.fillna(0, inplace=True)\\n\",\n",
    "        \"        return merged_df\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def train(self, vmstat_df, iostat_df, netstat_df, process_df,\\n\",\n",
    "        \"              target_columns=['us', 'sy', 'mem_mean', 'tps'],\\n\",\n",
    "        \"              test_size=0.2):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Complete training pipeline\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        print(\\\"Starting AIX Monitoring System Training...\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # 0. Merge data\\n\",\n",
    "        \"        print(\\\"0. Merging data...\\\")\\n\",\n",
    "        \"        merged_df = self.merge_data(vmstat_df, iostat_df, netstat_df, process_df)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # 1. Data Processing\\n\",\n",
    "        \"        print(\\\"1. Processing data...\\\")\\n\",\n",
    "        \"        processed_df = self.data_processor.process_data(merged_df, target_columns)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # 2. Split data\\n\",\n",
    "        \"        train_df, test_df = train_test_split(\\n\",\n",
    "        \"            processed_df, test_size=test_size, shuffle=False\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # 3. Train Forecasting Models\\n\",\n",
    "        \"        print(\\\"2. Training forecasting models...\\\")\\n\",\n",
    "        \"        self.forecasting_engine.train_ensemble(train_df, target_columns)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # 4. Train Anomaly Detection Models\\n\",\n",
    "        \"        print(\\\"3. Training anomaly detection models...\\\")\\n\",\n",
    "        \"        self.anomaly_detector.train_detectors(train_df)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # 5. Evaluate on test set\\n\",\n",
    "        \"        print(\\\"4. Evaluating models...\\\")\\n\",\n",
    "        \"        evaluation_results = self.evaluate_models(test_df, target_columns)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # 6. Store training history\\n\",\n",
    "        \"        training_record = {\\n\",\n",
    "        \"            'timestamp': pd.Timestamp.now(),\\n\",\n",
    "        \"            'train_size': len(train_df),\\n\",\n",
    "        \"            'test_size': len(test_df),\\n\",\n",
    "        \"            'target_columns': target_columns,\\n\",\n",
    "        \"            'evaluation_results': evaluation_results\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"        self.training_history.append(training_record)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        self.is_trained = True\\n\",\n",
    "        \"        print(\\\"Training completed successfully!\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return evaluation_results\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def evaluate_models(self, test_df, target_columns):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Comprehensive model evaluation\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        results = {\\n\",\n",
    "        \"            'forecasting': {},\\n\",\n",
    "        \"            'anomaly_detection': {},\\n\",\n",
    "        \"            'overall_performance': {}\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Evaluate Forecasting\\n\",\n",
    "        \"        for target_col in target_columns:\\n\",\n",
    "        \"            if target_col in test_df.columns:\\n\",\n",
    "        \"                # Generate predictions\\n\",\n",
    "        \"                forecast_pred, model_preds = self.forecasting_engine.predict(\\n\",\n",
    "        \"                    test_df.head(50), target_col, horizon=24\\n\",\n",
    "        \"                )\\n\",\n",
    "        \"\\n\",\n",
    "        \"                if forecast_pred is not None and len(forecast_pred) > 0:\\n\",\n",
    "        \"                    # Calculate metrics (simplified - would need actual future values)\\n\",\n",
    "        \"                    results['forecasting'][target_col] = {\\n\",\n",
    "        \"                        'mae': np.mean(np.abs(forecast_pred)),\\n\",\n",
    "        \"                        'mse': np.mean(forecast_pred ** 2),\\n\",\n",
    "        \"                        'model_contributions': list(model_preds.keys())\\n\",\n",
    "        \"                    }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Evaluate Anomaly Detection\\n\",\n",
    "        \"        anomaly_scores, severity, detection_details = self.anomaly_detector.detect_anomalies(test_df)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        results['anomaly_detection'] = {\\n\",\n",
    "        \"            'total_anomalies': np.sum(severity != 'Normal'),\\n\",\n",
    "        \"            'severity_distribution': {\\n\",\n",
    "        \"                severity_level: np.sum(severity == severity_level)\\n\",\n",
    "        \"                for severity_level in ['Normal', 'Low', 'Medium', 'High', 'Critical']\\n\",\n",
    "        \"            },\\n\",\n",
    "        \"            'average_anomaly_score': np.mean(anomaly_scores),\\n\",\n",
    "        \"            'detection_methods_used': list(detection_details.keys())\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Overall Performance\\n\",\n",
    "        \"        results['overall_performance'] = {\\n\",\n",
    "        \"            'training_time': pd.Timestamp.now(),\\n\",\n",
    "        \"            'data_quality_score': self._calculate_data_quality_score(test_df),\\n\",\n",
    "        \"            'model_complexity': self._calculate_model_complexity(),\\n\",\n",
    "        \"            'memory_usage_mb': self._estimate_memory_usage()\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return results\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def predict_and_detect(self, vmstat_df, iostat_df, netstat_df, process_df,\\n\",\n",
    "        \"                          target_columns=['us', 'sy', 'mem_mean', 'tps'],\\n\",\n",
    "        \"                          forecast_horizon=24):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Generate predictions and detect anomalies on new data\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        if not self.is_trained:\\n\",\n",
    "        \"            raise ValueError(\\\"Models must be trained before making predictions\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Process new data\\n\",\n",
    "        \"        merged_df = self.merge_data(vmstat_df, iostat_df, netstat_df, process_df)\\n\",\n",
    "        \"        processed_df = self.data_processor.process_data(merged_df, target_columns)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        results = {\\n\",\n",
    "        \"            'forecasts': {},\\n\",\n",
    "        \"            'anomalies': {},\\n\",\n",
    "        \"            'explanations': {},\\n\",\n",
    "        \"            'recommendations': []\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Generate Forecasts\\n\",\n",
    "        \"        for target_col in target_columns:\\n\",\n",
    "        \"            if target_col in processed_df.columns:\\n\",\n",
    "        \"                forecast_pred, model_preds = self.forecasting_engine.predict(\\n\",\n",
    "        \"                    processed_df, target_col, horizon=forecast_horizon\\n\",\n",
    "        \"                )\\n\",\n",
    "        \"\\n\",\n",
    "        \"                if forecast_pred is not None:\\n\",\n",
    "        \"                    std_dev = np.std(forecast_pred)\\n\",\n",
    "        \"                    # Calculate full confidence bands\\n\",\n",
    "        \"                    confidence_band_lower = forecast_pred - 1.96 * std_dev\\n\",\n",
    "        \"                    confidence_band_upper = forecast_pred + 1.96 * std_dev\\n\",\n",
    "        \"\\n\",\n",
    "        \"                    # Get LAST confidence interval for explanation\\n\",\n",
    "        \"                    last_ci = [confidence_band_lower[-1], confidence_band_upper[-1]]\\n\",\n",
    "        \"\\n\",\n",
    "        \"                    results['forecasts'][target_col] = {\\n\",\n",
    "        \"                        'values': forecast_pred.tolist(),\\n\",\n",
    "        \"                        'confidence_intervals': [confidence_band_lower.tolist(),\\n\",\n",
    "        \"                                               confidence_band_upper.tolist()],\\n\",\n",
    "        \"                        'model_contributions': model_preds\\n\",\n",
    "        \"                    }\\n\",\n",
    "        \"\\n\",\n",
    "        \"                    # Pass single interval to explainer\\n\",\n",
    "        \"                    explanation = self.explainer.explain_forecast(\\n\",\n",
    "        \"                        forecast_pred, last_ci, [target_col]\\n\",\n",
    "        \"                    )\\n\",\n",
    "        \"                    results['explanations'][f'forecast_{target_col}'] = explanation\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Detect Anomalies\\n\",\n",
    "        \"        anomaly_scores, severity, detection_details = self.anomaly_detector.detect_anomalies(processed_df)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Find anomalous points\\n\",\n",
    "        \"        anomalous_indices = np.where(severity != 'Normal')[0]\\n\",\n",
    "        \"\\n\",\n",
    "        \"        results['anomalies'] = {\\n\",\n",
    "        \"            'scores': anomaly_scores.tolist(),\\n\",\n",
    "        \"            'severity': severity.tolist(),\\n\",\n",
    "        \"            'anomalous_points': len(anomalous_indices),\\n\",\n",
    "        \"            'detection_details': {k: v.tolist() if isinstance(v, np.ndarray) else v\\n\",\n",
    "        \"                                for k, v in detection_details.items()}\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Generate explanations for significant anomalies\\n\",\n",
    "        \"        for idx in anomalous_indices[:5]:  # Explain top 5 anomalies\\n\",\n",
    "        \"            if severity[idx] in ['High', 'Critical']:\\n\",\n",
    "        \"                feature_values = processed_df.iloc[idx][self.anomaly_detector.feature_columns].values\\n\",\n",
    "        \"                explanation = self.explainer.explain_anomaly(\\n\",\n",
    "        \"                    anomaly_scores[idx],\\n\",\n",
    "        \"                    feature_values,\\n\",\n",
    "        \"                    self.anomaly_detector.feature_columns,\\n\",\n",
    "        \"                    detection_details\\n\",\n",
    "        \"                )\\n\",\n",
    "        \"                results['explanations'][f'anomaly_{idx}'] = explanation\\n\",\n",
    "        \"                results['recommendations'].extend(explanation['recommendations'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return results\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def update_models_with_feedback(self, feedback_data):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Update models with new feedback data\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        if not self.is_trained:\\n\",\n",
    "        \"            raise ValueError(\\\"Models must be trained before updating\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Collect feedback\\n\",\n",
    "        \"        self.active_learner.collect_feedback(\\n\",\n",
    "        \"            predictions=feedback_data.get('predictions'),\\n\",\n",
    "        \"            actual_values=feedback_data.get('actual_values'),\\n\",\n",
    "        \"            expert_annotations=feedback_data.get('expert_annotations')\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Check if retraining is needed\\n\",\n",
    "        \"        should_retrain = self.active_learner.update_models(\\n\",\n",
    "        \"            self.forecasting_engine,\\n\",\n",
    "        \"            self.anomaly_detector,\\n\",\n",
    "        \"            feedback_data\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if should_retrain:\\n\",\n",
    "        \"            print(\\\"Model performance degraded. Retraining recommended.\\\")\\n\",\n",
    "        \"            return {'status': 'retraining_recommended', 'reason': 'performance_degradation'}\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            # Update thresholds based on feedback\\n\",\n",
    "        \"            if 'anomaly_feedback' in feedback_data:\\n\",\n",
    "        \"                self.anomaly_detector.update_thresholds(feedback_data['anomaly_feedback'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"            return {'status': 'updated', 'reason': 'incremental_learning'}\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def get_model_status(self):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Get current status of all models\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        if not self.is_trained:\\n\",\n",
    "        \"            return {'status': 'not_trained', 'models': {}}\\n\",\n",
    "        \"\\n\",\n",
    "        \"        status = {\\n\",\n",
    "        \"            'status': 'trained',\\n\",\n",
    "        \"            'training_history': len(self.training_history),\\n\",\n",
    "        \"            'last_training': self.training_history[-1]['timestamp'] if self.training_history else None,\\n\",\n",
    "        \"            'models': {\\n\",\n",
    "        \"                'forecasting': {\\n\",\n",
    "        \"                    'lstm_models': len([k for k in self.forecasting_engine.models.keys() if 'lstm' in k]),\\n\",\n",
    "        \"                    'transformer_models': len([k for k in self.forecasting_engine.models.keys() if 'transformer' in k]),\\n\",\n",
    "        \"                    'arima_models': len([k for k in self.forecasting_engine.models.keys() if 'arima' in k]),\\n\",\n",
    "        \"                    'prophet_models': len([k for k in self.forecasting_engine.models.keys() if 'prophet' in k]),\\n\",\n",
    "        \"                },\\n\",\n",
    "        \"                'anomaly_detection': {\\n\",\n",
    "        \"                    'isolation_forest': 'isolation_forest' in self.anomaly_detector.models,\\n\",\n",
    "        \"                    'oneclass_svm': 'oneclass_svm' in self.anomaly_detector.models,\\n\",\n",
    "        \"                    'lstm_autoencoder': 'lstm_autoencoder' in self.anomaly_detector.models,\\n\",\n",
    "        \"                },\\n\",\n",
    "        \"                'active_learning': {\\n\",\n",
    "        \"                    'feedback_samples': len(self.active_learner.feedback_history),\\n\",\n",
    "        \"                    'performance_records': len(self.active_learner.model_performance)\\n\",\n",
    "        \"                }\\n\",\n",
    "        \"            },\\n\",\n",
    "        \"            'memory_usage_estimate': self._estimate_memory_usage()\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return status\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def save_models(self, filepath):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Save trained models to disk\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        import pickle\\n\",\n",
    "        \"        import os\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if not self.is_trained:\\n\",\n",
    "        \"            raise ValueError(\\\"No trained models to save\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        os.makedirs(filepath, exist_ok=True)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save data processor\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'data_processor.pkl'), 'wb') as f:\\n\",\n",
    "        \"            pickle.dump(self.data_processor, f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save forecasting models (non-neural network components)\\n\",\n",
    "        \"        forecasting_state = {\\n\",\n",
    "        \"            'model_weights': self.forecasting_engine.model_weights,\\n\",\n",
    "        \"            'feature_columns': self.forecasting_engine.feature_columns,\\n\",\n",
    "        \"            'sequence_length': self.forecasting_engine.sequence_length\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save ARIMA and Prophet models\\n\",\n",
    "        \"        arima_models = {k: v for k, v in self.forecasting_engine.models.items() if 'arima' in k}\\n\",\n",
    "        \"        prophet_models = {k: v for k, v in self.forecasting_engine.models.items() if 'prophet' in k}\\n\",\n",
    "        \"\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'forecasting_classical.pkl'), 'wb') as f:\\n\",\n",
    "        \"            pickle.dump({'arima': arima_models, 'prophet': prophet_models, 'state': forecasting_state}, f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save neural network models separately\\n\",\n",
    "        \"        for model_name, model in self.forecasting_engine.models.items():\\n\",\n",
    "        \"            if 'lstm' in model_name or 'transformer' in model_name:\\n\",\n",
    "        \"                model.save(os.path.join(filepath, f'{model_name}.h5'))\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save anomaly detection models\\n\",\n",
    "        \"        anomaly_state = {\\n\",\n",
    "        \"            'thresholds': self.anomaly_detector.thresholds,\\n\",\n",
    "        \"            'feature_columns': self.anomaly_detector.feature_columns,\\n\",\n",
    "        \"            'sequence_length': self.anomaly_detector.sequence_length\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save sklearn models\\n\",\n",
    "        \"        sklearn_models = {k: v for k, v in self.anomaly_detector.models.items()\\n\",\n",
    "        \"                         if k in ['isolation_forest', 'oneclass_svm']}\\n\",\n",
    "        \"\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'anomaly_detection.pkl'), 'wb') as f:\\n\",\n",
    "        \"            pickle.dump({'sklearn_models': sklearn_models, 'state': anomaly_state}, f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save LSTM autoencoder\\n\",\n",
    "        \"        if 'lstm_autoencoder' in self.anomaly_detector.models:\\n\",\n",
    "        \"            self.anomaly_detector.models['lstm_autoencoder'].save(\\n\",\n",
    "        \"                os.path.join(filepath, 'lstm_autoencoder.h5')\\n\",\n",
    "        \"            )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save active learning component\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'active_learning.pkl'), 'wb') as f:\\n\",\n",
    "        \"            pickle.dump(self.active_learner, f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Save training history\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'training_history.pkl'), 'wb') as f:\\n\",\n",
    "        \"            pickle.dump(self.training_history, f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        print(f\\\"Models saved successfully to {filepath}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def load_models(self, filepath):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Load trained models from disk\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        import pickle\\n\",\n",
    "        \"        import os\\n\",\n",
    "        \"        from tensorflow.keras.models import load_model\\n\",\n",
    "        \"\\n\",\n",
    "        \"        if not os.path.exists(filepath):\\n\",\n",
    "        \"            raise ValueError(f\\\"Model directory {filepath} does not exist\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load data processor\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'data_processor.pkl'), 'rb') as f:\\n\",\n",
    "        \"            self.data_processor = pickle.load(f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load forecasting models\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'forecasting_classical.pkl'), 'rb') as f:\\n\",\n",
    "        \"            forecasting_data = pickle.load(f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        self.forecasting_engine.model_weights = forecasting_data['state']['model_weights']\\n\",\n",
    "        \"        self.forecasting_engine.feature_columns = forecasting_data['state']['feature_columns']\\n\",\n",
    "        \"        self.forecasting_engine.sequence_length = forecasting_data['state']['sequence_length']\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load classical models\\n\",\n",
    "        \"        self.forecasting_engine.models.update(forecasting_data['arima'])\\n\",\n",
    "        \"        self.forecasting_engine.models.update(forecasting_data['prophet'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load neural network models\\n\",\n",
    "        \"        for filename in os.listdir(filepath):\\n\",\n",
    "        \"            if filename.endswith('.h5') and ('lstm' in filename or 'transformer' in filename):\\n\",\n",
    "        \"                model_name = filename.replace('.h5', '')\\n\",\n",
    "        \"                if 'autoencoder' not in filename:  # Skip autoencoder here\\n\",\n",
    "        \"                    self.forecasting_engine.models[model_name] = load_model(\\n\",\n",
    "        \"                        os.path.join(filepath, filename)\\n\",\n",
    "        \"                    )\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load anomaly detection models\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'anomaly_detection.pkl'), 'rb') as f:\\n\",\n",
    "        \"            anomaly_data = pickle.load(f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        self.anomaly_detector.thresholds = anomaly_data['state']['thresholds']\\n\",\n",
    "        \"        self.anomaly_detector.feature_columns = anomaly_data['state']['feature_columns']\\n\",\n",
    "        \"        self.anomaly_detector.sequence_length = anomaly_data['state']['sequence_length']\\n\",\n",
    "        \"        self.anomaly_detector.models.update(anomaly_data['sklearn_models'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load LSTM autoencoder\\n\",\n",
    "        \"        autoencoder_path = os.path.join(filepath, 'lstm_autoencoder.h5')\\n\",\n",
    "        \"        if os.path.exists(autoencoder_path):\\n\",\n",
    "        \"            self.anomaly_detector.models['lstm_autoencoder'] = load_model(autoencoder_path)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load active learning component\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'active_learning.pkl'), 'rb') as f:\\n\",\n",
    "        \"            self.active_learner = pickle.load(f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Load training history\\n\",\n",
    "        \"        with open(os.path.join(filepath, 'training_history.pkl'), 'rb') as f:\\n\",\n",
    "        \"            self.training_history = pickle.load(f)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        self.is_trained = True\\n\",\n",
    "        \"        print(f\\\"Models loaded successfully from {filepath}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def _calculate_data_quality_score(self, df):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Calculate a simple data quality score\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        numeric_df = df.select_dtypes(include=[np.number])\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Check for missing values\\n\",\n",
    "        \"        missing_ratio = numeric_df.isnull().sum().sum() / (len(numeric_df) * len(numeric_df.columns))\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Check for constant columns\\n\",\n",
    "        \"        constant_cols = (numeric_df.nunique() == 1).sum()\\n\",\n",
    "        \"        constant_ratio = constant_cols / len(numeric_df.columns)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Calculate quality score (0-1, higher is better)\\n\",\n",
    "        \"        quality_score = (1 - missing_ratio) * (1 - constant_ratio)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return max(0, min(1, quality_score))\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def _calculate_model_complexity(self):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Estimate model complexity\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        complexity = 0\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Count forecasting models\\n\",\n",
    "        \"        complexity += len(self.forecasting_engine.models) * 10\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Count anomaly detection models\\n\",\n",
    "        \"        complexity += len(self.anomaly_detector.models) * 5\\n\",\n",
    "        \"\\n\",\n",
    "        \"        # Add feature complexity\\n\",\n",
    "        \"        complexity += len(self.data_processor.feature_columns)\\n\",\n",
    "        \"\\n\",\n",
    "        \"        return complexity\\n\",\n",
    "        \"\\n\",\n",
    "        \"    def _estimate_memory_usage(self):\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        Estimate memory usage in MB\\n\",\n",
    "        \"        \\\"\\\"\\\"\\n\",\n",
    "        \"        total_size = 0\\n\",\n",
    "        \"        components = [\\n\",\n",
    "        \"            self.data_processor,\\n\",\n",
    "        \"            self.forecasting_engine,\\n\",\n",
    "        \"            self.anomaly_detector,\\n\",\n",
    "        \"            self.active_learner\\n\",\n",
    "        \"        ]\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        for obj in components:\\n\",\n",
    "        \"            for v in vars(obj).values():\\n\",\n",
    "        \"                total_size += sys.getsizeof(v)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Add model sizes\\n\",\n",
    "        \"        for model in self.forecasting_engine.models.values():\\n\",\n",
    "        \"            if hasattr(model, 'count_params'):\\n\",\n",
    "        \"                total_size += model.count_params() * 4  # 4 bytes per float\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        return total_size / (1024 * 1024)  # Convert to MB\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"KYh8rWTumRni\"\n",
    "      },\n",
    "      \"id\": \"KYh8rWTumRni\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"source\": [\n",
    "        \"# Load data with Polars\\n\",\n",
    "        \"def load_and_fix_data():\\n\",\n",
    "        \"    print(\\\"Loading real AIX server metrics with Polars...\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Load data with Polars\\n\",\n",
    "        \"    vmstat_df = pl.read_csv(\\\"vmstat_metrics.csv\\\")\\n\",\n",
    "        \"    iostat_df = pl.read_csv(\\\"iostat_metrics.csv\\\")\\n\",\n",
    "        \"    netstat_df = pl.read_csv(\\\"netstat_metrics.csv\\\")\\n\",\n",
    "        \"    process_df = pl.read_csv(\\\"process_metrics.csv\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Function to fix timestamps\\n\",\n",
    "        \"    def fix_timestamps(df):\\n\",\n",
    "        \"        # Handle incomplete timestamps\\n\",\n",
    "        \"        df = df.with_columns(\\n\",\n",
    "        \"            pl.when(pl.col(\\\"timestamp\\\").str.ends_with(\\\"+00\\\") | pl.col(\\\"timestamp\\\").str.ends_with(\\\"-00\\\"))\\n\",\n",
    "        \"            .then(pl.col(\\\"timestamp\\\") + \\\"00\\\")\\n\",\n",
    "        \"            .otherwise(pl.col(\\\"timestamp\\\"))\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Try multiple formats\\n\",\n",
    "        \"        return df.with_columns(\\n\",\n",
    "        \"            pl.coalesce(\\n\",\n",
    "        \"                pl.col(\\\"timestamp\\\").str.to_datetime(strict=False, format=\\\"%Y-%m-%d %H:%M:%S%.f%z\\\"),\\n\",\n",
    "        \"                pl.col(\\\"timestamp\\\").str.to_datetime(strict=False, format=\\\"%Y-%m-%d %H:%M:%S\\\"),\\n\",\n",
    "        \"                pl.col(\\\"timestamp\\\").str.to_datetime(strict=False, format=\\\"%Y-%m-%d %H\\\")\\n\",\n",
    "        \"            )\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Apply to all dataframes\\n\",\n",
    "        \"    vmstat_df = fix_timestamps(vmstat_df)\\n\",\n",
    "        \"    iostat_df = fix_timestamps(iostat_df)\\n\",\n",
    "        \"    netstat_df = fix_timestamps(netstat_df)\\n\",\n",
    "        \"    process_df = fix_timestamps(process_df)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return vmstat_df, iostat_df, netstat_df, process_df\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Load data\\n\",\n",
    "        \"vmstat_df, iostat_df, netstat_df, process_df = load_and_fix_data()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Initialize trainer\\n\",\n",
    "        \"trainer = AIXMonitoringTrainer()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Define target columns\\n\",\n",
    "        \"target_columns = [\\n\",\n",
    "        \"    # CPU metrics (vmstat)\\n\",\n",
    "        \"    'us',    # User CPU %\\n\",\n",
    "        \"    'sy',    # System CPU %\\n\",\n",
    "        \"    'idle',  # Idle CPU %\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Memory metrics (vmstat)\\n\",\n",
    "        \"    'fre',   # Free memory\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Disk metrics (iostat)\\n\",\n",
    "        \"    'tps',   # Transactions per second\\n\",\n",
    "        \"    'service_time',  # Disk service time\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Network metrics (netstat)\\n\",\n",
    "        \"    'ipkts_rate',  # Input packets rate\\n\",\n",
    "        \"    'oerrs_rate',  # Output error rate\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # Process metrics (process)\\n\",\n",
    "        \"    'cpu'    # Process CPU usage\\n\",\n",
    "        \"]\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Train the model\\n\",\n",
    "        \"print(\\\"\\\\nTraining models for:\\\", target_columns)\\n\",\n",
    "        \"evaluation_results = trainer.train(\\n\",\n",
    "        \"    vmstat_df,\\n\",\n",
    "        \"    iostat_df,\\n\",\n",
    "        \"    netstat_df,\\n\",\n",
    "        \"    process_df,\\n\",\n",
    "        \"    target_columns=target_columns,\\n\",\n",
    "        \"    test_size=0.2\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Print detailed evaluation results\\n\",\n",
    "        \"def print_evaluation(results):\\n\",\n",
    "        \"    print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "        \"    print(\\\"FORECASTING PERFORMANCE (MAE/MSE)\\\")\\n\",\n",
    "        \"    print(\\\"=\\\"*50)\\n\",\n",
    "        \"    for metric, scores in results['forecasting'].items():\\n\",\n",
    "        \"        print(f\\\"{metric.upper():<15} MAE: {scores['mae']:.4f} | MSE: {scores['mse']:.4f}\\\")\\n\",\n",
    "        \"        print(f\\\"    Models used: {', '.join(scores['model_contributions'])}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "        \"    print(\\\"ANOMALY DETECTION RESULTS\\\")\\n\",\n",
    "        \"    print(\\\"=\\\"*50)\\n\",\n",
    "        \"    anomalies = results['anomaly_detection']\\n\",\n",
    "        \"    print(f\\\"Total anomalies detected: {anomalies['total_anomalies']}\\\")\\n\",\n",
    "        \"    print(\\\"Severity distribution:\\\")\\n\",\n",
    "        \"    for severity, count in anomalies['severity_distribution'].items():\\n\",\n",
    "        \"        print(f\\\"  {severity:<8}: {count}\\\")\\n\",\n",
    "        \"    print(f\\\"Average anomaly score: {anomalies['average_anomaly_score']:.2f}\\\")\\n\",\n",
    "        \"    print(f\\\"Detection methods: {', '.join(anomalies['detection_methods_used'])}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "        \"    print(\\\"SYSTEM PERFORMANCE METRICS\\\")\\n\",\n",
    "        \"    print(\\\"=\\\"*50)\\n\",\n",
    "        \"    perf = results['overall_performance']\\n\",\n",
    "        \"    print(f\\\"Training time: {perf['training_time']}\\\")\\n\",\n",
    "        \"    print(f\\\"Data quality score: {perf['data_quality_score']:.2f}/1.0\\\")\\n\",\n",
    "        \"    print(f\\\"Model complexity: {perf['model_complexity']} (relative units)\\\")\\n\",\n",
    "        \"    print(f\\\"Memory usage: {perf['memory_usage_mb']:.2f} MB\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print_evaluation(evaluation_results)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Sample predictions\\n\",\n",
    "        \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "        \"print(\\\"GENERATING SAMPLE PREDICTIONS\\\")\\n\",\n",
    "        \"print(\\\"=\\\"*50)\\n\",\n",
    "        \"sample_results = trainer.predict_and_detect(\\n\",\n",
    "        \"    vmstat_df.tail(100),\\n\",\n",
    "        \"    iostat_df.tail(200),\\n\",\n",
    "        \"    netstat_df.tail(200),\\n\",\n",
    "        \"    process_df.tail(500)\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"\\\\nGenerated forecasts for: {list(sample_results['forecasts'].keys())}\\\")\\n\",\n",
    "        \"print(f\\\"Detected {sample_results['anomalies']['anomalous_points']} anomalies\\\")\\n\",\n",
    "        \"print(f\\\"Top anomaly explanation:\\\")\\n\",\n",
    "        \"first_anomaly_key = [k for k in sample_results['explanations'].keys() if 'anomaly_' in k][0]\\n\",\n",
    "        \"print(sample_results['explanations'][first_anomaly_key]['explanation'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Model status\\n\",\n",
    "        \"print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "        \"print(\\\"MODEL STATUS SUMMARY\\\")\\n\",\n",
    "        \"print(\\\"=\\\"*50)\\n\",\n",
    "        \"status = trainer.get_model_status()\\n\",\n",
    "        \"print(f\\\"Status: {status['status']}\\\")\\n\",\n",
    "        \"print(f\\\"Last trained: {status['last_training']}\\\")\\n\",\n",
    "        \"print(f\\\"Forecasting models: {status['models']['forecasting']}\\\")\\n\",\n",
    "        \"print(f\\\"Anomaly detectors: {status['models']['anomaly_detection']}\\\")\\n\",\n",
    "        \"print(f\\\"Memory usage: {status['memory_usage_estimate']:.2f} MB\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Save models\\n\",\n",
    "        \"trainer.save_models(\\\"aix_monitoring_models\\\")\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"WRfSmnYwmTOZ\"\n",
    "      },\n",
    "      \"id\": \"WRfSmnYwmTOZ\",\n",
    "      \"execution_count\": null,\n",
    "      \"outputs\": []\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"file_extension\": \".py\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"name\": \"python\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"version\": \"3.11.11\"\n",
    "    },\n",
    "    \"colab\": {\n",
    "      \"provenance\": []\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"import pandas as pd\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import polars as pl\\n\",\n",
    "        \"from sklearn.preprocessing import StandardScaler, RobustScaler\\n\",\n",
    "        \"from sklearn.ensemble import IsolationForest\\n\",\n",
    "        \"from sklearn.svm import OneClassSVM\\n\",\n",
    "        \"from sklearn.model_selection import train_test_split\\n\",\n",
    "        \"from sklearn.metrics import precision_recall_fscore_support, mean_absolute_error\\n\",\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from tensorflow.keras.models import Sequential, Model\\n\",\n",
    "        \"from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, RepeatVector, TimeDistributed\\n\",\n",
    "        \"from tensorflow.keras.optimizers import Adam\\n\",\n",
    "        \"from statsmodels.tsa.arima.model import ARIMA\\n\",\n",
    "        \"from statsmodels.tsa.holtwinters import SimpleExpSmoothing\\n\",\n",
    "        \"from prophet import Prophet\\n\",\n",
    "        \"import warnings\\n\",\n",
    "        \"import sys\\n\",\n",
    "        \"warnings.filterwarnings('ignore')\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
